6022616 5595336 5279443 4730362 4425265 4020651 10535 8638 
6027350
3D ellipsoid fitting for multi-view gait recognition###Gait recognition approaches continue to struggle with challenges including view-invariance, low-resolution data, robustness to unconstrained environments, and fluctuating gait patterns due to subjects carrying goods or wearing different clothes. Although computationally expensive, model based techniques offer promise over appearance based techniques for these challenges as they gather gait features and interpret gait dynamics in skeleton form. In this paper, we propose a fast 3D ellipsoidal-based gait recognition algorithm using a 3D voxel model derived from multi-view silhouette images. This approach directly solves the limitations of view dependency and self-occlusion in existing ellipse fitting model-based approaches. Voxel models are segmented into four components (left and right legs, above and below the knee), and ellipsoids are fitted to each region using eigenvalue decomposition. Features derived from the ellipsoid parameters are modeled using a Fourier representation to retain the temporal dynamic pattern for classification. We demonstrate the proposed approach using the CMU MoBo database and show that an improvement of 15-20% can be achieved over a 2D ellipse fitting baseline.
6027351
Part-based clothing segmentation for person retrieval###Recent advances have shown that clothing appearance provides important features for person re-identification and retrieval in surveillance and multimedia data. However, the regions from which such features are extracted are usually only very crudely segmented, due to the difficulty of segmenting highly articulated entities such as persons. In order to overcome the problem of unconstrained poses, we propose a segmentation approach based on a large number of part detectors. Our approach is able to separately segment a person's upper and lower clothing regions, taking into account the person's body pose. We evaluate our approach on the task of character retrieval on a new challenging data set and present promising results.
6027374
Modeling and optimization of dynamic signal processing in resource-aware sensor networks###Sensor node processing in resource-aware sensor networks is often critically dependent on dynamic signal processing functionality - i.e., signal processing functionality in which computational structure must be dynamically assessed and adapted based on time-varying environmental conditions, operating constraints or application requirements. In dynamic signal processing systems, it is important to provide flexibility for run-time adaptation of application behavior and execution characteristics, but in the domain of resource-aware sensor networks, such flexibility cannot come with significant costs in terms of power consumption overhead or reduced predictability. In this paper, we review a variety of complementary models of computation that are being developed as part of the dataflow interchange format (DIF) project to facilitate efficient and reliable implementation of dynamic signal processing systems. We demonstrate these methods in the context of resource-aware sensor networks.
6027375
Dynamic resource aware sensor networks: Integration of sensor cloud and ERPs###Today's work in the sensor networks community focuses on collecting and processing data from specific networks with associated base stations. One of the most important requirements in these networks is minimizing resource usage such as processing power and storage size on sensor nodes. Resource constraints in the sensor nodes can be divided into four categories: energy, communication, storage and computational power. In this paper, we present an efficient deployment of sensors with possibility of accessing most recent data through information obtained from ERP (enterprise resource planning) systems' re-configuration models. In this scheme the probability of losing any precious data or events would be minimized. In other words, our main focus in this paper is using ERP or high level distributed decision making systems' processed data or prediction models to reduce resource usage needed on sensor nodes. In the area of integration of sensors and ERPs or distributed decision making systems, very little work has been reported. However, those reported in the literature, mostly address relaying data from sensors to ERPs and tend to largely ignore issues that come with sensor resource constraints. Also they don't make use of the information processed and generated by ERPs in the cloud environment to optimize power consumption and transmission frequency of sensors, which is our aim.
6027377
Determining operational measures from multi-camera surveillance systems using soft biometrics###CCTV and surveillance networks are increasingly being used for operational as well as security tasks. One emerging area of technology that lends itself to operational analytics is soft biometrics. Soft biometrics can be used to describe a person and detect them throughout a sparse multi-camera network. This enables them to be used to perform tasks such as determining the time taken to get from point to point, and the paths taken through an environment by detecting and matching people across disjoint views. However, in a busy environment where there are 100's if not 1000's of people such as an airport, attempting to monitor everyone is highly unrealistic. In this paper we propose an average soft biometric, that can be used to identity people who look distinct, and are thus suitable for monitoring through a large, sparse camera network. We demonstrate how an average soft biometric can be used to identify unique people to calculate operational measures such as the time taken to travel from point to point.
6027370
PTZ network configuration for optimal 3D coverage###During the last years, the need for security-oriented surveillance systems has grown higher and higher. Nowadays many public environments, such as airports, train stations, etc. are monitored by some sort of video-surveillance system in order to detect or prevent security issues. The involved technology ranges from the use of plain closed-circuit cameras (CCTV) to sophisticated computer-based video processing systems. The CCTV approach has been the only feasible choice in the past, and it is still widely used, however its limits are more and more evident: the increase of the number of sensors (modern surveillance systems can use hundreds of cameras) is often not matched by an adequate number of human operators, whose attention is spread on many different tasks and quickly decreases over time. Modern computer-based systems try to face these problems using automatic video analysis and understanding techniques, in order to cover wide areas and simultaneously highlight only the potential security issues and thus requiring the attention of a human operator only in a limited number of cases (e.g. [6, 5]). The research in this field has been very active and produced many techniques for video analysis and interpretation, but many works are limited to the use of static cameras. Only recently the research community started focusing on more sophisticated sensors like Pan-Tilt-Zoom (PTZ) cameras, and the research on dynamic, active networks of PTZ cameras is still limited (for an example of some recent works in this field, see [1]). Many of these works focus on exploiting the dynamic features of a network of PTZ cameras to improve tracking performance [3, 4, 13, 10, 12], while relatively few works address the problem of optimizing the camera coverage of the monitored area according to specific criteria. Angella et al. [2] propose a method to maximize the area coverage by using a 3D model of the observed zone, but their work only aims at finding a good initial camera displacemen- - t, which cannot be dynamically modified according to the observed data. Mittal and Davis [8, 7] also consider the presence of dynamic occluding objects in order to evaluate the visibility of the scene. Piciarelli et al. [11] propose a method to automatically and dynamically reconfigure the camera orientations and zoom levels using an Expectation-Maximization-based approach.
6027371
Resource-aware sensor selection and task assignment###Multimedia sensor networks [1] and visual sensor networks (VSN) [3] have been increasingly studied in recent years. However, the aspect of resource-awareness has just recently moved into the focus of research interests. Especially energy-aware systems that may be deployed in areas without fixed infrastructure have only recently achieved attention.
6027372
Activity aware video collection to minimize resource usage in smart camera nodes###We envision future video sensor networks comprising tether-less smart camera nodes capable of supporting a variety of applications, ranging from video surveillance to traffic management, smart environments to ecological monitoring, etc. A key difference between video sensor networks and traditional multi-camera systems is that the later typically are not concerned with power, storage, and bandwidth usage. Power requirements, especially, must be considered when designing tether-less smart camera networks, since the operational life of a camera node is closely tied to the available power. Video capture and processing performed on a camera node and the communication between nodes needed to carry out collaborative sensing tasks impact power usage of these camera nodes. Therefore, one must devise strategies to minimize video capture and processing at each node and communication between nodes in order to reduce power consumption at each node, thereby increasing the operational life of a video sensor network.
6027373
Energy-aware objects abandon / removal detection###A major issue for video surveillance embedded systems is the need to continuously perform a number of highly demanding operations even when the analyzed scene does not show peculiar or interesting features, so that power consumption is a critical issue. In this paper we present a low-power multimodal embedded video surveillance system aimed at detecting objects abandoned/removed in/from a static monitored scene. Energy-awareness is achieved by means of an efficient and scalable objects abandon/removal detection algorithm, a Linux governor that controls CPU frequency and operating mode so as to establish an optimal trade-off between fulfilling the application efficiency-accuracy requirements and maximizing battery life and, finally, a pyroelectric infrared sensor that allows to wake up the CPU only when video processing is actually needed.
6027378
Real time complex event detection for resource-limited multimedia sensor networks###This paper presents a real-time complex event detection concept for resource-limited multimedia sensor networks. A comprehensive solution based on Answer Set Programming (ASP) is developed. We show that ASP is an appropriate solution to detect a large number of simple and complex events (video-audio understanding) on platforms with limited resources e.g. power consumption, memory and processing power. We underline the major problems of the existing paradigms for complex event detection (based on e.g. logic programming and SemanticWeb), with a special focus on the major challenges which reduce the performance of real-time event detection. Finally, we demonstrate the high performance of ASP compared to that of Semantic Web.
6027379
A game-theoretic design for collaborative tracking in a video camera network###Tracking a moving target of interest at a high resolution with a dynamically designated network camera while ensuring complete-coverage of the area under surveillance of a video camera network can be a challenging task. Game theory can be applied to the situation, treating individual cameras as players and area coverage as utility. Camera collaboration is needed when one camera handoff the job of tracking a moving target of interest to another. By taking into account coverage shared by two cameras as secondary utility and giving precedence to border-covering camera directions, we can improve the performance of collaborative tracking, reducing complete-coverage failures as well as their associated uncovered blocks between handoffs. The cost of camera adjustment involved in a handoff can also be reduced this way.
6027341
People re-identification across multiple non-overlapping cameras system by appearance classification and silhouette part segmentation###In this paper, we present a new person re-identification method based on appearance classification and silhouette part segmentation. In crowded areas, heads are considered as most apparent parts, hence the typical advantage of using the skeleton graph for the head detection and location of people after partial occlusion. The appearance classification consists in characterizing the appearance of a person into two classes, the frontal and the back appearance, using head detector and the orthogonal iteration algorithm for head pose estimation. The silhouette part segmentation divides the silhouette into three horizontal parts, ideally corresponding to head, torso and legs using skeleton graph and head detector. Our approach is robust to real world situations, in particular to variations in scales, human pose, illumination and clothes appearance changes. It also allows to reduce the confusion cases among people appearance and the amount of falsely matches.
6027340
A MultiView Appearance Model for people re-identification###Tracking moving objects across events that break the continuity of the trajectory, such as occlusions or temporary exits from the scene, usually requires that a model of the objects of interest is created and maintained. Commonly used model representations are prone to errors when the objects can change the direction of their motion. In this paper we introduce a novel model representation, the MultiView Appearance Model, specifically devised to deal with the issue. The algorithms that create and update the model also take into account the problem of object apparent size changes due to perspective. An experimental evaluation of the proposed model representation has been performed on the PETS2010 dataset. The results show a consistent improvement of the performances in comparison with another well-known appearance model.
6027343
A testing framework for background subtraction algorithms comparison in intrusion detection context###Identifying objects from a video stream is a fundamental and critical task in many computer-vision applications. A popular approach is the background subtraction, which consists in separating foreground (moving objects) from background. Many methodologies have been developed for automatic background segmentation but this fundamental task is still challenging. We focus here on a particular application of computer vision: intrusion detection in video surveillance. We propose in this paper a multi-level methodology for evaluating and comparing background subtraction algorithms. Three levels are studied: first, pixel level to evaluate the accuracy of the segmentation algorithm to attribute the right class to each pixel. Second, image level, measuring the rate of right decision on each frame (intrusion vs no intrusion) and finally sequence level, measuring the accordance with the time span where objects appear. Moreover, we also propose a new similarity measure, called D-Score, adapted to the context of intrusion detection.
6027342
Frontal-to-side face re-identification based on hair, skin and clothes patches###Despite recent advances, face-recognition algorithms are still challenged when applied in the setting of video surveillance systems which inherently introduce variations in the pose of subjects. The present work addresses this problem, and seeks to provide a recognition algorithm that is specifically suited for a frontal-to-side re-identification setting. Deviating from classical biometric approaches, the proposed method considers color- and texture- based soft biometric traits, specifically those taken from patches of hair, skin and clothes. The proposed method and the suitability of these patch-based traits are then validated both analytically and empirically.
6027345
Naturalistic data sets for image and behavior analysis - &#x201C;normal&#x201D; versus &#x201C;anomalous&#x201D; events###The approach and rationale used to create controlled data sets encompassing video, track, and reference data and meta-data is described in this paper. The data sets are designed to support the development of automated technologies for the detection of situational and operational behaviors of interest. A custom tool for the concurrent visualization and access of the data is also introduced.
6027344
Online failure detection and correction for Bayesian sparse feature-based object tracking###Online evaluation of tracking algorithms is an important task in real time tracking systems to detect failures. In visual object tracking based on sparse features, detecting the failure of one of the feature points (corners) and correcting it will improve the performance of the tracker as a whole. In this paper a time reversed Markov chain is applied as evaluation technique to identify the failed trackers and Partial Least Square regression is used for learning the correlation between feature points from training data set. The detected feature point trackers are recovered from the knowledge of the learned correlation model. The results are explained on a Bayesian algorithm for rigid/nonrigid 2D visual object tracking. The experimental outcomes show a global performance improvement of the tracking algorithm even in the presence of clutter.
6027347
A comparison of a chaos-theoretic method for pre-attentive vision with traditional grayscale-based methods###Accurate and robust attention direction has been of substantial interest in the computer vision community, particularly for industrial surveillance systems that initiate recording at the onset of motion or an interesting contextual event. One key issue is minimizing false alarms to limit video record bandwidth and capacity. One issue that these systems face is high false alarm rates under sudden illumination change. In this paper we propose a system which applies measures from chaos theory and fractal analysis to provide a robust pre-attentive processing engine for motion detection. Results compare quite favorably in terms of probability of detection versus false detection rate against traditional methods for low-level change detection, namely Sum of Absolute Differences, and Gaussian Mixture Models. The proposed chaos-based method is shown to have superior performance. Additionally the proposed approach has an intuitive justification based on creation and flow of information between image frames, and consequently a very intuitive and problem-based threshold determination.
6027346
Resolution enhancement of ROI from surveillance video using Bernstein interpolation###In visual surveillance system, a small region-of-interest (ROI) is in most cases set for the target to detect, track, and recognize. In this paper, we propose novel image restoration algorithm using stochastic data regularization (i.e. Bernstein interpolation) in real world surveillance video. We firstly demonstrate the capability of Bernstein function for image enhancement technique such as denoising or deblurring. In addition, a promising approach for Super Resolution algorithm via Bernstein interpolation is also proposed. Representative experimental results prove the effectiveness of the proposed method for ROI from synthetic and real image sequences.
6027349
Improving the efficiency and accuracy of visual attention###Visual attention is the cognitive process of selectively focusing on certain areas of a visual scene while ignoring the others. It is a desirable capability for intelligent video surveillance systems, as it allows them to control the aim of mobile cameras or to selectively process the most relevant parts of the captured images. This paper proposes an adaptation of a well-known biologically-inspired visual attention model in order to increase its computational efficiency without sacrificing its accuracy, and shows that the latter can be further improved through a supervised training stage that fine-tunes the model to the particular application scope in which the system is being utilized. Experimental results and comparisons with previous visual attention techniques are shown and discussed.
6027286
Pairwise Shape configuration-based PSA for gait recognition under small viewing angle change###Two main components of Procrustes Shape Analysis (PSA) are adopted and adapted specifically to address gait recognition under small viewing angle change: 1) Procrustes Mean Shape (PMS) for gait signature description; 2) Procrustes Distance (PD) for similarity measurement. Pairwise Shape Configuration (PSC) is proposed as a shape descriptor in place of existing Centroid Shape Configuration (CSC) in conventional PSA. PSC can better tolerate shape change caused by viewing angle change than CSC. Small variation of viewing angle makes large impact only on global gait appearance. Without major impact on local spatio-temporal motion, PSC which effectively embeds local shape information can generate robust view-invariant gait feature. To enhance gait recognition performance, a novel boundary re-sampling process is proposed. It provides only necessary re-sampled points to PSC description. In the meantime, it efficiently solves problems of boundary point correspondence, boundary normalization and boundary smoothness. This re-sampling process adopts prior knowledge of body pose structure. Comprehensive experiment is carried out on the CASIA gait database. The proposed method is shown to significantly improve performance of gait recognition under small viewing angle change without additional requirements of supervised learning, known viewing angle and multi-camera system, when compared with other methods in literatures.
6027348
Next-generation 3D visualization for visual surveillance###Existing visual surveillance systems typically require that human operators observe video streams from different cameras, which becomes infeasible if the number of observed cameras is ever increasing. In this paper, we present a new surveillance system that combines automatic video analysis (i.e., single person tracking and crowd analysis) and interactive visualization. Our novel visualization takes advantage of a high resolution display and given 3D information to focus the operator's attention to interesting/ critical areas of the observed area. This is realized by embedding the results of automatic scene analysis techniques into the visualization. By providing different visualization modes, the user can easily switch between the different modes and can select the mode which provides most information. The system is demonstrated for a real setup on a university campus.
6027297
Complementary background models for the detection of static and moving objects in crowded environments###In this paper we propose the use of complementary background models for the detection of static and moving objects in crowded video sequences. One model is devoted to accurately detect motion, while the other aims to achieve a representation of the empty scene. The differences in foreground detection of the complementary models are used to identify new static regions. A subsequent analysis of the detected regions is used to ascertain if an object was placed in or removed from the scene. Static objects are prevented from being incorporated into the empty scene model. Removed objects are rapidly dropped from both models. In this way, we build a very precise model of the empty scene and improve the foreground segmentation results of a single background model. The system was validated with several public datasets, showing many advantages over state-of-the-art static objects and foreground detectors.
6027296
Real-time person counting by propagating networks flows###In this paper we present a system that tracks multiple persons by detection in real-time. We introduce a measure for similarity of detections which segments significant information from background clutter by using statistical information obtained during the learning phase of the detector. In order to track multiple persons we map the detections into flow networks utilizing this measure. A continuous real-time processing of video streams is accomplished by analyzing only small chunks of detections consecutively using different networks. By propagating the result of one network into the subsequent one a temporal consistent association is achieved. The system was evaluated using a standard video sequence containing a crowded scene and an own dataset with very long sequences. The results demonstrate that the system performs comparable to other systems while meeting real-time requirements.
6027295
Crowd flow estimation using multiple visual features for scenes with changing crowd densities###Crowd estimation and monitoring is an important surveillance task. We address the problem of estimating the &#x201C;flow,&#x201D; that is the number of persons passing a designated region in a unit time. We designate an area of the scene as a virtual trip wire and accumulate the total number of foreground pixels (in the trip wire) over a chosen time period. We show that cumulative pixel count is related to the number of persons passing through the trip-wire by a scale factor. This scale factor is highly sensitive to the &#x201C;crowdedness&#x201D; (levels of crowd density) of the scene which creates different levels of occlusion of the individuals walking/passing through the trip-wire. We use texture features to determine the crowdedness and choose the most appropriate scaling factor. Our method does not require detection and tracking of individuals and is robust to scene dynamics, background subtraction errors, and different crowd levels.
6027294
Robust people counting in video surveillance: Dataset and system###As an important application in civilian surveillance, pedestrian counting is challenging due to the occlusion and cluttered background. In this paper, we present an efficient people counting system based on regression and template matching. This method can effectively overcome the shortcomings of pedestrian detecting and tracking-based method and feature regression-based method. At the same time, we also introduce a challenging and practical public dataset named CASIA Pedestrian Counting Dataset. It contains richly annotated video and images captured from daily surveillance scenes. Experimental results on the proposed dataset show that our counting system is robust and accurate.
6027293
Stereoscopic viewing facilitates the perception of crowds###In this study the perception of crowds was investigated in urban environment. The images of crowds were viewed non-stereoscopically and stereoscopically with HMD (head-mounted display). The task of the participants was to count the number of persons in the crowds. The results clearly indicate that stereoscopic viewing enhances perception of crowds. The counting task was determined to be easiest with stereoscopic viewing, its error rate was significantly smaller and it was significantly preferred to non-stereoscopic viewing. The viewing method did not differ statistically with respect to the completion time.
6027291
A new multi-lateral filter for real-time depth enhancement###We present an adaptive multi-lateral filter for real-time low-resolution depth map enhancement. Despite the great advantages of Time-of-Flight cameras in 3-D sensing, there are two main drawbacks that restricts their use in a wide range of applications; namely, their fairly low spatial resolution, compared to other 3-D sensing systems, and the high noise level within the depth measurements. We therefore propose a new data fusion method based upon a bilateral filter. The proposed filter is an extension the pixel weighted average strategy for depth sensor data fusion. It includes a new factor that allows to adaptively consider 2-D data or 3-D data as guidance information. Consequently, unwanted artefacts such as texture copying get almost entirely eliminated, outperforming alternative depth enhancement filters. In addition, our algorithm can be effectively and efficiently implemented for real-time applications.
6027290
Modeling of temporarily static objects for robust abandoned object detection in urban surveillance###We propose a robust approach for abandoned object detection in urban surveillance with over thousands of cameras. For such a large-scale monitoring based on intelligent video analysis, it is critical that a system be designed with careful control of false alarms. Our approach is based on proactive modeling of temporally static objects (TSO) such as cars stopping at red light and still pedestrians in the street. We develop a finite state machine to track the entire life cycles of TSOs from creation to termination. The semantically meaningful object information provided by the state machine in turn allows adaptive region-level updating of the background model without using any sophisticated object classification techniques. We demonstrate that our approach significantly mitigates the problematic issue of false alarm related to people in city surveillance, using both a small publicly available data set and a large one collected from various realistic urban scenarios.
6027356
Speeded up Gaussian Mixture Model algorithm for background subtraction###Adaptive Gaussian Mixture Models (GMM) have been one of the most popular and successful approaches to perform foreground segmentation on multimodal background scenes. However, the good accuracy of the GMM algorithm comes at a high computational cost. An improved GMM technique was proposed by Zivkovic to reduce computational cost by minimizing the number of modes adaptively. In this paper, we propose a modification to his adaptive GMM algorithm that further reduces execution time by replacing expensive floating point computations with low cost integer operations. To maintain accuracy, we derive a heuristic that computes periodic floating point updates for the GMM weight parameter using the value of an integer counter. Experiments show speedups in the range of 1.33 - 1.44 on standard video datasets where a large fraction of pixels are multimodal.
6027357
Robust background subtraction using data fusion for real elevator scene###This paper proposes a background subtraction technique robust in elevator environments. Sudden local illumination changes arise frequently in an elevator environment due to opening and closing of the elevator door as well as the inner walls of elevator being made of reflective materials. We present a novel method sequentially fusing a Gaussian mixture model for background subtraction, motion information and a spatial likelihood model based on textured features. Experimental results on real video data demonstrate effectiveness of the proposed approach.
6027354
Learning to recognize people in a smart environment###In this paper, we address the problem of online learning to recognize people from visual appearances, a prerequisite step towards building a fully intelligent and context-aware smart environment. While the trajectories of tracked individuals are responsible for producing samples to the appearance signature learning process, it is highly risky to directly label these appearance samples with tracker IDs, due to possible tracker switches and temporary tracker losses. Through the exploration of trajectory fidelity in terms of temporal continuity and spatial locality, we show that the side information from tracking, in the form of pairwise constraints, such as &#x201C;must-link&#x201D; and &#x201C;cannot-link&#x201D;, could significantly benefit signature learning. Furthermore, to learn and update an online identity signature pool, a two-step approach is proposed: 1) a data clustering step based on spectral kernel learning with pairwise constraints, and 2) a large-margin based discriminative signature model learning step. A real-world setup in a smart office environment is used to evaluate the performance of the learning paradigm. Consistent recognition of individuals from live videos verifies the efficacy and effectiveness of our proposal.
6027352
Image-based vehicle indexing for a seaport transportation surveillance system###In this paper we describe and evaluate two methods underpinning a surveillance-based content management system, designed for monitoring and profiling freight-based vehicular traffic in a seaport environment. The `InSPeCT' system captures video footage of passing vehicles, and uses tailored optical character recognition (OCR) to index the footage according to vehicle license-plates and freight codes. The system provides advanced search techniques for the efficient retrieval of records, where each captured vehicle is profiled according to captured imagery and its associated interpretations. Underpinning this system is a method for detecting the boundaries of individual transits within sustained traffic flow. Considering it desirable to extend the indexing functionality of the system beyond OCR, a colour-based vehicle indexing approach is proposed and evaluated. All evaluations take place in the context of a system deployed in a busy national seaport.
6027353
Automatic make and model recognition from frontal images of cars###We investigate a range of solutions in car `make and model' recognition. Several different feature detection approaches are investigated and applied to the problem including a new approach based on Harris corner strengths. This approach recursively partitions the image into quadrants, the feature strengths in these quadrants are then summed and locally normalised in a recursive, hierarchical fashion. Two different classification approaches are investigated; a k-nearest-neighbour classifier and a Naive Bayes classifier. Our system is able to classify vehicles with 96.0% accuracy, tested using leave-one-out cross-validation on a realistic dataset of 262 frontal images of cars.
6027299
Tracking sound sources by means of HMM###Video-based surveillance systems may benefit from the integration with microphone arrays for the localization of sound events. Applying the sound localization techniques to the surveillance of large areas requires addressing some open issues, such as the non uniform resolution of the microphones-based localization systems. This paper presents a new method for tracking moving sound events based on an Hidden Markov Model (HMM), which exploits a priori information derived from medium and longterm observations of the monitored area. The results obtained with simulated trajectories show that the HMM-based tracker is able to significantly reduce the localization error. Applications can be found in surveillance systems for large areas, such as square, streets, or parking lots, where it is of interest the monitoring of moving vehicles and people.
6027298
Multiple acoustic sources localization using incident Signal Power comparison###We present a novel approach to locate multiple acoustic sources in far-field environments, in order to solve an interesting problem in different application domain, such as: audio surveillance systems and soundscape analysis frameworks. This approach aims at finding a solution to the ambiguities in Direction Of Arrivals (DOAs) combination caused by simultaneous multiple sources. The algorithm is based on two steps: the separation of the sources by means of beamforming techniques and the comparison of the Incident Signal Power (ISP) spectrum by means of a spectral distance measure. We implemented a prototype, composed by two linear arrays, that has been successfully tested in a real noisy environment.
6027284
Combined estimation of location and body pose in surveillance video###In surveillance videos, cues such as head or body pose provide important information for analyzing people's behavior and interactions. In this paper we propose an approach that jointly estimates body location and body pose in monocular surveillance video. Our approach is based on tracks derived by multi-object tracking. First, body pose classification is conducted using sparse representation technique on each frame of the tracks, generating (noisy) observation on body poses. Then, both location and body pose in 3D space are estimated jointly in a particle filtering framework by utilizing a soft coupling of body pose with the movement. The experiments show that the proposed system successfully tracks body position and pose simultaneously in many scenarios. The output of the system can be used to perform further analysis on behaviors and interactions.
6027285
Gaze and body pose estimation from a distance###We present a comprehensive approach to track gaze by estimating location, body pose, and head pose direction of multiple individuals in unconstrained environments. The approach combines person detections from fixed cameras with directional face detections obtained from actively controlled pan tilt zoom (PTZ) cameras. The main contribution of this work is to estimate both body pose and head pose (gaze) direction independently from motion direction, using a combination of sequential Monte Carlo Filtering and MCMC sampling. There are numerous benefits in tracking body pose and gaze in surveillance. It allows to track people's focus of attention, can optimize the control of active cameras for biometric face capture, and can provide better interaction metrics between pairs of people. The availability of gaze and face detection information also improves localization and data association for tracking in crowded environments. The performance of the system will be demonstrated on data captured at a real-time surveillance site.
6027329
A real-time image-to-panorama registration approach for background subtraction using pan-tilt-cameras###While for static cameras several background subtraction approaches have been developed in the past, for non-static pan/tilt cameras efficient and robust motion detection is still a challenging task. Known approaches use image-to-image registration methods to generate a panorama background model of the scene, which spans a joint pixel coordinate system for later background estimation and subtraction. However, for a real-time panorama-based background subtraction a highly efficient image-to-panorama registration is needed. For this purpose, in this paper a key-frame representation of the panorama image is proposed and a strategy for fast global homography estimation in large panorama images is presented.
6027287
Learning to recognize faces from videos and weakly related information cues###Videos are often associated with additional information that could be valuable for interpretation of their content. This especially applies for the recognition of faces within video streams, where often cues such as transcripts and subtitles are available. However, this data is not completely reliable and might be ambiguously labeled. To overcome these limitations, we take advantage of semi-supervised (SSL) and multiple instance learning (MIL) and propose a new semi-supervised multiple instance learning (SSMIL) algorithm. Thus, during training we can weaken the prerequisite of knowing the label for each instance and can integrate unlabeled data, given only probabilistic information in form of priors. The benefits of the approach are demonstrated for face recognition in videos on a publicly available benchmark dataset. In fact, we show exploring new information sources can considerably improve the classification results.
6027323
Unsupervised learning of micro-action exemplars using a Product Manifold###This paper presents a completely unsupervised mechanism for learning micro-actions in continuous video streams. Unlike other works, our method requires no prior knowledge of an expected number of labels (classes), requires no silhouette extraction, is tolerant to minor tracking errors and jitter, and can operate at near real time speed. We show how to construct a set of training &#x201C;tracklets,&#x201D; how to cluster them using a recently introduced Product Manifold distance measure, and how to perform detection using exemplars learned from the clusters. Further, we show that the system is amenable to incremental learning as anomalous activities are detected in the video stream. We demonstrate performance using the publicly-available ETHZ Livingroom data set.
6027327
Textures of optical flow for real-time anomaly detection in crowds###Automated visual surveillance of crowds is a rapidly growing area of research. In this paper we focus on motion representation for the purpose of abnormality detection in crowded scenes. We propose a novel visual representation called textures of optical flow. The proposed representation measures the uniformity of a flow field in order to detect anomalous objects such as bicycles, vehicles and skateboarders; and can be combined with spatial information to detect other forms of abnormality. We demonstrate that the proposed approach outperforms state-of-the-art anomaly detection algorithms on a large, publicly-available dataset.
6027326
Automatic detection of dangerous motion behavior in human crowds###Tragically, mass gatherings such as music festivals, sports events or pilgrimage quite often end in terrible crowd disasters with many victims. In the past, research focused on developing physical models that model human behavior in order to simulate pedestrian flows and to identify potentially hazardous locations. However, no automatic systems for detection of dangerous motion behavior in crowds exist. In this paper, we present an automatic system for the detection and early warning of dangerous situations during mass events. It is based on optical flow computations and detects patterns of crowd motion that are characteristic for hazardous congestions. By applying an online change-point detection algorithm, the system is capable of identifying changes in pedestrian flow and thus alarms security personnel to take necessary actions.
6027325
Multi-camera open space human activity discovery for anomaly detection###We address the discovery of typical activities in video stream contents and its exploitation for estimating the abnormality levels of these streams. Such estimates can be used to select the most interesting cameras to show to a human operator. Our contributions come from the following facets: i) the method is fully unsupervised and learns the activities from long term data; ii) the method is scalable and can efficiently handle the information provided by multiple un-calibrated cameras, jointly learning activities shared by them if it happens to be the case (e.g. when they have overlapping fields of view); iii) unlike previous methods which were mainly applied to structured urban traffic scenes, we show that ours performs well on videos from a metro environment where human activities are only loosely constrained.
6027324
Learning neighborhood cooccurrence statistics of sparse features for human activity recognition###A common approach to activity recognition has been the use of histogram of codewords computed from Spatio Temporal Interest Points (STIPs). Recent methods have focused on leveraging the spatio-temporal neighborhood structure of the features, but they are generally restricted to aggregate statistics over the entire video volume, and ignore local pairwise relationships. Our goal is to capture these relations in terms of pairwise cooccurrence statistics of codewords. We show a reduction of such cooccurrence relations to the edges connecting the latent variables of a Conditional Random Field (CRF) classifier. As a consequence, we also learn the codeword dictionary as a part of the maximum likelihood learning process, with each interest point assigned a probability distribution over the codewords. We show results on two widely used activity recognition datasets.
6027338
An efficient pattern-less background modeling based on scale invariant local states###A robust and efficient background modeling algorithm is crucial to the success of most of the intelligent video surveillance systems. Compared with intensity-based approaches, texture-based background modeling approaches have shown to be more robust against dynamic backgrounds and illumination changes, which are common in real life videos. However, many of the existing texture-based methods are too computationally expensive, which renders them useless in real-time applications. In this paper, a novel efficient texture-based background modeling algorithm is presented. Scale invariant local states (SILS) are introduced as pixel features for modeling a background pixel, and a pattern-less probabilistic measurement (PLPM) is derived to estimate the probability of a pixel being background from its SILS. An adaptive background modeling framework is also introduced for learning and representing a multi-modal background model. Experimental results show that the proposed method can run nearly 3 times faster than existing state-of-the-art texture-based method, without sacrificing the output quality. This allows more time for a real-time surveillance system to carry out other computationally intensive analysis on the detected foreground objects.
6027339
Evaluation of local features for person re-identification in image sequences###In this paper we present a comparative study of local features for the task of person (re) identification. A combination of state of the art interest point detectors and descriptors is evaluated. The experiments are performed on a novel dataset which we make publicly available for future research in this area. The results indicate that there are significant differences between the evaluated descriptors, with GLOH and SIFT outperforming both Shape Context and SURF descriptors. The evaluated interest point descriptors perform equally well, with a slight advantage for the Hessian-Laplace detector. The Harris-Affine and Hessian-Affine affine invariant region detectors do not provide any performance advantage and therefore do not justify their additional computational expense.
6027330
Background subtraction by non-parametric probabilistic clustering###We present a background subtraction approach aimed at efficiency and robustness to common source of disturbance such as gradual and sudden illumination changes, camera gain and exposure variations, noise. At each new frame, a non-parametric mixture-based probabilistic clustering is performed to segment the image into changed and unchanged pixels with respect to a fixed background. A two-components mixture, a two-dimensional discrete feature space, a non-parametric model for the components likelihood and a proper initial guess are the key ingredients of this novel algorithm that, besides dealing effectively with the discrimination of photometric and semantic changes, exhibits very high computational efficiency. Experiments are presented, proving the achieved state-of-the-art robustness-efficiency trade-off.
6027331
Regularized online Mixture of Gaussians for background subtraction###Mixture of Gaussians (MoG) modelling [13] is a popular approach to background subtraction in video sequences. Although the algorithm shows good empirical performance, it lacks theoretical justification. In this paper, we give a justification for it from an online stochastic expectation maximization (EM) viewpoint and extend it to a general framework of regularized online classification EM for MoG with guaranteed convergence. By choosing a special regularization function, l<sub>1</sub> norm, we derived a new set of updating equations for l<sub>1</sub> regularized online MoG. It is shown empirically that l<sub>1</sub> regularized online MoG converge faster than the original online MoG.
6027333
People detection based on appearance and motion models###The main contribution of this paper is a new people detection algorithm based on motion information. The algorithm builds a people motion model based on the Implicit Shape Model (ISM) Framework and the MoSIFT descriptor. We also propose a detection system that integrates appearance, motion and tracking information. Experimental results over sequences extracted from the TRECVID dataset show that our new people motion detector produces results comparable to the state of the art and that the proposed multimodal fusion system improves the obtained results combining the three information sources.
6027334
Robust adapted object detection under complex environment###In this paper, we present a novel robust technique for background subtraction in different complex conditions (e.g. sudden illumination changes, swaying leaves, and camera vibrations). Unlike the previous works, the proposed method utilizes multiple point pairs that exhibit a stable statistical intensity relationship as a background model. The intensity difference between pixels of the pair is much more stable than the intensity of a single pixel, especially in varying environments. Furthermore, our proposed method focuses more on the history of global spatial correlations between pixels than on the history of any given pixel or local spatial correlations. we also adopt an adapted judgement criterion to ensure our method displays well in real-time detection. The approach has been compared with the state of the art on videos from several challenging datasets (PETS, Wallflower, and i-Lids), demonstrating that superior object detection is achieved.
6027335
A multi-stage pedestrian detection using monolithic classifiers###Despite the many efforts in finding effective feature sets or accurate classifiers for people detection, few works have addressed ways for reducing the computational burden introduced by the sliding window paradigm. This paper proposes a multi-stage procedure for refining the search for pedestrians using the HOG features and the monolithic SVM classifier. The multi-stage procedure is based on particle-based estimation of pdfs and exploits the margin provided by the classifier to draw more particles on the areas where the classifier's response is higher. This iterative algorithm achieves the same accuracy than sliding window using less particles (and thus being more efficient) and, conversely, is more accurate when configured to work at the same computational load. Experimental results on publicly available datasets demonstrate that this method, previously proposed for boosted classifiers only, can be successfully applied to monolithic classifiers.
6027336
Object detection through edge behavior modeling###The detection of moving objects depends on the accuracy of the model used to represent the background. Common pixel-based and naive edge-based approaches have many drawbacks in dynamic environments, e.g., false detections with noise. We propose a novel background model that encodes the background as edges, building a statistical distribution per segment that represents the edge behavior. We build the background distributions using a kernel-based approach; the moving objects are detected as the edges that deviate from the distributions. The method does adaptive thresholding to the edges, which maintains their shape and boosts the detection accuracy. Sets of gradient distributions are incorporated into the model, to determine edges that lie within the distributions, but are moving edges. The number of distributions is handled dynamically, allowing them to increase and decrease accordingly to the situation. The experiments show that the proposed method improves the detection rates, due to its robustness against illumination changes.
6027337
Fast face detection and species classification of African great apes###Decline of biodiversity has become a serious problem on a global scale. Therefore environmental groups try to protect the endangered species populations. To this end, autonomous video traps are powerful instruments to monitor population sizes in the wild. These systems are used increasingly, however manually analyzing the huge amount of data gathered by video traps is taking a lot of time. Therefore automatic video analysis systems are in great demand. In this paper we show that technology developed for human face detection and analysis can successfully be applied to African great apes. We describe the algorithms and demonstrate the performance of the system using the example of chimpanzee and gorilla faces. Moreover we depict two different methods for species classification and compare the capabilities to distinguish between both species.
6027381
Improved person detection in industrial environments using multiple self-calibrated cameras###Person detection is a challenging task in industrial environments which typically feature rapidly changing conditions of illumination and the presence of occluding objects and cluttered background. This paper proposes a series of algorithms for improving the robustness of person detection in such harsh industrial environments. Based on a state-of-the-art person detector, significant robustness and automation is achieved by introducing automatic ground plane estimation, confidence filtering, cross-camera correspondence estimation and multi-camera fusion. Detailed experiments made on an industrial dataset that captures an automotive assembly process show the stepwise improvement when combining the above mentioned techniques in a fully unsupervised manner.
6027380
Multi-camera detection association for 3D localisation###A multi-camera system is described for 3-D localisation of subjects within a confined space. In particular, we present a novel neighbourhood association algorithm to solve the problem of associating detections in multiple camera views with subjects. To evaluate our approach, experiments were conducted using multiple view video sequences of up to four subjects simulating typical passenger behaviour on a bus. ROC curves were generated for three different versions which showed that for smaller values of the neighbourhood radius parameter, the system tended to over-estimate the number of subjects. However, increasing the radius reduced the over-estimation from 60% to 5%.
6027383
HSV and RGB color histograms comparing for objects tracking among non overlapping FOVs, using CBTF###Object tracking over wide-areas, such as an airport, the downtown of a large city or any large public area, is done by multiple cameras. Especially in realistic application, those cameras have non overlapping Field of Views (FOVs). Multiple camera tracking is very important to establish correspondence among detected objects across different cameras. In this paper we investigate color histogram techniques to evaluate inter-camera tracking algorithm based on object appearances. We compute HSV and RGB color histograms in order to evaluate their performance in establishing correspondence between object appearances in different FOVs before and after Cumulative Brightness Transfer Function (CBTF).
6027382
Multiple views based human motion tracking in surveillance videos###Most work on activity recognition focuses on 2D image properties, holistic spatiotemporal representations, or space-time shapes in image domain rather than with 3D pose in a body-centric or world frame. Such techniques rely on advanced pattern recognition algorithms and interpreting complex behavioral patterns. In this work we posit that it is possible to achieve 3D pose tracking using videos recorded in multi-camera surveillance systems. We show experimental results that were obtained on PETS 2009 datasets. The estimation of the 3D articulated motion is achieved using a modified particle swarm optimization.
6027305
Modeling of moving object trajectory by spatio-temporal learning for abnormal behavior detection###This paper proposes a trajectory analysis method by handling the spatio-temporal property of trajectory. Not using similarity measures of two trajectories, our model analyzes overall path of a trajectory. Learning of spatio property is presented as semantic regions (e.g. go straight, turn left, turn right) that are clustered effectively using topic model. The temporal order of observations on a trajectory is taken into account using HMM for detecting global anomaly. Results of experiments show that modeling of semantic region and detecting of unusual trajectories are successful even in complex scenes.
6027304
Detection of abnormal behaviour in a surveillance environment using control charts###This paper introduces a new approach to unsupervised detection of abnormal sequences of images in video surveillance data. We leverage an online object detection method and statistical process control techniques in order to identify suspicious sequences of events. Our method assumes a training phase in which the spatial distribution of objects is learned, followed by a chart-based tracking process. We evaluate the performance of our method on a standard dataset and have implemented a publicly available open-source prototype.
6027307
An improved Mean Shift tracker with fast failure recovery strategy after complete occlusion###The effectiveness of the conventional Mean Shift tracking algorithm diminishes for fast moving targets and complete occlusion. In this paper an improved Mean Shift algorithm comprising a fast failure recovery strategy that aims to deal with randomly moving targets and complete occlusion as encountered in crowded scenes is presented. Experimental results show that after complete occlusion or target loss, the new algorithm can effectively recover and continue to successfully track targets in complex scenarios.
6027306
Abnormal events detection using unsupervised One-Class SVM - Application to audio surveillance and evaluation -###This paper proposes an unsupervised method for real time detection of abnormal events in the context of audio surveillance. Based on training a One-Class Support Vector Machine (OC-SVM) to model the distribution of the normality (ambience), we propose to construct sets of decision functions. This modification allows controlling the trade-off between false-alarm and miss probabilities without modifying the trained OC-SVM that best capture the ambience boundaries, or its hyperparameters. Then we present an adaptive online scheme of temporal integration of the decision function output in order to increase performance and robustness. We also introduce a framework to generate databases based on real signals for the evaluation of audio surveillance systems. Finally, we present the performances obtained on the generated database.
6027301
Mono versus Multi-view tracking-based model for automatic scene activity modeling and anomaly detection###In this paper, we present a novel method able to automatically discover recurrent activities occurring in a video scene, and to identify the temporal relations between these activities, which can be used either in mono-view or in multi-view context (for example, to discover the different flows of passengers inside a subway station and identify the rules that govern these flows). The proposed method is based on particle-based trajectories, analyzed through a cascade of HMM and HDP-HMM models. We experiment our model for scene activity recognition task on a subway dataset using both mono-view and multi-view analysis. We last show that our model is also able to perform on the fly and in real-time abnormal events detection (by identifying activities or relations that do not fit in the usual/learnt ones).
6027300
Hierarchical approach for abnormal acoustic event classification in an elevator###In this paper, we propose a hierarchical method to detect and classify abnormal acoustic events occurring in an elevator environment. The Gaussian Mixture Model (GMM) based event classifier essentially employs two types of acoustic features; Mel Frequency Cepstral Coefficient (MFCC) and Timbre. We explore the effectiveness of various combinations of the two features in terms of classification performance. In addition, we design a hierarchical approach for realizing acoustic event classification and compare it with a single-level approach. It can be verified from an experiment, that the classification performance is improved when the proposed hierarchical approach is applied. In particular, for detection of abnormal situations, we employ a maximum likelihood estimation approach for acoustic event recognition at the 1<sup>st</sup> step, and then on the 2<sup>nd</sup> step we determine the abnormal contexts by using the ratio of abnormal events to cumulative events during a certain period. For performance evaluation, we employ a database collected in an actual elevator under several scenarios. By experimental results, our proposed method demonstrates 91% correct detection rate and 2.5% error detection rate for abnormal context.
6027303
Action recognition using tri-view constraints###Two-view methods have been well developed to identify human actions. However, in a case where the corresponding imaged points cannot induce distinguished measures, the performance of the methods deteriorates. For this reason, we propose a new view-invariant measure for human action recognition by enforcing tri-view constraints in this paper. We apply our approach to video synchronization by imposing both the similarity ratio and the consistency in the trifocal tensor over entire video sequences. By testing on both synthetic and real data, our method has achieved higher tolerance to noise levels, as well as higher identification accuracy than the traditional two-view method. Experimental results demonstrate that our approach can identify human pose transitions, despite of dynamic time-lines, different viewpoints, and unknown camera parameters.
6027302
Discrimination of abandoned and stolen object based on active contours###In this paper we propose an approach based on active contours to discriminate previously detected static foreground regions between abandoned and stolen. Firstly, the static foreground object contour is extracted. Then, an active contour adjustment is performed on the current and the background frames. Finally, similarities between the initial contour and the two adjustments are studied to decide whether the object is abandoned or stolen. Three different methods have been tested for this adjustment. Experimental results over a heterogeneous dataset show that the proposed method outperforms state-of-art approaches and provides a robust solution against non-accurate data (i.e., foreground static objects wrongly segmented) that is common in complex scenarios.
6027395
AVSS2011 demo session: Abstract of PRIMA-S for AVSS-Demo 2011###The Demo from Funkwerk plettac shows an innovative system for masking of privacy zones in video surveillance systems in order to meet the requirements of data privacy, especially in public areas.
6027309
Appearance tracking by transduction in surveillance scenarios###We propose a formulation of people tracking problem as a Transductive Learning (TL) problem. TL is an effective semi-supervised learning technique by which many classification problems have been recently reinterpreted as learning labels from incomplete datasets. In our proposal the joint exploitation of spectral graph theory and Riemannian manifold learning tools leads to the formulation of a robust approach for appearance based tracking in Video Surveillance scenarios. The key advantage of the presented method is a continuously updated model of the tracked target, used in the TL process, that allows to on-line learn the target visual appearance and consequently to improve the tracker accuracy. Experiments on public datasets show an encouraging advancement over alternative state-of the-art techniques.
6027308
Extended feature-based object tracking in presence of data association uncertainty###This paper proposes and algorithm for extended object tracking using sparse feature points. The described technique is based on the Rao-Blackwellized Particle Filter. In particular, two different data association techniques that take into consideration clutter and missed detections, are coupled and tested in order to provide a comparison of their performance for the problem of extended object tracking.
6027398
AVSS2011 demo session: GPU enabled Smart Video Node###This paper presents an All-in-One video analytics system, a compact, multi-channel, real-time, video monitoring, event detection, alarm notification, event recording and browsing solution implemented on low cost hardware, taking advantage of NVIDIA's GPU CUDA platform. An inventive distribution of video object detection and tracking processing chain between the GPUs and the CPU provides maximum efficiency at the lowest cost.
6027399
AVSS 2011 demo session: Interactive person-retrieval in a distributed camera network###Tracking and identifying persons in videos are important building blocks in many applications. For interactive investigation of surveillance footage it is often not even necessary to uniquely identify a person. It rather suffices to find occurrences of a person indicated by the user with an exemplary image sequence. We present a system in which the search for a specific person can be initiated by a sample image sequence and then be further refined by interactive feedback by the operator. The demonstrated system will track people online in multiple cameras and make the sequences immediately searchable from a central station.
6027393
AVSS2011 demo session: Real-time human detection using fast contour template matching for visual surveillance###Achieving accurate pedestrian detection for practically relevant scenarios in real-time is an important problem for many applications, while representing a major scientific challenge at the same time. We present a human detection framework which efficiently computes pedestrian-specific shape and motion cues and combines them in a probabilistic manner to infer the location and occlusion status of pedestrians viewed by a stationary camera. The articulated pedestrian shape is represented by a set of sparse contour templates, where fast template matching against image features is carried out using integral images built along oriented scan-lines. The motion cue is obtained by employing a non-parametric background model using the YCbCr color space. Given the probabilistic output from the two cues the spatial configuration of hypothesized human body locations is obtained by an iterative optimization scheme taking into account the depth ordering and occlusion status of individual hypotheses. The method achieves fast computation times even in complex scenarios with a high pedestrian density. The framework and the validity of the approach will be demonstrated on various datasets with different scene complexity, such as pedestrian density and illumination conditions.
6027390
Traffic video detection: A manufacturers' point of view###In this presentation an overview of traffic video detection will be given from the point of view of a manufacturer. Founded in 1992 Traficon is today one of the leading companies in the world for traffic video detection. The history and the current markets of Traficon are shortly presented together with some key reference projects. Next some new market and technology trends are presented and how Traficon responds to these. As a high tech company playing in a highly dynamic technology landscape it is essential to create strategic alliances with research institutes and other companies. This requires the right mind set, the need for formal ways of cooperating, the awareness that product quality is key and last but not least a good nose for market trends. Some of these aspects will be highlighted. Finally it will be explained how Traficon is dealing with this.
6027391
A high-way operator's view on automated video surveillance###Start-ups offering computer vision solutions in the field of surveillance typically suffer under a short half-life - while Infrastructure operators regularly complain about high false-alarm rates and other limitations of practical usage. These phenomena are obviously related to the technological difficulties on the one hand, the reasonable sized gap between &#x201C;applied research&#x201D; and application on the other hand contributes as well. After giving a short overview of the ASFINAG Video-System in general, the major challenges for traffic surveillance related to &#x201C;automated video analysis&#x201D; are discussed. The list of challenges is in a very subjective manner compared to statements from the scientific community and the state-of-the-art. This analysis leads to a brief description of the gap between application of computer vision for infrastructure operators and &#x201C;applied&#x201D; research within this field. Some of the major points out of this gap will be highlighted, like application-oriented testing, input quality measure, the importance of operator-friendly false-alarm rates, set-up effort for calibration, &#x2026; Finally, a few thoughts are presented, which might increase the chances for a fruitful transmission of scientific results into real world applications.
6027396
AVSS 2011 demo session: A systems level approach to perimeter protection###The primary technical goal of this work is the development of a comprehensive approach to perimeter protection for critical infrastructure and industrial sites. The approach taken is to combine both video and non-video sensors so as to produce a real-time system capable of tracking objects of interest and of detecting potential events that may warrant the attention of security officials. A summary of the system architecture is shown in Figure 1. System modules include: &#x2022; The ability to detect and track people using both visual and radar based sensors. &#x2022; The detection of articulated motions as well as complex and abnormal events. &#x2022; The application of object recognition to detected left behind objects.
6027397
AVSS 2011 demo session###IEE has developed a vision sensor based on 3D MLI Sensor&#x2122; technology. This sensor is the basis for a number of people and object sensing solutions aimed at enhancing building safety, security and management. This paper provides details about the nature of the technology, as well as the challenges faced by building and security professionals to solve safety issues, and how the sensor aids in facing those challenges.
6027394
AVSS 2011 demo session: People flow analysis###Based on a unique video stream analysis and combined with the Sony Smartcamera architecture, Blue Eye Video stand alone solution is able to determine how many persons are waiting in a queue, the customer behaviour when moving in a department store, airports, theatre or stadium.
6027289
Data driven frequency mapping for computationally scalable object detection###Nonlinear kernel Support Vector Machines achieve better generalizations, yet their training and evaluation speeds are prohibitively slow for real-time object detection tasks where the number of data points in training and the number of hypotheses to be tested in evaluation are in the order of millions. To accelerate the training and particularly testing of such nonlinear kernel machines, we map the input data onto a low-dimensional spectral (Fourier) feature space using a cosine transform, design a kernel that approximates the classification objective in a supervised setting, and apply a fast linear classifier instead of the conventional radial basis functions. We present a data driven hypotheses generation technique and a LogistBoost feature selection. Our experimental results demonstrate the computational improvements 20~100&#x00D7; while maintaining a high classification accuracy in comparison to SVM linear and radial kernel basis function classifiers.
6027312
Continuous recovery for real time pan tilt zoom localization and mapping###We propose a method for real time recovering from tracking failure in monocular localization and mapping with a Pan Tilt Zoom camera (PTZ). The method automatically detects and seamlessly recovers from tracking failure while preserving map integrity. By extending recent advances in the PTZ localization and mapping, the system can quickly and continuously resume tracking failures by determining the best way to task two different localization modalities. The tradeoff involved when choosing between the two modalities is captured by maximizing the information expected to be extracted from the scene map. This is especially helpful in four main viewing condition: blurred frames, weak textured scene, not up to date map and occlusions due to sensor quantization or moving objects. Extensive tests show that the resulting system is able to recover from several different failures while zooming-in weak textured scene, all in real time.
6027313
A unified rectification method for single viewpoint multi-camera system###Stereo matching and 3D reconstruction has been studied for decades as a fundamental problem in the field of computer vision. Recent years, stereo matching and 3D reconstruction with a large field of view, especially using omnidirectional vision and panoramic images, have received increasing attention. As a pre-step for dense stereo matching, methods are proposed to rectify different kinds of omnidirectional stereo image pairs. However, no one has described a rectification method applied to multi-camera omnidirectional systems yet. In this work, we proposed a rectification algorithm based on spherical camera model for rectifying omnidirectional stereo pairs, especially well suitable for the multi-camera omnidirectional systems as long as a spherical camera model is able to be applied. We describe the geometrical framework of the algorithm and implement it. Also we present the experimental results of the real stereo image pairs captured by Ladybug3. As the experimental results show, the effect of rectification is promising.
6027310
Real time color based particle filtering for object tracking with dual cache architecture###Particle filtering framework is widely used on tracking applications. In surveillance systems, it often combines with color information to achieve visual object tracking. However, the resource usage of this framework, including memory bandwidth and operation cycles, is very intensive to make a low cost real time object tracking unattainable. In this paper, an efficient architecture of color based particle filtering tracking with dual cache is proposed. It utilizes a frame cache to reduce memory bandwidth of loading frame data, and a histogram cache to reduce operation cycles when constructing color histogram. The experimental results show that this architecture can improve the performance to real time on a high system specification.
6027311
Multi-tasking smart cameras for intelligent video surveillance systems###We demonstrate a video surveillance system- comprising passive and active pan/tilt/zoom (PTZ) cameras-that intelligently responds to scene complexity, automatically capturing higher resolution video when there are fewer people in the scene and capturing lower resolution video as the number of pedestrians present in the scene increases. To this end, we have developed behavior based-controllers for passive and active cameras, enabling these cameras to carry out multiple observation tasks simultaneously. The research presented herein is a step towards video surveillance systems-consisting of a heterogeneous set of sensors-that provide persistent coverage of large spaces, while optimizing surveillance data collection by tuning the sensing parameters of individual sensors (in a distributed manner) in response to scene activity.
6027316
Multiple-shot human re-identification by Mean Riemannian Covariance Grid###Human re-identification is defined as a requirement to determine whether a given individual has already appeared over a network of cameras. This problem is particularly hard by significant appearance changes across different camera views. In order to re-identify people a human signature should handle difference in illumination, pose and camera parameters. We propose a new appearance model combining information from multiple images to obtain highly discriminative human signature, called Mean Riemannian Covariance Grid (MRCG). The method is evaluated and compared with the state of the art using benchmark video sequences from the ETHZ and the i-LIDS datasets. We demonstrate that the proposed approach outperforms state of the art methods. Finally, the results of our approach are shown on two other more pertinent datasets.
6027317
Multiple view, multiple target tracking with principal axis-based data association###We present a novel method for multi-object tracking that tracks target both in the video streams and in a reference ground frame. This allows to remove ambiguities created by occlusions in one view. Our system takes as a base a recently proposed collaborative scheme and makes it handle multiple targets. We use a fast, simple solution for data association in the ground plane based on principal axis and a partly joint probabilistic model with MCMC sampling to ensure that tracked targets are kept separated whenever groups of targets appear. Results are presented on several popular databases of multi-camera, multi-target videos.
6027314
Efficiently secure image transmission against tampering in wireless visual sensor networks###Wireless visual sensor networks for surveillance can dissipate their limited resources to process irrelevant images maliciously injected by compromised nodes. In particular, since nodes compromised by tampering reveal their security keys to encrypt messages, traditional data authentication techniques cannot identify false data deceivably encrypted by such stolen keys. To challenge this problem, this paper first presents a surveillance-fitted network model where our false data sensitive protocol efficiently works. The protocol allows malicious messages to travel only one hop by authentically and semantically testing every packet and every image sent from wireless cameras vulnerable to tampering. We additionally suggest a dynamic key scheme which lets wireless sensors employ a different key in each communication for reasonable resource consumption, in order to reduce a possibility of key disclosure itself. Two lemmas and three comparison results verify how well our three approaches outperform their alternatives in resiliency to compromised nodes and memory, computation and communication overheads.
6027318
Formulation, detection and application of occlusion states (Oc-7) in the context of multiple object tracking###Occlusion is often thought of as a challenge for visual algorithms, specially tracking. Existing literature, however, has identified a number of occlusion categories in the context of tracking in ad hoc manner. We propose a systematic approach to formulate a set of occlusion cases by considering the spatial relations among object support(s) (projections on the image plane) with the detected foreground blob(s), to show that only 7 occlusion states are possible. We designate the resulting qualitative formalism as Oc-7, and show how these occlusion states can be detected and used effectively for the task of multi-object tracking under occlusion of various types. The object support is decomposed into overlapping patches which are tracked independently on the occurrence of occlusions. As a demonstration of the application of these occlusion states, we propose a reasoning scheme for selective tracker execution and object feature updates to track multiple objects in complex environments.
6027319
View-invariant person re-identification with an Implicit Shape Model###In this paper, we approach the task of appearance based person re-identification for scenarios where no biometric features can be used. For that, we build on a person re-identification approach that uses the Implicit Shape Model (ISM) and SIFT features for re-identification. This approach builds identity models of persons during tracking and employs these models for re-identification. We apply this re-identification, which was until now only evaluated in the infrared spectrum, to data acquired in the visible spectrum. Furthermore we evaluate view independence of the re-identification approach and introduce methods that extend view invariance. Specifically, we (i) propose a method for online view-determination of a tracked person, (ii) use the online view-determination to generate view specific identity models of persons which increase model distinctiveness in re-identification, and (iii) introduce a method to convert identity models between views to increase view independence.
6027402
AVSS 2011 demo session: Construction site monitoring from highly-overlapping MAV images###We present a concept for automatic construction site monitoring by taking into account 4D information (3D over time), that is acquired from highly-overlapping digital aerial images. On the one hand today's maturity of flying micro aerial vehicles (MAVs) enables a low-cost and an efficient image acquisition of high-quality data that maps construction sites entirely from many varying viewpoints. On the other hand, due to low-noise sensors and high redundancy in the image data, recent developments in 3D reconstruction workflows have benefited the automatic computation of accurate and dense 3D scene information. Having both an inexpensive high-quality image acquisition and an efficient 3D analysis workflow enables monitoring, documentation and visualization of observed sites over time with short intervals. Relating acquired 4D site observations, composed of color, texture, geometry over time, largely supports automated methods toward full scene understanding, the acquisition of both the change and the construction site's progress.
6027403
AVSS 2011 demo session: OUTLIER - online learning and visualization of unusual events###Unusual event detection, i.e., identifying (previously unseen) rare/critical events, has become one of the major challenges in visual surveillance. The main solution for this problem is to describe local or global normalness and to report events that do not fit to the estimated models. The majority of existing approaches, however, is limited to a single description (e.g., appearance or motion) and/or builds on inflexible (unsupervised) learning techniques, both clearly degrading the practical applicability. To overcome these limitations, we demonstrate a system that, on the one hand is capable of extracting and modeling several representations in parallel and, on the other hand, allows for user interaction within a continuous learning setup. Novel yet intuitive concepts of result visualization and user interaction will be presented that allow for exploiting the underlying data.
6027400
AVSS 2011 demo session: A large-scale benchmark dataset for event recognition in surveillance video###We introduce to the surveillance community the VIRAT Video Dataset[1], which is a new large-scale surveillance video dataset designed to assess the performance of event recognition algorithms in realistic scenes<sup>1</sup>.
6027401
AVSS 2011 demo session: Smart Resource-Aware Multi-Sensor Network###The Interreg IV project &#x201C;Smart Resource-Aware Multi-Sensor Network (SRSnet)&#x201D;<sup>1</sup> is coordinated, managed and disseminated by Lakeside Labs GmbH. The project is planned for three years and focuses on the design of a smart resource-aware multi-sensor network capable of autonomously detecting and localizing various events such as screams animal noise, tracks of persons and more complex human behaviours. The project's research areas include (i) collaborative audio and video analysis, (ii) complex event detection and (iii) network reconfiguration. The SRSnet will be demonstrated in a biologically sensitive environmental, namely in the Nationalpark Hohe Tauern.
6027406
Pedestrian sensing for increased traffic safety and efficiency at signalized intersections###The control of signalized intersection plays an important role in the safety and efficiency of urban traffic. The last decades a lot of resources were spent on ITS for the detection of vehicles at traffic lights. Today not only the efficiency of traffic is of interest but also the safety of pedestrians is becoming a priority. To respond to this need two new traffic video sensors are proposed specifically designed for the detection of pedestrians in an urban setting.
6027407
AVSS 2011 demo session: Level of service classification for smart cameras###At the Industrial Surveillance Day, ASFINAG and the Alpen Adria Universitt Klagenfurt (in particular the Institute of Information Technology and the Institute of Networked and Embedded Systems) demonstrate a show case of their video-based level of service (LOS) classification for smart cameras. This LOS classification system has been developed in a joint Lakeside Labs project in Klagenfurt, Austria. It is part of a case study which aims at improving the quality of traffic messages for the two particular traffic situations level-of-service (LOS) and weather-related road conditions (WRRC) on two dedicated test tracks on Austrian motorways. Using a live connection to a smart camera at one of these test tracks, we plan to show a live demonstration for visual speed estimation and LOS classification. This demo is coordinated with our partner SLR Engineering, which provided the smart cameras for the case study.
6027404
AVSS 2011 demo session: Intelligent crossing sensor and vehicle detector###The aim of the iCS system is to detect and record footages of possibly hazardous situations on a pedestrian crossing and/or conduct real-time traffic surveillance. Videos recorded by cameras could be used for enforcement purposes or as evidence in case of an accident. Information about the traffic could be used for statistic purposes and thus help to improve road infrastructure planning and traffic flow. The system contains two Smart Cameras. The first one detects pedestrians which are on or close to the pedestrian crossing, the second one detects and tracks vehicles approaching the the crossing, additionally the vehicle's numberplate is detected and recognized. Based on vehicle's position, direction and velocity and pedestrian's position the system decides if the situation is hazardous or not. If so both cameras start to record beginning with several seconds before the decision (using an image ring buffer).
6027405
VTrack: Video analytics for automatic video-surveillance###TechnoAware research and develops technologies and solutions for ambient intelligence. Established in 2003 TechnoAware was born from the experiences and competencies of the ISIP40 research group of the University of Genova. This research group is studying and implementing video analytics algorithms since 1985 and is considered nowadays one of the major actors in this filed worldwide. Entirely made up by researchers and experts in the video analytics field, TechnoAware main principles are: proprietary technologies (highly customizable and modular solutions), scientific competencies (high quality level and performances), continuous research and technological innovation (cutting edge products).
6027366
Multi-agent system for moving object segmentation and tracking###Video segmentation and tracking have been important and challenging issues for many video processing. A novel spatio-temporal video object segmentation and tracking algorithm is proposed in this paper. This algorithm is based on multi-agent system and active contour technique. The multi-agent system is composed of a set of supervisor and explorator agents. The agents are communicating and inspired in their conduct from active contour technique, more precisely the &#x201C;Level Sets&#x201D;. We used the DIMA platform to implement this algorithm. Experimental results indicate that the proposed algorithm is more robust than previous approaches.
6027365
On building decentralized wide-area surveillance networks based on ONVIF###In this paper we present a decentralized surveillance network composed of IP video cameras, analysis devices and a central node which collects information and displays it in a 3D model of the complete area. The exchange of information between all components in the surveillance network takes place according to the ONVIF specification, therefore ensuring interoperability between products complying with the specification and flexibility regarding the integration of new devices and services. The collected information is displayed in a 3D model of the surveilled area, therefore providing a comfortable overview of the activity in large environments and offering the user an intuitive way to eventually interact with network devices.
6027364
A robust approach for on-line and off-line threat detection based on event tree similarity analysis###The security of railway and mass-transit systems is increasingly dependant on the effectiveness of integrated Security Management Systems (SMS), which are meant to detect threats and to provide operators with information required for alarm verification purposes. In order to lower the false alarm rate and improve the detection reliability of threat scenarios, event correlation capabilities need to be integrated into the SMS. In this paper an existing approach based on a-priori defined event patterns is extended using a heuristic situation recognition approach which is more robust to both imperfect scenario modeling (human faults) and missed detections (sensor faults). The approach is based on similarity analysis between the event trees representing scenarios and it is effective both on-line and off-line. Applied on-line, it allows for an earlier and more fault-tolerant threat detection, since scenario matching is not required to be complete nor exact. Applied off-line, its effectiveness is twofold: first, it allows for detecting redundancies when updating the scenario repository; secondly, it enhances the post-event forensic search of suspicious behaviors not previously stored in the scenario repository. The strategy is being experimented in the context of railway protection.
6027363
Optimizing Mean Reciprocal Rank for person re-identification###Person re-identification is one of the most challenging issues in network-based surveillance. The difficulties mainly come from the great appearance variations induced by illumination, camera view and body pose changes. Maybe influenced by the research on face recognition and general object recognition, this problem is habitually treated as a verification or classification problem, and much effort has been put on optimizing standard recognition criteria. However, we found that in practical applications the users usually have different expectations. For example, in a real surveillance system, we may expect that a visual user interface can show us the relevant images in the first few (e.g. 20) candidates, but not necessarily before all the irrelevant ones. In other words, there is no problem to leave the final judgement to the users. Based on such an observation, this paper treats the re-identification problem as a ranking problem and directly optimizes a listwise ranking function named Mean Reciprocal Rank (MRR), which is considered by us to be able to generate results closest to human expectations. Using a maximum-margin based structured learning model, we are able to show improved re-identification results on widely-used benchmark datasets.
6027362
Smart resource-aware multimedia sensor network for automatic detection of complex events###This paper presents a smart resource-aware multimedia sensor network. We illustrate a surveillance system which supports human operators, by automatically detecting the complex events and giving the possibility to recall the detected events and searching them in an intelligent search engine. Four subsystems have been implemented, the tracking and detection system, the network configuration system, the reasoning system and an advanced archiving system in an annotated multimedia database.
6027369
Dynamic resource allocation for probabilistic tracking via attentive sensing and sampling###In the context of Ambient Intelligence a fundamental challenge is the design of monitoring technologies able to infer activities of people at-a-distance, employing non-intrusive sensors. Ideally, such solutions should operate in real time using minimal resources and scale to environments with complex topologies. These requirements naturally emerge in application domains such as Security &amp; Surveillance, Ambient Assisted Living, Retail Monitoring, etc., and new research challenges are to be faced to push current state-of-the-art towards meeting them. In line with this trend, our recent efforts detailed in this paper focus on some of the limitations of traditional multi-camera based tracking methods arising in this context, which are characterized by passive sensing and limited adaptation.
5597128
Learning Dense Optical-Flow Trajectory Patterns for Video Object Extraction###We proposes an unsupervised method to address video object extraction (VOE) in uncontrolled videos, i.e. videos captured by low-resolution and freely moving cameras. We advocate the use of dense optical-flow trajectories (DOTs), which are obtained by propagating the optical flow information at the pixel level. Therefore, no interest point extraction is required in our framework. To integrate color and and shape information of moving objects, we group the DOTs at the super-pixel level to extract co-motion regions, and use the associated pyramid histogram of oriented gradients (PHOG) descriptors to extract objects of interest across video frames. Our approach for VOE is easy to implement, and the use of DOTs for both motion segmentation and object tracking is more robust than existing trajectory-based methods. Experiments on several video sequences exhibit the feasibility of our proposed VOE framework.
5597097
Real-Time 3D Human Pose Estimation from Monocular View with Applications to Event Detection and Video Gaming###We present an effective real-time approach for automatically estimating 3D human body poses from monocular video sequences. In this approach, human body is automatically detected from video sequence, then image features such as silhouette, edge and color are extracted and integrated to infer 3D human poses by iteratively minimizing the cost function defined between 2D features derived from the projected 3D model and those extracted from video sequence. In addition, 2D locations of head, hands, and feet are tracked to facilitate 3D tracking. When tracking failure happens, the approach can detect and recover from failures quickly. Finally, the efficiency and robustness of the proposed approach is shown in two real applications: human event detection and video gaming.
5597094
Simultaneous Object Recognition and Localization in Image Collections###This papers presents a weakly supervised method to simultaneously address object localization and recognition problems. Unlike prior work using exhaustive search methods such as sliding windows, we propose to learn category and image-specific visual words in image collections by extracting discriminating feature information via two different types of support vector machines: the standard L2-regularized L1-loss SVM, and the one with L1 regularization and L2 loss. The selected visual words are used to construct visual attention maps, which provide descriptive information for each object category. To preserve local spatial information, we further refine these maps by Gaussian smoothing and cross bilateral filtering, and thus both appearance and spatial information can be utilized for visual categorization applications. Our method is not limited to any specific type of image descriptors, or any particular codebook learning and feature encoding techniques. In this paper, we conduct preliminary experiments on a subset of the Caltech-256 dataset using bag-of-feature (BOF) models with SIFT descriptors. We show that the use of our visual attention maps improves the recognition performance, while the one selected by L1-regularized L2-loss SVMs exhibits the best recognition and localization results.
5597095
Local Directional Pattern (LDP) &#150; A Robust Image Descriptor for Object Recognition###This paper presents a novel local feature descriptor, the Local Directional Pattern (LDP), for describing local image feature. A LDP feature is obtained by computing the edge response values in all eight directions at each pixel position and generating a code from the relative strength magnitude. Each bit of code sequence is determined by considering a local neighborhood hence becomes robust in noisy situation. A rotation invariant LDP code is also introduced which uses the direction of the most prominent edge response. Finally an image descriptor is formed to describe the image (or image region) by accumulating the occurrence of LDP feature over the whole input image (or image region). Experimental results on the Brodatz texture database show that LDP impressively outperforms the other commonly used dense descriptors (e.g.,Gabor-wavelet and LBP).
5597092
Exploiting Geometric Restrictions in a PTZ Camera for Finding Point-orrespondences Between Configurations###A pan-tilt-zoom (PTZ) camera, fixed in location, may perform only rotational movements. There is a class of feature-based self-calibration approaches that exploit the restrictions on the camera motion in order to obtain accurate point-correspondences between two configurations of a PTZ camera. Most of these approaches require extensive computation and yet do not guarantee a satisfactory result. In this paper, we approach this problem from a different perspective. We exploit the geometric restrictions on the image planes, which are imposed by the motion restrictions on the camera. We present a simple method for estimating the camera focal length and finding the point-correspondences between two camera configurations. We compute pan-only, tilt-only and zoom-only correspondences and then combine the three to derive the geometrical relationship between any two camera configurations. We perform radial lens distortion estimation in order to calibrate distorted image coordinates. Our purely geometric approach does not require any intensive computations, feature tracking or training. However, our point-correspondence experiments show that, it still performs well-enough for most computer vision applications of PTZ cameras.
5597340
Person Re-identification Using Haar-based and DCD-based Signature###In many surveillance systems there is a requirement to determine whether a given person of interest has already been observed over a network of cameras. This paper presents two approaches for this person re-identification problem. In general the human appearance obtained in one camera is usually different from the ones obtained in another camera. In order to re-identify people the human signature should handle difference in illumination, pose and camera parameters. Our appearance models are based on hoar-like features and dominant color descriptors. The AdaBoost scheme is applied to both descriptors to achieve the most invariant and discriminative signature. The methods are evaluated using benchmark video sequences with different camera views where people are automatically detected using Histograms of Oriented Gradients (HOG). The reidentification performance is presented using the cumulative matching characteristic (CMC) curve.
5597090
Occlusion-Aided Weights for Local Stereo Matching###Recently, local stereo matching has experienced large progress by the introduction of adaptive support-weights. In this paper, we aim at eliminating negative effects of occlusions by proposing an occlusion-based method to improve traditional support weights. Weights of occluded points are greatly reduced while computing matching costs, initial disparities and final disparities. Experimental results on the Middlebury images demonstrate that our method is very effective in improving disparities of points around occluded areas and depth discontinuities. According to the Middlebury benchmark, the proposed algorithm is now the top performer among local stereo methods. Moreover, this approach can be easily integrated into nearly all existing support weights strategies.
5597091
Automatic Inter-image Homography Estimation from Person Detections###Inter-image homographies are essential for many different tasks involving projective geometry. This paper proposes an adaptive correspondence estimation approach between person detections in a planar scene not relying on correspondence features as it is the case in many other RANSAC-based approaches. The result is a planar inter-image homography calculated from estimated point correspondences. The approach is self-configurable, adaptive and provides robustness over time by exploiting temporal and geometric information. We demonstrate the manifold applicability of the proposed approach on a variety of datasets. Improved results compared to a common baseline approach are shown and the influence of error sources such as missed detections, false detections and non overlapping field of views is investigated.
5597074
An Authentication Mechanism Using Chinese Remainder Theorem for Efficient Surveillance Video Transmission###Now-a-days, surveillance cameras have been widely deployed in various security applications. In many surveillance applications, the background changes very slowly and the foreground objects occupy only a relatively small portion of a video frame. In these type of applications, an efficient solution for transmissions over bandwidth-limited networks is to send only the foreground objects for every frame in real time while the background is sent occasionally. At the receiving end of the transmission, the objects and the most recent background can be fused together and the original frame can be reconstructed. However, protecting the authenticity of the video becomes more challenging in this case as a malicious entity can modify/replace/remove the individual foreground objects and background in the video. In this paper, we propose a Chinese remainder theorem based watermarking mechanism for protecting the authenticity of videos transmitted or stored as objects and background. Our mechanism ensures the authenticity between video objects and their associated background.
5597341
Bringing Richer Information with Reliability to Automated Traffic Monitoring from the Fusion of Multiple Cameras, Inductive Loops and Road Maps###This paper presents a novel, deterministic framework to extract the traffic state of an intersection with high reliability and in real-time. The multiple video cameras and inductive loops at the intersection are fused on a common plane which consists of a satellite map. The sensors are registered from a CAD map of the intersection that is aligned on the satellite map. The cameras are calibrated to provide the mapping equations that project the detected vehicle positions onto the coordinate system of the satellite map. We use a night time vehicle detection algorithm to process the camera frames. The inductive loops confirm or reject the vehicle tracks measured by the cameras, and the fusion of camera and loop provides an additional feature : the vehicle length. A Kalman filter linearly tracks the vehicles along the lanes. Over time, this filter reduces the noise present in the measurements. The advantage of this approach is that the detected vehicles and their parameters acquire a very high confidence, which brings almost 100% accuracy of the traffic state. An empirical evaluation is performed on a testbed intersection. We show the improvement of this framework over single sensor frameworks.
5597083
Privacy-Aware Object Representation for Surveillance Systems###Real-time object tracking, feature assessment and classification based on video are an enabling technology for improving situation awareness of human operators as well as for automated recognition of critical situations. To bridge the gap between video signal-processing output and spatio-temporal analysis of object behavior at the semantic level, a generic and sensor-independent object representation is necessary. However, in the case of public and corporate video surveillance, centralized storage of aggregated data leads to privacy violations. This article explains how a centralized object representation, complying with the Fair Information Practice Principles (FIP) privacy constraints, can be implemented for a video surveillance system.
5597098
A Local Directional Pattern Variance (LDPv) Based Face Descriptor for Human Facial Expression Recognition###Automatic facial expression recognition is a challenging problem in computer vision, and has gained significant importance in applications of human-computer interaction. This paper presents a new appearance-based feature descriptor, the Local Directional Pattern Variance (LDPv), to represent facial components for human expression recognition. In contrast with LDP, the proposed LDPv introduces the local variance of directional responses to encode the contrast information within the descriptor. Here, the LDPv representation characterizes both spatial structure and contrast information of each micro-patterns. Template matching and Support Vector Machine (SVM) classifier are used to classify the LDPv feature vector of different prototypic expression images. Experimental results using the Cohn-Kanade database show that the LDPv descriptor yields an improved recognition rate, as compared to existing appearance-based feature descriptors, such as the Gaborwavelet and Local Binary Pattern (LBP).
5597099
A Bayesian Framework for Online Interaction Classification###Real-time automatic human behavior recognition is one of the most challenging tasks for intelligent surveillance systems. Its importance lies in the possibility of robust detection of suspicious behaviors in order to prevent possible threats. The widespread integration of tracking algorithms into modern surveillance systems makes it possible to acquire descriptive motion patterns of different human activities. In this work, a statistical framework for human interaction recognition based on Dynamic Bayesian Networks (DBNs) is presented: the environment is partitioned by a topological algorithm into a set of zones that are used to define the state of the DBNs. Interactive and non-interactive behaviors are described in terms of sequences of significant motion events in the topological map of the environment. Finally, by means of an incremental classification measure, a scenario can be classified while it is currently evolving. In this way an autonomous surveillance system can detect and cope with potential threats in real-time.
5597320
Traffic Abnormality Detection through Directional Motion Behavior Map###Automatic traffic abnormality detection through visual surveillance is one of the critical requirements for Intelligent Transportation Systems (ITS). In this paper, we present a novel algorithm to detect abnormal traffic events in crowded scenes. Our algorithm can be deployed with few setup steps to automatically monitor traffic status. Different from other approaches, we don't need to define region of interests (ROI) or tripwires nor to configure object detection and tracking parameters. A novel object behavior descriptor directional motion behavior descriptors are proposed. The directional motion behavior descriptors collect foreground objects' direction and speed information from a video sequence with normal traffic events, and then these descriptors are accumulated to generate a directional motion behavior map which models the normal traffic status. During detection steps, we first extract the directional motion behavior map from the newly observed video and then measure the differences between the normal behavior map and the new map. If new direction motion behaviors are very different from the descriptors in the normal behavior map, then the corresponding regions in the observed video contain traffic abnormalities. Our proposed algorithm has been tested using both synthesized and real surveillance videos. Experimental results demonstrated that our algorithm is effective and efficient for practical real-time traffic surveillance applications.
5597134
PETS2010 and PETS2009 Evaluation of Results Using Individual Ground Truthed Single Views###This paper presents the results of the crowd image analysis challenge of the PETS2010 workshop. The evaluation was carried out using a selection of the metrics developed in the Video Analysis and Content Extraction (VACE) program and the CLassification of Events, Activities, and Relationships (CLEAR) consortium. The PETS 2010 evaluation was performed using new ground truthing created from each independant 2D view. In addition, the performance of the submissions to the PETS 2009 and Winter-PETS 2009 were evaluated and included in the results. The evaluation highlights the detection and tracking performance of the authors' systems in areas such as precision, accuracy and robustness.
5597322
Example-Based Color Vehicle Retrieval for Surveillance###In this paper, we evaluate several low dimensional color features for object retrieval in surveillance video. Previous work in object retrieval in surveillance has been hampered by issues in low resolution, poor segmentation, pose and lighting variations and the cost of retrieval. To overcome these difficulties, we restrict our analysis to alarm-based vehicle detection and as a consequence, we restrict both pose and lighting variations. In addition, we study the utility of example-based retrieval to avoid the limitations of strict color classification. Finally, since we perform our evaluation at run-time for alarm-based detection, we do not need to index into a large database. We evaluate the efficiency and effectiveness of several color features including standard color histograms, weighted color histograms, variable bin size color histograms and color correlograms. Results show color correlogram to have the best performance for our datasets.
5597136
Fast People Counting Using Head Detection From Skeleton Graph###In this paper, we present a new method for counting people. This method is based on the head detection after a segmentation of the human body by skeleton graph process. The skeleton silhouette is computed and decomposed into a set of segments corresponding to the head , torso and limbs. This structure captures the minimal information about the skeleton shape. No assumption is made about the viewpoint, this is done after the head pose process. Several results present the efficiency of the labelling process , particularly its structural properties for the detection of heads within a crowd. A proposed method are evaluated on the crowd counting task in the PETS 2010 dataset.
5597324
Thirteen Hard Cases in Visual Tracking###Visual tracking is a fundamental task in computer vision. However there has been no systematic way of analyzing visual trackers so far. In this paper we propose a method that can help researchers determine strengths and weaknesses of any visual tracker. To this end, we consider visual tracking as an isolated problem and decompose it into fundamental and independent subproblems. Each subproblem is designed to associate with a different tracking circumstance. By evaluating a visual tracker onto a specific subproblem, we can determine how good it is with respect to that dimension. In total we come up with thirteen subproblems in our decomposition. We demonstrate the use of our proposed method by analyzing working conditions of two state-of-the-art trackers.
5597325
A Method Based on the Indirect Approach for Counting People in Crowded Scenes###This paper presents a method for counting people in a scene by establishing a mapping between some scene features and the number of people avoiding the complex foreground detection problem. The method is based on the use of SURF features and of an &#x2208;-SVR regressor to provide an estimate of this count. The algorithm takes specifically into account problems due to partial occlusions and to perspective.
5597326
Performance Evaluation of a People Tracking System on PETS2009 Database###In this paper a system for autonomous video surveillance in relatively unconstrained environments is described. The system consists of two principal phases: object detection and object tracking. An adaptive background subtraction, together with a set of corrective algorithms, is used to cope with variable lighting, dynamic and articulate scenes, etc. The tracking algorithm is based on a matrix representation of the problem, and is used to face splitting and occlusion problems. When the tracking algorithm fails in following actual object trajectories, an appearance-based module is used to restore object identities. An experimental evaluation, carried out on the PETS2009 dataset for tracking, shows promising results.
5597327
Intelligent Video Systems: A Review of Performance Evaluation Metrics that Use Mapping Procedures###In Intelligent Video Systems, most of the recent advanced performance evaluation metrics perform a stage of mapping data between the system results and ground truth. This paper aims to review these metrics using a proposed framework. It will focus on metrics for events detection, objects detection and objects tracking systems.
5597077
SVM-Based Biometric Authentication Using Intra-Body Propagation Signals###To use intra-body propagation signals for biometric authentication have been proposed. The intra-body propagation signals are hid in human bodies; therefore, they have tolerability to circumvention using artifacts. Additionally, utilizing the signals in the body enables liveness detection with no additional scheme. The problem is, however, verification performance using the intra-body propagation signal is not so high. In this paper, in order to improve the performance we propose to use user-specific frequency bands for all users in verification. The verification performance is improved to 70 %. Furthermore, we introduce the support vector machine (SVM) into the verification process. It is confirmed that verification rate of about 86 % is achieved.
5597139
PETS2010: Dataset and Challenge###This paper describes the crowd image analysis challenge that forms part of the PETS 2010 workshop. The aim of this challenge is to use new or existing systems for i) crowd count and density estimation, ii) tracking of individual(s) within a crowd, and iii) detection of separate flows and specific crowd events, in a real-world environment. The dataset scenarios were filmed from multiple cameras and involve multiple actors.
5597138
Fast Background Initialization with Recursive Hadamard Transform###In this paper, we present a new and fast technique for background estimation from cluttered image sequences. Most of the background initialization approaches developed so far collect a number of initial frames and then require a slow estimation step which introduces a delay whenever it is applied. Conversely, the proposed technique redistributes the computational load among all the frames by means of a patch by patch preprocessing, which makes the overall algorithm more suitable for real-time applications. For each patch location a prototype set is created and maintained. The background is then iteratively estimated by choosing from each set the most appropriate candidate patch, which should verify a sort of frequency coherence with its neighbors. To this aim, the Hadamard transform has been adopted which requires less computation time than the commonly used DCT Finally, a refinement step exploits spatial continuity constraints along the patch borders to prevent erroneous patch selections. The approach has been compared with the state of the art on videos from available datasets (ViSOR and CAVIAR), showing a speed up of about 10 times and an improved accuracy.
5597129
Multi Camera-Based Person Tracking Using Region Covariance and Homography Constraint###In this paper, an algorithm for multiple camera based person tracking is presented. Region covariance matrixes are used to model the target appearance. The correspondence between multiple camera views is established via homography. It is utilized to improve the tracking of people under assumption that they are at the common ground plane. If there is occlusion in one view, the homography to this view from another view is utilized to locate the object template. The information about the true location of the template helps the tracker to resume, even in case of substantial temporal occlusions or large object movements. The object template is represented by multiple non-overlapping patches. Owing to such an object representation the tracker is capable both detecting the occlusion and handling considerable partial occlusions. The object tracking is achieved using particle swarm optimization. The objective function is based on the Log-Euclidean Riemannian metric. Experimental results that were obtained on surveillance videos show the feasibility of the presented approach.
5597093
Body Parts Detection for People Tracking Using Trees of Histogram of Oriented Gradient Descriptors###Vision algorithms face many challenging issues when it comes to analyze human activities in video surveillance applications.For instance, occlusions makes the detection and tracking of people a hard task to perform. Hence advanced and adapted solutions are required to analyze the content of video sequences. We here present a people detection algorithm based on a hierarchical tree of Histogram of Oriented Gradients referred to as HOG. The detection is coupled with independently trained body part detectors to enhance the detection performance and to reach state of the art performances. We adopt a person tracking scheme which calculates HOG dissimilarities between detected persons throughout a sequence. The algorithms are tested in videos with challenging situations such as occlusions. False alarms are further reduced by using 2D and 3D information of moving objects segmented from a background reference frame.
5597078
TrustCAM: Security and Privacy-Protection for an Embedded Smart Camera Based on Trusted Computing###Security and privacy protection are critical issues for public acceptance of camera networks. Smart cameras, with onboard image processing, can be used to identify and remove privacy sensitive image regions. Existing approaches, however, only address isolated aspects without considering the integration with established security technologies and the underlying platform. This work tries to fill this gap and presents TrustCAM, a security-enhanced smart camera. Based on Trusted Computing, we realize integrity protection, authenticity and confidentiality of image data. Multiple levels of privacy protection, together with access control, are supported. Impact on overall system performance is evaluated on a real prototype implementation.
5597079
License Plate Detection Using Local Structure Patterns###We address the problem of license plate detection in video surveillance systems. The Adaboost based approach, known for relative ease of implementation, makes use of discriminative features such as edges or Haar-like features. In this paper, we propose a novel detection algorithm based on local structure patterns for license plate detection. The proposed algorithm includes post-processing methods to reduce false positive rate using positional and color information of license plates. Experimental results demonstrate effectiveness of the proposed method compared to both the edge and Haar-like feature based methods.
5597119
Multi-pose Face Recognition for Person Retrieval in Camera Networks###In this paper, we study the use of facial appearance features for the re-identification of persons using distributed camera networks in a realistic surveillance scenario. In contrast to features commonly used for person reidentification, such as whole body appearance, facial features offer the advantage of remaining stable over much larger intervals of time. The challenge in using faces for such applications, apart from low captured face resolutions, is that their appearance across camera sightings is largely influenced by lighting and viewing pose. Here, a number of techniques to address these problems are presented and evaluated on a database of surveillance-type recordings. A system for online capture and interactive retrieval is presented that allows to search for sightings of particular persons in the video database. Evaluation results are presented on surveillance data recorded with four cameras over several days. A mean average precision of 0.60 was achieved for inter-camera retrieval using just a single track as query set, and up to 0.86 after relevance feedback by an operator.
5597118
Robust Real Time Moving People Detection in Surveillance Scenarios###In this paper an improved real time algorithm for detecting pedestrians in surveillance video is proposed. The algorithm is based on people appearance and defines a person model as the union of four models of body parts. Firstly, motion segmentation is performed to detect moving pixels. Then, moving regions are extracted and tracked. Finally, the detected moving objects are classified as human or nonhuman objects. In order to test and validate the algorithm, we have developed a dataset containing annotated surveillance sequences of different complexity levels focused on the pedestrians detection. Experimental results over this dataset show that our approach performs considerably well at real time and even better than other real and non-real time approaches from the state of art.
5597113
Learning Directed Intention-driven Activities using Co-Clustering###We present a novel approach for discovering directed intention-driven pedestrian activities across large urban areas. The proposed approach is based on a mutual information co-clustering technique that simultaneously clusters trajectory start locations in the scene which have similar distributions across stop locations and vice-versa. The clustering assignments are obtained by minimizing the loss of mutual information between a trajectory start-stop association matrix and a compressed co-clustered matrix, after which the scene activities are inferred from the compressed matrix. We demonstrate our approach using a dataset of long duration trajectories from multiple PTZ cameras covering a large area and show improved results over two other popular trajectory clustering and entry-exit learning approaches.
5597112
Tracking People with a 360-Degree Lidar###Advances in lidar technology, in particular 360-degree lidar sensors, create new opportunities to augment and improve traditional surveillance systems. This paper describes an initial challenge to use a single stationary 360-degree lidar sensor to detect and track people moving throughout a scene in real-time. The depicted approach focuses on overcoming three primary challenges inherent in any lidar tracker: classification and matching errors between multiple human targets, segmentation errors between humans and fixed objects in the scene, and segmentation errors between targets that are very close together.
5597111
Background Subtraction under Sudden Illumination Changes###Robust background subtraction under sudden illumination changes is a challenging problem. In this paper, we propose an approach to address this issue, which combines the Eigenbackground algorithm together with a statistical illumination model. The first algorithm is used to give a rough reconstruction of the input frame, while the second one improves the foreground segmentation. We introduce an online spatial likelihood model by detecting reliable background and foreground pixels. Experimental results illustrate that our approach achieves consistently higher accuracy compared to several state-of-the-art algorithms.
5597110
Learning of Scene-Specific Object Detectors by Classifier Co-Grids###Recently, classifier grids have shown to be a considerable alternative to sliding window approaches for object detection from static cameras. The main drawback of such methods is that they are biased by the initial model. In fact, the classifiers can be adapted to changing environmental conditions but due to conservative updates no new object-specific information is acquired. Thus, the goal of this work is to increase the recall of scene-specific classifiers while preserving their accuracy and speed. In particular, we introduce a co-training strategy for classifier grids using a robust on-line learner. Thus, the robustness is preserved while the recall can be increased. The co-training strategy robustly provides negative as well as positive updates. In addition, the number of negative updates can be drastically reduced, which additionally speeds up the system. In the experimental results these benefits are demonstrated on different publicly available surveillance benchmark data sets.
5597117
A Spatiotemporal Motion-Vector Filter for Object Tracking on Compressed Video###In this paper, a novel filter for real-time object tracking from compressed domain is presented and evaluated. The filter significantly reduces the noisy motion vectors, that do not represent a real object movement, from Mpeg family compressed videos. The filter analyses the spatial (neighborhood) and temporal coherence of block motion vectors to determine if they are likely to represent true motion from the recorded scene. Qualitative and quantitative experiments are performed displaying that the proposed spatiotemporal filter (STF) outperforms the currently widely used vector median filter. The results obtained with the spatiotemporal filter make it suitable as a first step of any system that aims to detect and track objects from compressed video using its motion vectors.
5597075
An Ultra-Low-Power Contrast-Based Integrated Camera Node and its Application as a People Counter###We describe the implementation in a self-standing system of a novel contrast-based binary CMOS imaging sensor.This sensor is characterized by very low power consumption and wide dynamic range, which makes it attractive for wireless camera network applications. In our implementation,the sensor is interfaced with a Flash-based FPGA processor,which handles data readout and image processing.This self-standing camera node is configured as a system for counting persons walking through a corridor. Simple features are extracted from each image in a video stream at 30 fps. A classifier is designed based on the temporal evolution of these features, which is modeled as a Markov chain. The video stream is then segmented into intervals corresponding to individual persons crossing through the field of view. Experimental results are shown in cross-validated tests over real sequences acquired by the camera.
5597115
Affinity Propagation Feature Clustering with Application to Vehicle Detection and Tracking in Road Traffic Surveillance###In this paper, we investigate the applicability of the newly proposed data clustering method, affinity propagation, in feature points clustering and the task of vehicle detection and tracking in road traffic surveillance. We propose a model-based temporal association scheme and novel preprocessing and postprocessing operations which together with affinity propagation make a quite successful method for the given task. Our experiments demonstrate the effectiveness and efficiency of our method and its superiority over the state-of-the-art algorithm.
5597114
Person Re-identification Using Spatial Covariance Regions of Human Body Parts###In many surveillance systems there is a requirement to determine whether a given person of interest has already been observed over a network of cameras. This is the person re-identification problem. The human appearance obtained in one camera is usually different from the ones obtained in another camera. In order to re-identify people the human signature should handle difference in illumination, pose and camera parameters. We propose a new appearance model based on spatial covariance regions extracted from human body parts. The new spatial pyramid scheme is applied to capture the correlation between human body parts in order to obtain a discriminative human signature. The human body parts are automatically detected using Histograms of Oriented Gradients (HOG). The method is evaluated using benchmark video sequences from i-LIDS Multiple-Camera Tracking Scenario data set. The re-identification performance is presented using the cumulative matching characteristic (CMC) curve. Finally, we show that the proposed approach outperforms state of the art methods.
5597103
Intelligent Sensor Information System For Public Transport &#150; To Safely Go&#133;###The Intelligent Sensor Information System (ISIS) is described. ISIS is an active CCTV approach to reducing crime and anti-social behavior on public transport systems such as buses. Key to the system is the idea of event composition, in which directly detected atomic events are combined to infer higher-level events with semantic meaning. Video analytics are described that profile the gender of passengers and track them as they move about a 3-D space. The overall system architecture is described which integrates the on-board event recognition with the control room software over a wireless network to generate a real-time alert. Data from preliminary data-gathering trial is presented.
5597130
Incremental Mosaicking of Images from Autonomous, Small-Scale UAVs###Unmanned aerial vehicles (UAVs) have been recently deployed in various civilian applications such as environmental monitoring, aerial imaging or surveillance. Small-scale UAVs are of special interest for first responders since they can rather easily provide bird's eye view images of disaster areas. In this paper we present a hybrid approach to mosaick an overview image of the area of interest given a set of individual images captured by UAVs flying at low altitude. Our approach combines metadata-based and imagebased stitching methods in order to overcome the challenges of low-altitude, small-scale UAV deployment such as nonnadir view, inaccurate sensor data, non-planar ground surfaces and limited computing and communication resources. For the generation of the overview image we preserve georeferencing as much as possible, since this is an important requirement for disaster management applications. Our mosaicking method has been implemented on our UAV system and evaluated based on a quality metric.
5597131
Human Motion Change Detection by Hierarchical Gaussian Process Dynamical Model with Particle Filter###Human motion change detection is a challenging task for a surveillance sensor system. Major challenges include complex scenes with a large amount of targets and confusors, and complex motion behaviors of different human objects. Human motion change detection and understanding have been intensively studied over the past decades. In this paper, we present a Hierarchical Gaussian Process Dynamical Model (HGPDM) integrated with particle filter tracker for human motion change detection. Firstly, the high dimensional human motion trajectory training data is projected to the low dimensional latent space with a two-layer hierarchy. The latent space at the leaf node in bottom layer represents a typical human motion trajectory, while the root node in the upper layer controls the interaction and switching among leaf nodes. The trained HGPDM will then be used to classify test object trajectories which are captured by the particle filter tracker. If the motion trajectory is different from the motion in the previous frame, the root node will transfer the motion trajectory to the corresponding leaf node. In addition, HGPDM can be used to predict the next motion state, and provide Gaussian process dynamical samples for the particle filter framework. The experiment results indicate that our framework can accurately track and detect the human motion changes despite of complex motion and occlusion. In addition, the sampling in the hierarchical latent space has greatly improved the efficiency of the particle filter framework.
5597086
Local Feature Based Person Reidentification in Infrared Image Sequences###In this paper, we address the task of appearance based person reidentification in infrared image sequences. While common approaches for appearance based person reidentification in the visible spectrum acquire color histograms of a person, this technique is not applicable in infrared for obvious reasons. To tackle the more difficult problem of person reidentification in infrared, we introduce an approach that relies on local image features only and thus is completely independent of sensor specific features which might be available only in the visible spectrum. Our approach fits into an Implicit Shape Model (ISM) based person detection and tracking strategy described in previous work. Local features collected during tracking are employed for person reidentification while the generalizing appearance codebook used for person detection serves as structuring element to generate person signatures. By this, we gain an integrated approach that allows for fast online model generation, a compact representation, and fast model matching. Since the model allows for a joined representation of appearance and spatial information, no complex representation models like graph structures are needed. We evaluate our person reidentification approach on a subset of the CASIA infrared dataset.
5597135
Subjective Logic Based Hybrid Approach to Conditional Evidence Fusion for Forensic Visual Surveillance###In forensic analysis of visual surveillance data, conditional knowledge representation and inference under uncertainty play an important role for deriving new contextual cues by fusing relevant evidential patterns. To address this aspect, both rule-based (aka. extensional) and state based (aka. intensional) approaches have been adopted for situation or visual event analysis. The former provides flexible expressive power and computational efficiency but typically allows only one directional inference. The latter is computationally expensive but allows bidirectional interpretation of conditionals by treating antecedent and consequent of conditionals as mutually relevant states. In visual surveillance, considering the varying semantics and potentially ambiguous causality in conditionals, it would be useful to combine the expressive power of rule-based system with the ability of bidirectional interpretation. In this paper, we propose a hybrid approach that, while relying mainly on a rule-based architecture, also provides an intensional way of on-demand conditional modeling using conditional operators in subjective logic. We first show how conditionals can be assessed via explicit representation of ignorance in subjective logic. We then describe the proposed hybrid conditional handling framework. Finally we present an experimental case study from a typical airport scene taken from visual surveillance data.
5597081
Audio-Visual Co-Training for Vehicle Classification###In this paper, we introduce a fully autonomous vehicle classification system that continuously learns from largeamounts of unlabeled data. For that purpose, we proposea novel on-line co-training method based on visual and acoustic information. Our system does not need complicated microphone arrays or video calibration and automatically adapts to specific traffic scenes. These specialized detectors are more accurate and more compact than general classifiers, which allows for light-weight usage in low-cost and portable embedded systems. Hence, we implemented our system on an off-the-shelf embedded platform. In the experimental part, we show that the proposed method is able to cover the desired task and outperforms single-cue systems. Furthermore, our co-training framework minimizes the labeling effort without degrading the overall system performance.
5597109
Resource-Efficient Salient Foreground Detection for Embedded Smart Cameras br Tracking Feedback###Battery-powered wireless embedded smart cameras have limited processing power, memory and energy. Since video processing tasks consume significant amount of power,the problem of limited resources becomes even more pronounced, and necessitates designing light-weight algorithms suitable for embedded platforms. In this paper, we present a resource-efficient salient foreground detection and tracking algorithm. Contrary to traditional methods that implement foreground object detection and tracking independently and in a sequential manner, the proposed method uses the feedback from the tracking stage in the foreground object detection. We compare the proposed method with a sequential method on the microprocessor of an embedded smart camera, and present the savings in the processing time and energy consumption and the gain in the lifetime of a battery-powered camera for different scenarios. The presented method provides significant savings in terms of the processing time of a frame. We take advantage of these savings by sending the microprocessor to idle state at the end of processing a frame, and when the scene is empty.
5597072
Incremental Learning Approach for Events Detection from Large Video Dataset###In this paper, we propose a strategy of multi-SVM incremental learning system based on Learn++ classifier for detection of predefined events in the video. This strategy is offline and fast in the sense that any new class of event can be learned by the system from very few examples. The extraction and synthesis of suitably video events are used for this purpose. The results showed that the performance of our system is improving gradually and progressively as we increase the number of such learning for each event. We then demonstrate the usefulness of the toolbox in the context of feature extraction, concepts/events learning and detection in large collection of video surveillance dataset.
5597126
Statistical Background Modeling: An Edge Segment Based Moving Object Detection Approach###We propose an edge segment based statistical background modeling algorithm and a moving edge detection framework for the detection of moving objects. We analyze the performance of the proposed segment based statistical background model with traditional pixel based, edge pixel based and edge segment based approaches. Existing edge based moving object detection algorithms fetches difficulty due to the change in background motion, object shape, illumination variation and noise. The proposed algorithm makes efficient use of statistical background model using the edge-segment structure. Experiments with natural image sequences show that our method can detect moving objects efficiently under the above mentioned environments.
5597122
Trajectory Based Activity Discovery###This paper proposes a framework to discover activities in an unsupervised manner, and add semantics with minimal supervision. The framework uses basic trajectory information as input and goes up to video interpretation. The work reduces the gap between low-level information and semantic interpretation, building an intermediate layer composed of Primitive Events. The proposed representation for primitive events aims at capturing small meaningful motions over the scene with the advantage of being learnt in an unsupervised manner. We propose the discovery of an activity using these Primitive Events as the main descriptors. The activity discovery is done using only real tracking data. Semantics are added to the discovered activities and the recognition of activities (e.g., "Cooking", "Eating") can be automatically done with new datasets. Finally we validate the descriptors by discovering and recognizing activities in a home care application dataset.
5597123
Real Time Human Action Recognition in a Long Video Sequence###In recent years, most action recognition researches focus on isolated action analysis for short videos, but ignore the issue of continuous action recognition for a long video sequence in real time. This paper proposes a novel approach for human action recognition in a video sequence with whatever length, which, unlike previous works,requires no annotations and no pre-temporal-segmentations.Based on the bag of words representation and the probabilistic Latent Semantic Analysis (pLSA) model, there cognition process goes frame by frame and the decision updates from time to time. Experimental results show that this approach is effective to recognize both isolated actions and continuous actions no matter how long a video sequence is. This is very useful for real time applications like video surveillance. Besides, we also test our approach for real time temporal video segmentation and real time keyframe extraction.
5597120
Histogram-Based Training Initialisation of Hidden Markov Models for Human Action Recognition###Human action recognition is often addressed by use of latent-state models such as the hidden Markov model and similar graphical models. As such models require Expectation-Maximisation training, arbitrary choices must be made for training initialisation, with major impact on the final recognition accuracy. In this paper, we propose a histogram-based deterministic initialisation and compare it with both random and a time-based deterministic initialisations. Experiments on a human action dataset show that the accuracy of the proposed method proved higher than that of the other tested methods.
5597319
Functionality Delegation in Distributed Surveillance Systems###The utilization of multimedia devices is growing rapidly in surveillance and monitoring applications. These multimedia surveillance systems need to process large amounts of multimodal sensor data in order to detect events and objects. While processing this large amount of data, the system faces many processing and network bottlenecks. The design of efficient multimedia surveillance system requires intelligent architectural decisions and performance evaluation to cope with these resource demands. One critical issue among all these architectures is task assignment among processing units. To study the effect of this task assignment on system performance with quantifiable performance measures is very useful and challenging. We define a Functionality Delegation Coefficient which abstracts the delegation of functionality among processing units of a distributed surveillance system and show its effect on event blocking probability and response time. Simulation and real implementation results are provided to validate the model.
5597318
Surveillance Camera Calibration from Observations of a Pedestrian###Calibrated cameras are an extremely useful resource for computer vision scenarios. Typically, cameras are calibrated through calibration targets, measurements of the observed scene, or self-calibrated through features matched between cameras with overlapping fields of view. This paper considers an approach to camera calibration based on observations of a pedestrian and compares the resulting calibration to a commonly used approach requiring that measurements be made of the scene.
5597124
Multi-Modal Object Tracking using Dynamic Performance Metrics###Intelligent surveillance systems typically use a single visual spectrum modality for their input. These systems work well in controlled conditions, but often fail when lighting is poor, or environmental effects such as shadows, dust or smoke are present. Thermal spectrum imagery is not as susceptible to environmental effects, however thermal imaging sensors are more sensitive to noise and they are only gray scale, making distinguishing between objects difficult. Several approaches to combining the visual and thermal modalities have been proposed, however they are limited by assuming that both modalities are perfuming equally well. When one modality fails, existing approaches are unable to detect the drop in performance and disregard the under performing modality. In this paper, a novel middle fusion approach for combining visual and thermal spectrum images for object tracking is proposed. Motion and object detection is performed on each modality and the object detection results for each modality are fused base on the current performance of each modality. Modality performance is determined by comparing the number of objects tracked by the system with the number detected by each mode, with a small allowance made for objects entering and exiting the scene. The tracking performance of the proposed fusion scheme is compared with performance of the visual and thermal modes individually, and a baseline middle fusion scheme. Improvement in tracking performance using the proposed fusion approach is demonstrated. The proposed approach is also shown to be able to detect the failure of an individual modality and disregard its results, ensuring performance is not degraded in such situations.
5597125
Human Action Recognition using a Hybrid NTLD Classifier###This work proposes a hybrid classifier to recognize human actions in different contexts. In particular, the proposed hybrid classifier (a neural tree with linear discriminant nodes NTLD), is a neural tree whose nodes can be either simple preceptrons or recursive fisher linear discriminant (RFLD) classifiers. A novel technique to substitute bad trained perceptron with more performant linear discriminators is introduced. For a given frame, geometrical features are extracted from the skeleton of the human blob (silhouette). These geometrical features are collected for a fixed number of consecutive frames to recognize the corresponding activity. The resulting feature vector is adopted as input to the NTLD classifier. The performance of the proposed classifier has been evaluated on two available databases.
5597315
Task-Oriented Object Tracking in Large Distributed Camera Networks###In this paper a task-oriented approach for object tracking in large distributed camera networks is presented. This work includes three main contributions. First a generic process framework is presented, which has been designed for task-oriented video processing. Second, system components of the task-oriented framework needed for the task of multi-camera person tracking are introduced in detail. Third, for an efficient task-oriented processing in large camera networks the capability of dynamic sensor scheduling by the multi-camera tracking processes is indispensable. For this purpose an efficient sensor selection approach is proposed.
5597314
Soccer Player Activity Recognition by a Multivariate Features Integration###Human action recognition is an important research area in the field of computer vision having a great number of real-world applications. This paper presents a multi-view action recognition framework that extracts human silhouette clues from different cameras, analyzes scene dynamics and interprets human behaviors by the integration of multivariate data in fuzzy rule-based system. Different features have been considered for the player action recognition some of them concerning the human silhouette analysis, and some others related to the ball and player kinematics. Experiments were carried out on a multi view image sequences of a public soccer data set.
5597317
Group Level Activity Recognition in Crowded Environments across Multiple Cameras###Environments such as schools, public parks and prisons and others that contain a large number of people are typically characterized by frequent and complex social interactions. In order to identify activities and behaviors in such environments, it is necessary to understand the interactions that take place at a group level. To this end, this paper addresses the problem of detecting and predicting suspicious and in particular aggressive behaviors between groups of individuals such as gangs in prison yards. The work builds on a mature multi-camera multi-target person tracking system that operates in real-time and has the ability to handle crowded conditions. We consider two approaches for grouping individuals: (i) agglomerative clustering favored by the computer vision community, as well as (ii) decisive clustering based on the concept of modularity, which is favored by the social network analysis community. We show the utility of such grouping analysis towards the detection of group activities of interest. The presented algorithm is integrated with a system operating in real-time to successfully detect highly realistic aggressive behaviors enacted by correctional officers in a simulated prison environment. We present results from these enactments that demonstrate the efficacy of our approach.
5597316
MuHAVi: A Multicamera Human Action Video Dataset for the Evaluation of Action Recognition Methods###This paper describes a body of multicamera human action video data with manually annotated silhouette data that has been generated for the purpose of evaluating silhouette-based human action recognition methods. It provides a realistic challenge to both the segmentation and human action recognition communities and can act as a benchmark to objectively compare proposed algorithms. The public multi-camera, multi-action dataset is an improvement over existing datasets (e.g. PETS, CAVIAR, soccerdataset) that have not been developed specifically for human action recognition and complements other action recognition datasets (KTH, Weizmann, IXMAS, HumanEva, CMU Motion). It consists of 17 action classes, 14 actors and 8 cameras. Each actor performs an action several times in the action zone. The paper describes the dataset and illustrates a possible approach to algorithm evaluation using a previously published action simple recognition method. In addition to showing an evaluation methodology, these results establish a baseline for other researchers to improve upon.
5597311
Spatio-Temporal Optical Flow Analysis for People Counting###In this paper, we present a new approach to count the number of people that cross a counting line from monocular video images. The proposed approach accumulates image slices and estimates the optical flow on them. Then, it performs an online blob detection on these slices in order to extract the crossing persons. The number of persons associated to each blob is determined using a linear regression model applied to blob features which are the position, velocity, orientation and size. The proposed approach is validated on several datasets captured using either a vertical overhead or an oblique mounted camera. The real-time performance and the high counting accuracy of this approach in indoor and outdoor environments are also demonstrated.
5597310
A Method for Counting People in Crowded Scenes###This paper presents a novel method to count people for video surveillance applications. Methods in the literature either follow a direct approach, by first detecting people and then counting them, or an indirect approach, by establishing a relation between some easily detectable scene features and the estimated number of people. The indirect approach is considerably more robust, but it is not easy to take into account such factors as perspective or people groups with different densities. The proposed technique, while based on the indirect approach, specifically addresses these problems; furthermore it is based on a trainable estimator that does not require an explicit formulation of a priori knowledge about the perspective and density effects present in the scene at hand. In the experimental evaluation, the method has been extensively compared with the algorithm by Albiol et al, which provided the highest performance at the PETS 2009 contest on people counting. The experimentation has used the public PETS 2009 datasets. The results confirm that the proposed method improves the accuracy, while retaining the robustness of the indirect approach.
5597312
Fast People Counting Using Head Detection from Skeleton Graph###In this paper, we present a new method for counting people. This method is based on the head detection after a segmentation of the human body by skeleton graph process. The skeleton silhouette is computed and decomposed into a set of segments corresponding to the head, torso and limbs. This structure captures the minimal information about the skeleton shape. No assumption is made about the viewpoint, this is done after the head pose process. Several results present the efficiency of the labelling process , particularly its structural properties for the detection of heads within a crowd. A proposed method has been tested with an experiment of counting the number of pedestrians passing in a specific area.
5597108
A Framework Dealing with Uncertainty for Complex Event Recognition###This paper presents a constraint-based approach for video event recognition with probabilistic reasoning for handling uncertainty. The main advantage of constraint-based approaches is the possibility for human expert to model composite events with complex temporal constraints. But the approaches are usually deterministic and do not enable the convenient mechanism of probability reasoning to handle the uncertainty. The first advantage of the proposed approach is the ability to model and recognize composite events with complex temporal constraints. The second advantage is that probability theory provides a consistent framework for dealing with uncertain knowledge for a robust and reliable recognition of complex event. This approach is evaluated with 4 real healthcare videos and a public video ETISEO'06. The results are compared with state of the art method. The comparison shows that the proposed approach improves significantly the process of recognition and characterizes the likelihood of the recognized events.
5597145
Action Recognition Using Sparse Representation on Covariance Manifolds of Optical Flow###A novel approach to action recognition in video based on the analysis of optical flow is presented. Properties of optical flow useful for action recognition are captured using only the empirical covariance matrix of a bag of features such as flow velocity, gradient, and divergence. The feature covariance matrix is a low-dimensional representation of video dynamics that belongs to a Riemannian manifold. The Riemannian manifold of covariance matrices is transformed into the vector space of symmetric matrices under the matrix logarithm mapping. The log-covariance matrix of a test action segment is approximated by a sparse linear combination of the log-covariance matrices of training action segments using a linear program and the coefficients of the sparse linear representation are used to recognize actions. This approach based on the unique blend of a logcovariance-descriptor and a sparse linear representation is tested on the Weizmann and KTH datasets. The proposed approach attains leave-one-out cross validation scores of 94.4% correct classification rate for the Weizmann dataset and 98.5% for the KTH dataset. Furthermore, the method is computationally efficient and easy to implement.
5597147
Human Action Recognition and Localization in Video Using Structured Learning of Local Space-Time Features###This paper presents a unified framework for human action classification and localization in video using structured learning of local space-time features. Each human action class is represented by a set of its own compact set of local patches. In our approach, we first use a discriminative hierarchical Bayesian classifier to select those space-time interest points that are constructive for each particular action. Those concise local features are then passed to a Support Vector Machine with Principal Component Analysis projection for the classification task. Meanwhile, the action localization is done using Dynamic Conditional Random Fields developed to incorporate the spatial and temporal structure constraints of superpixels extracted around those features. Each superpixel in the video is defined by the shape and motion information of its corresponding feature region. Compelling results obtained from experiments on KTH [22], Weizmann [1], HOHA [13] and TRECVid [23] datasets have proven the efficiency and robustness of our framework for the task of human action recognition and localization in video.
5597140
On the Evaluation of Background Subtraction Algorithms without Ground-Truth###In video-surveillance systems, the moving object segmentation stage (commonly based on background subtraction) has to deal with several issues like noise, shadows and multimodal backgrounds. Hence, its failure is inevitable and its automatic evaluation is a desirable requirement for online analysis. In this paper, we propose a hierarchy of existing performance measures not-based on ground-truth for video object segmentation. Then, four measures based on color and motion are selected and examined in detail with different segmentation algorithms and standard test sequences for video object segmentation. Experimental results show that color-based measures perform better than motion-based measures and background multimodality heavily reduces the accuracy of all obtained evaluation results.
5597141
Counting People in Crowded Environments by Fusion of Shape and Motion Information###Knowing the number of people in a crowded scene is of big interest in the surveillance scene. In the past, this problem has been tackled mostly in an indirect, statistical way. This paper presents a direct, counting by detection, method based on fusing spatial information received from an adapted Histogram of Oriented Gradients-algorithm (HOG) with temporal information by exploiting distinctive motion characteristics of different human body parts. For that purpose, this paper defines a measure for uniformity of motion. Furthermore, the system performance is enhanced by validating the resulting human hypotheses by tracking and applying a coherent motion detection. The approach is illustrated with an experimental evaluation.
5597142
Recognizing and Localizing Individual Activities through Graph Matching###In this paper we tackle the problem of detecting individual human actions in video sequences. While the most successful methods are based on local features, which proved that they can deal with changes in background, scale and illumination, most existing methods have two main shortcomings: first, they are mainly based on the individual power of spatio-temporal interest points (STIP), and therefore ignore the spatio-temporal relationships between them. Second, these methods mainly focus on direct classification techniques to classify the human activities, as opposed to detection and localization. In order to overcome these limitations, we propose a new approach, which is based on a graph matching algorithm for activity recognition. In contrast to most previous methods which classify entire video sequences, we design a video matching method from two sets of ST-points for human activity recognition. First, points are extracted, and a hyper graphs are constructed from them, i.e. graphs with edges involving more than 2 nodes (3 in our case). The activity recognition problem is then transformed into a problem of finding instances of model graphs in the scene graph. By matching local features instead of classifying entire sequences, our method is able to detect multiple different activities which occur simultaneously in a video sequence. Experiments on two standard datasets demonstrate that our method is comparable to the existing techniques on classification, and that it can, additionally, detect and localize activities.
5597321
Human Localization in a Cluttered Space Using Multiple Cameras###The use of single and dual-camera approaches to locating a subject in a 3-D cluttered space is investigated. Specifically, we investigate the case where the lower portion of the body may be occluded, e.g., by a chair on a bus. Experiments were conducted involving eleven subjects moving along a pre-designated route within a cluttered space. For each time instant the position of each subject was manually estimated and compared to that produced automatically. The dual camera approach was found to give significantly better performance than the single camera approach. It was found that inaccurate bounding of the lowest part of the subject, due to occlusion, led to localisation errors in range as large as 10m for the latter. Using the side bounds of the detected object, which were found to be robust, accurate azimuth estimates can be obtained for a single camera. The dual-camera approach exploits the greater degree of accuracy in azimuth to estimate the range through triangulation, giving average localisation errors of 40cm over the space of interest.
5597101
Local Abnormality Detection in Video Using Subspace Learning###On-line abnormality detection in video without the use of object detection and tracking is a desirable task in surveillance.We address this problem for the case when labeled information about normal events is limited and information about abnormal events is not available. We formulate this problem as a one-class classification, where multiple local novelty classifiers (detectors) are used to first learn normal actions based on motion information and then to detect abnormal instances. Each detector is associated to a small region of interest and is trained over labeled samples projected on an appropriate subspace. We discover this subspace by using both labeled and unlabeled segments.We investigate the use of subspace learning and compare two methodologies based on linear (Principal Components Analysis) and on non-linear subspace learning (Locality Preserving Projections), respectively. Experimental results on a real underground station dataset shows that the linear approach is better suited for cases where the subspace learning is restricted to the labeled samples, whereas the non-linear approach is preferable in the presence of additional unlabeled data.
5597127
An Activity Monitoring System for Real Elderly at Home: Validation Study###Since the population of the elderly grows highly, the improvement of the quality of life of elderly at home is of a great importance. This can be achieved through the development of technologies for monitoring their activities at home. In this context, we propose an activity monitoring system which aims to achieve behavior analysis of elderly people. The proposed system consists of an approach combining heterogeneous sensor data to recognize activities at home. This approach combines data provided by video cameras with data provided by environmental sensors attached to house furnishings. In this paper, we validate the proposed activity monitoring system for the recognition of a set of daily activities (e.g. using kitchen equipment, preparing meal) for 9 real elderly volunteers living in an experimental apartment. We compare the behavioral profile between the 9 elderly volunteers. This study shows that the proposed system is thoroughly accepted by the elderly and it is also well appreciated by the medical staff.
5597143
Adaptive Patch-Based Background Modelling for Improved Foreground Object Segmentation and Tracking###A robust foreground object segmentation technique is proposed, capable of dealing with image sequences containing noise, illumination variations and dynamic backgrounds. The method employs contextual spatial information by analysing each image on an overlapping patch-by-patch basis and obtaining a low-dimensional texture descriptor for each patch. Each descriptor is passed through an adaptive multi-stage classifier, comprised of a likelihood evaluation, an illumination robust measure, and a temporal correlation check. A probabilistic foreground mask generation approach integrates the classification decisions by exploiting the overlapping of patches, ensuring smooth contours of the foreground objects as well as effectively minimising the number of errors. The parameter settings are robust against wide variety of sequences and post-processing of foreground masks is not required. Experiments on the difficult Wallflower and I2R datasets show that the proposed method obtains considerably better results (both qualitatively and quantitatively) than methods based on Gaussian mixture models, feature histograms, and normalised vector distances. Further experiments on the CAVIAR dataset (using several tracking algorithms) indicate that the proposed method leads to considerable improvements in object tracking accuracy.
5597104
Global Identification of Tracklets in Video Using Long Range Identity Sensors###Reliable tracking of people in video and recovering their identities are of great importance to video analytics applications.For outdoor applications, long range identity sensors such as active RFID can provide good coverage in a large open space, though they only provide coarse location information. We propose a probabilistic approach using noisy inputs from multiple long range identity sensors to globally associate and identify fragmented tracklets generated by video tracking algorithms. We extend a network flow based data association model to recover tracklet identity efficiently. Our approach is evaluated using five minutes of video and active RFID measurements capturing four people wearing RFID tags and a couple of passersby. Simulation is then used to evaluate performance for larger number of targets under different scenarios.identities are of great importance to video analytics applications.For outdoor applications, long range identity sensors such as active RFID can provide good coverage in a large open space, though they only provide coarse location information. We propose a probabilistic approach using noisy inputs from multiple long range identity sensors to globally associate and identify fragmented tracklets generated by video tracking algorithms. We extend a network flow based data association model to recover tracklet identity efficiently. Our approach is evaluated using five minutes of video and active RFID measurements capturing four people wearing RFID tags and a couple of passersby. Simulation is then used to evaluate performance for larger number of targets under different scenarios.
5597308
Crowd Counting Using Group Tracking and Local Features###In public venues, crowd size is a key indicator of crowd safety and stability. In this paper we propose a crowd counting algorithm that uses tracking and local features to count the number of people in each group as represented by a foreground blob segment, so that the total crowd estimate is the sum of the group sizes. Tracking is employed to improve the robustness of the estimate, by analysing the history of each group, including splitting and merging events. A simplified ground truth annotation strategy results in an approach with minimal setup requirements that is highly accurate.
5597106
Accurate and Efficient Background Subtraction by Monotonic Second-Degree Polynomial Fitting###We present a background subtraction approach aimed at efficiency and accuracy also in presence of common sources of disturbance such as illumination changes, camera gain and exposure variations, noise. The novelty of the proposal relies on a-priori modeling the local effect of disturbs on small neighborhoods of pixel intensities as a monotonic, homogeneous, second-degree polynomial transformation plus additive Gaussian noise. This allows for classifying pixels as changed or unchanged by an efficient inequality-constrained least-squares fitting procedure. Experiments prove that the approach is state-of-the-art in terms of efficiency-accuracy tradeoff on challenging sequences characterized by disturbs yielding sudden and strong variations of the background appearance.
5597107
Extracting Pathlets FromWeak Tracking Data###We present a novel framework for extracting "pathlets" from tracking data. A pathlet is defined as a motion region that contains tracks having the same origin and destination in the scene and that are temporally correlated. The proposed method requires only weak tracking data (multiple fragmented tracks per target). We employ a probabilistic state space representation to construct a Markovian transition model and estimate the scene entry/exit locations. The resulting model is treated as a set of vertices in a graph and a similarity matrix is built which describes broader nonlocal relationships between states. A Spectral Clustering approach is then used to automatically extract the pathlets of the scene. We present experimental results from scenes of varying difficulty and compare against other approaches.
5767512
Who, what, when, where, why and how in video analysis: an application centric view###This paper presents an end-user application centric view of surveillance video analysis and describes a flexible, extensible and modular approach to video content extraction. Various detection and extraction components including tracking of moving objects, detection of text, faces, and face based soft biometric for gender, age and ethnicity classification are described within the general framework for real-time and post event analysis applications Panoptes and VideoRecall. Some end-user applications that are built on this framework are discussed.
5597070
Dynamic Sensor Selection for Single Target Tracking in Large Video Surveillance Networks###In this paper an approach for dynamic camera selection in large video-based sensor networks for the purpose of multi-camera object tracking is presented. The sensor selection approach is based on computational geometry algorithms and is able to determine task-relevant cameras (camera cluster) by evaluation of geometrical attributes, given the last observed object position, the sensor configurations and a building map. A special goal of this algorithm is the efficient determination of the minimum number of sensors needed to relocate an object, even if the object is temporarily out of sight. In particular, the approach is applicable in camera networks with overlapping and non-overlapping field of views as well as with static and non-static sensors.
5597088
Pose Estimation of Interacting People using Pictorial Structures###Pose estimation of people have had great progress in recent years but so far research has dealt with single persons.In this paper we address some of the challenges that arise when doing pose estimation of interacting people. We build on the pictorial structures framework and make important contributions by combining color-based appearance and edge information using a measure of the local quality of the appearance feature. In this way we not only combine the two types of features but dynamically find the optimal weighting of them. We further enable the method to handle occlusions by searching a foreground mask for possible occluded body parts and then applying extra strong kinematic constraints to find the true occluded body parts. The effect of applying our two contributions are show through both qualitative and quantitative tests and show a clear improvement on the ability to correctly localize body parts.
5597323
A Framework for an Event Driven Video Surveillance System###In this paper we present an event driven surveillance system. The purpose of this system is to enable thorough exploration of surveillance events. The system uses a client-server web architecture as this provides scalability for further development of the system infrastructure. The system is designed to be accessed by surveillance operators who can review and comment on events generated by our event detection processing modules. The presentation interface is based around a cross between Gmail and YouTube, as we believe these interfaces to be intuitive for ordinary computer operators. Our motivation is to fully utilize the events archived in our database and to further refine the relevant events. We do not just focus on event detection, but are working towards the optimization of event detection. To the best of our knowledge this system provides a novel approach to the technological surveillance paradigm.
5597076
Automatic Detection and Reading of Dangerous Goods Plates###In this paper, we present an efficient solution for automatic detection and reading of dangerous goods plates on trucks and trains. According to the ADR agreement dangerous goods transports are marked with an orange plate covering the hazard class and the identification number for the hazardous substances. Since under real-world conditions high resolution images (often at low quality) have to be processed an efficient and robust system is required. In particular, we propose a multi-stage system consisting of an acquisition step, a saliency region detector (to reduce the run-time), a plate detector, and a robust recognition step based on an Optical Character Recognition (OCR). To demonstrate the system, we show qualitative and quantitative localization/recognition results on two challenging data sets. In fact, building on proven robust and efficient methods, we show excellent detection and classification results under hard environmental conditions at low run-time.
5597133
Robust Dynamic Super Resolution under Inaccurate Motion Estimation###In image reconstruction, dynamic super resolution image reconstruction algorithms have been investigated to enhance video frames sequentially, where explicit motion estimation is considered as a major factor in the performance. This paper proposes a novel measurement validation method to attain robust image reconstruction results under inaccurate motion estimation. In addition, we present an effective scene change detection method dedicated to the proposed super resolution technique for minimizing erroneous results when abrupt scene changes occur in the video frames. Representative experimental results show excellent performance of the proposed algorithm in terms of the reconstruction quality and processing speed.
5597342
A Safe Fault Tolerant Multi-view Approach for Vision-Based Protective Devices###We present a new approach that realizes an image-based fault tolerant distance computation for a multi-view camera system which conservatively approximates the shortest distance between unknown objects and 3D volumes. Our method addresses the industrial application of vision-based protective devices which are used to detect intrusions of humans into areas of dangerous machinery, in order to prevent injuries. This requires hardware redundancy for compensation of hardware failures without loss of functionality and safety. By taking sensor failures during the fusion process of distances from different cameras into account, this is realized implicitly, with the benefit of no additional hardware cost. In particular we employ multiple camera perspectives for safe and non-conservative occlusion handling of obstacles and formulate general system assumptions which are also appropriate for other applications like multi-view reconstruction methods.
5597096
Video Activity Extraction and Reporting with Incremental Unsupervised Learning###The present work presents a new method for activity extraction and reporting from video based on the aggregation of fuzzy relations. Trajectory clustering is first employed mainly to discover the points of entry and exit of mobiles appearing in the scene. In a second step, proximity relations between resulting clusters of detected mobiles and contextual elements from the scene are modeled employing fuzzy relations. These can then be aggregated employing typical soft-computing algebra. A clustering algorithm based on the transitive closure calculation of the fuzzy relations allows building the structure of the scene and characterises the ongoing different activities of the scene. Discovered activity zones can be reported as activity maps with different granularities thanks to the analysis of the transitive closure matrix. Taking advantage of the soft relation properties, activity zones and related activities can be labeled in a more human-like language. We present results obtained on real videos corresponding to apron monitoring in the Toulouse airport in France.
5597102
Dynamics Based Trajectory Segmentation for UAV videos###A novel representation of vehicle trajectories is proposed for applications in trajectory analysis and activity detection. Specifically, a piecewise arc fitting based smoothing algorithm is proposed for denoising the trajectories. A dynamic program is used to find the optimal arc fit to a given trajectory. We motivate the usage of dynamic primitives to parametrize common vehicular activities, and propose a dynamics based trajectory segmentation algorithm. Each primitive is modeled using a second order Auto-Regressive model, and form useful descriptors for a given vehicular trajectory. We evaluate both our trajectory smoothing and dynamic trajectory segmentation algorithm on a real UAV video dataset, and show performance improvements which clearly motivate its wide applicability in a general trajectory analysis system.
5597343
Multi-Camera Analysis of Soccer Sequences###The automatic detection of meaningful phases in a soccer game depends on the accurate localization of players and the ball at each moment. However, the automatic analysis of soccer sequences is a challenging task due to the presence of fast moving multiple objects. For this purpose, we present a multi-camera analysis system that yields the position of the ball and players on a common ground plane. The detection in each camera is based on a code-book algorithm and different features are used to classify the detected blobs. The detection results of each camera are transformed using homography to a virtual top-view of the playing field. Within this virtual top-view we merge trajectory information of the different cameras allowing to refine the found positions. In this paper, we evaluate the system on a public SOCCER dataset and end with a discussion of possible improvements of the dataset.
5279761
Distributed Audio Network for Speech Enhancement in Challenging Noise Backgrounds###This paper presents a new approach to enhance speech based on a distributed microphone network. Each microphone is used to simultaneously classify the input into either one of the noise types or as speech. For enhancing the speech signal a modified spectral subtraction approach is used that utilize the sound information of the entire network to update the noise model even during speech. This improves the reduction of the ambient noise, especially for non-stationary noise types such as street or beach noise. Experiments demonstrate the effectiveness of the proposed system.
5279824
Context-Based Reasoning Using Ontologies to Adapt Visual Tracking in Surveillance###Classical tracking methods are often insufficient when dealing with complex scenarios. In order to solve tracking errors, innovative techniques based on the use of information about the context of the scene have been proposed. Context information ranges from precise measures computed on the pixels of the object neighborhood to high level representations of the entities and the activities of the scene. In this work, we focus on the second approach and propose an ontology-based extension of a general tracking procedure that reasons with abstract context descriptions to improve its accuracy. We describe the design of this extension and how reasoning is performed, as well as its advantages in surveillance scenarios.
5279762
A 3D Face Model for Pose and Illumination Invariant Face Recognition###Generative 3D face models are a powerful tool in computer vision. They provide pose and illumination invariance by modeling the space of 3D faces and the imaging process. The power of these models comes at the cost of an expensive and tedious construction process, which has led the community to focus on more easily constructed but less powerful models. With this paper we publish a generative 3D shape and texture model, the Basel face model (BFM), and demonstrate its application to several face recognition task. We improve on previous models by offering higher shape and texture accuracy due to a better scanning device and less correspondence artifacts due to an improved registration algorithm. The same 3D face model can be fit to 2D or 3D images acquired under different situations and with different sensors using an analysis by synthesis method. The resulting model parameters separate pose, lighting, imaging and identity parameters, which facilitates invariant face recognition across sensors and data sets by comparing only the identity parameters. We hope that the availability of this registered face model will spur research in generative models. Together with the model we publish a set of detailed recognition and reconstruction results on standard databases to allow complete algorithm comparisons.
5280097
MotionSearch: Context-Based Video Retrieval and Activity Recognition in Video Surveillance###Summary form only given. This talk will explore the use of motion information in video surveillance. We will focus primarily on retrieval and activity recognition of motion events in video and sensor databases characterized by multiple interactive motion trajectories. We will present a framework based on tensor decomposition for indexing and retrieval of multiple motion trajectories in video databases. An efficient method for extraction and insertion of partial information in video databases used for multiple motion trajectory representation based on high-order singular value decomposition of tensors will also be provided. We will present a solution to classification and activity recognition of multiple interactive motion trajectories by deriving an extension of hidden Markov models to multiple dimensions. A closed-form solution for the training and classification general forward-backward, expectation-maximization, and Viterbi algorithms for multiple dimensions will be provided for causal systems. An approach to multiple motion trajectory classification and activity recognition based on distributed multidimensional hidden Markov models will be presented for non-causal systems. We will finally introduce a new approach to view-invariance of motion trajectories for unknown and moving cameras based on a null-space matrix representation of motion trajectory information. We will also extend the null-space representation to tensors for view-invariant indexing and retrieval of multiple motion trajectories from unknown and moving cameras. A method for extraction and insertion of partial information into a video database of multiple motion trajectories represented based on null-space tensors is finally presented.
5279823
An Ontology for Event Detection and its Application in Surveillance Video###In this paper, we propose an ontology for representing the prior knowledge related to video event analysis. It is composed of two types of knowledge related to the application domain and the analysis system. Domain knowledge involves all the high level semantic concepts in the context of each examined domain (objects, events, context...) whilst system knowledge involves the capabilities of the analysis system (algorithms, reactions to events...). The proposed ontology has been structured in two parts: the basic ontology (composed of the basic concepts and their specializations) and the domain-specific extensions. Additionally, a video analysis framework based on the proposed ontology is defined for the analysis of different application domains showing the potential use of the proposed ontology. In order to show the real applicability of the proposed ontology, it is specialized for the underground video-surveillance domain showing some results that demonstrate the usability and effectiveness of the proposed ontology.
5279985
Analysis of Time-multiplexed Security Videos###In this paper we present robust statistical methods for segmentation and preprocessing of time-multiplexed videos. We will present hidden Markov and hidden semi-Markov model based real-time detectors and their usage for video segmentation and anomalous event detection. We demonstrate the high performance of our detectors with real-life outdoor videos from low-quality cameras.
5280098
Clustered Synopsis of Surveillance Video###Millions of surveillance cameras record video around the clock, producing huge video archives. Even when a video archive is known to include critical activities, finding them is like finding a needle in a haystack, making the archive almost worthless. Two main approaches were proposed to address this problem: action recognition and video summarization. Methods for automatic detection of activities still face problems in many scenarios. The video synopsis approach to video summarization is very effective, but may produce confusing summaries by the simultaneous display of multiple activities.A new methodology for the generation of short and coherent video summaries is presented, based on clustering of similar activities. Objects with similar activities are easy to watch simultaneously, and outliers can be spotted instantly. Clustered synopsis is also suitable for efficient creation of ground truth data.
5279765
Acoustic Based Surveillance System for Intrusion Detection###This paper describes a surveillance system for intrusion detection which is based only on information derived from the processing of audio signals acquired by a distributed microphone network (DMN). In particular the system exploits different acoustic features and estimates of acoustic event positions in order to detect intrusion and reject possible false alarms that may be generated by sound sources inside and outside the monitored room. An evaluation has been conducted in order to measure the performance in terms of false alarms and missed alarms in presence of acoustic events produced inside and outside a test room.The obtained results are very promising and encouraging for future works aimed at improving the actual system accuracy.
5280019
A Flexible Surveillance System Architecture###Traditional multimedia surveillance systems are task specific and tightly coupled to the environment. Moreover, system designs generally start with the assumption that the environment, context, and sensors always remain static. With such a tight coupling, it becomes very difficult to port the system to new environments. Furthermore, for most of the systems, there is no straightforward way to upgrade the existing system to incorporate technological advancements such as new sensors or novel feature extraction techniques. We propose a flexible surveillance system architecture which can be easily ported in different environments, is dynamic without any significant compromise in system performance, and can be extended to integrate newer technological developments. We also introduce the notion of environment model (EM), which completely defines the coupling between system and the physical environment. The isolation of environment specific variables in EM makes the system easily portable in different environments. We present results of a prototype implementation of the system that highlights our design goals.
5279698
Event Composition with Imperfect Information for Bus Surveillance###Demand for bus surveillance is growing due to the increased threats of terrorist attack, vandalism and litigation. However, CCTV systems are traditionally used in forensic mode, precluding an in-time reaction to an event. In this paper, we introduce a real-time event composition framework which can support the instant recognition of emergent events based on uncertain or imperfect information gathered from multiple sources. This framework deploys a rule-based reasoning component that can infer malicious situations (composite events) from a set of correlated atomic events. These are recognized by applying analytic algorithms to the multimedia contents of bus surveillance data. We demonstrate the significance and usefulness of our framework with a case study of an on-going bus surveillance project.
5279695
Combination of Roadside and In-vehicle Sensors for Extensive Visibility Range Monitoring###Fog is a local meteorological phenomena which drastically reduces the visibility range. Fog detection and visibility range estimation are critical tasks for road operators who need to warn the drivers and advise them on speed reductions. To achieve this task, fixed sensors are quite accurate but they have a reduced spatial cover. Mobile sensors are less accurate, but they have a good spatial cover. Based on the combination of roadside sensors and in-vehicle devices (sensors or fog lamps), a data fusion framework is presented aiming at taking the advantages of both fixed and mobile sensors for the extensive detection and estimation of the fog density. The proposed solution is implemented by means of a local dynamic map fed by vehicle to infrastructure (V2I) communication, which gives a coherent view of the road environment.
5279694
Cooperative Object Tracking and Event Detection with Wireless Smart Cameras###Wireless embedded smart cameras not only capture images, but also can perform processing and communication. However,many system- and algorithm-wise challenges remain to be addressed to have operational, battery-powered wireless smart-camera networks, since they have limited processing power, memory, energy and bandwidth. In this paper, we present a wireless, embedded smart camera system for cooperative object tracking and event detection, wherein each camera platform consists of a camera board and a wireless mote. Light-weight background subtraction and tracking algorithms are implemented and run on the camera boards. Cameras communicate in a peer-to-peer manner over wireless links to exchange data, and thus to consistently track objects. In a wireless smart camera system, transferring large amounts of data between cameras should be avoided, since it requires more power, and incurs more communication delay. In the presented system, cameras exchange small-size packets for communication. Also, with wireless smart cameras, it is not viable to transfer all the captured frames to a base station due to limited resources. Instead, we define events of interest beforehand, and embedded smart cameras save only those portions of the live video capture where the defined event scenario occurs. We present results of tracking and detecting objects entering a region of interest, all of which are performed on the microprocessor of camera boards. We also show examples of consistently tracking objects, moving across different camera views, by wireless data exchange.
5279697
Automatic Components of Integrated CCTV Surveillance Systems: Functionality, Accuracy and Confidence###Recent societal events and advances in computer vision technology have lead to the development of a variety of automatic surveillance systems. Despite their arguable success in the laboratory, fully automatic methods remain unsuitable for use in real life situations due to the complex nature of the context in which they must operate. Current techniques may, however, be immediately valuable if deployed as components of integrated human-automatic CCTV surveillance systems. It is therefore important to understand the potential of current automatic methods and provide design recommendations for semi-automatic systems, so that work to date can be exploited in full. An experiment was conducted to investigate the importance of the functionality and level of accuracy of, and feedback provided by, the automatic component of an integrated, semi-automatic CCTV surveillance system. The operatorspsila workload and spare attentional capacity was measured to investigate the effect of each of these factors. Results showed significant reduction in workload when reliable confidence information is fed back. Increases in accuracy and variation in functionality failed to produce evidence of change in workload.
5279519
Explicit 3D Modeling for Vehicle Monitoring in Non-overlapping Cameras###Vehicles are indispensable in modern life. The capability of monitoring them over a long range can play significant roles in many surveillance applications. However, due to high mobility of vehicles, tracking them is difficult and we need to utilize a large network of cameras and reason on discrete sets of observations made from non-overlapping cameras. In this paper, we introduce enabling techniques for such a surveillance need. Specifically, we build explicit 3D models and use them for vehicle signature extraction and matching. The algorithm uses a single active shape model (ASM) for all consumer vehicles. After detecting presence of a vehicle, eg, by background subtraction, our algorithm then reconstructs a texture mapped 3D model. 3D car models enable us to monitor vehicles in many novel ways otherwise impossible. Two use cases are provided.
5279459
Automatic Gait Recognition Using Weighted Binary Pattern on Video###Human identification by recognizing the spontaneous gait recorded in real-world setting is a tough and not yet fully resolved problem in biometrics research. Several issues have contributed to the difficulties of this task. They include various poses, different clothes, moderate to large changes of normal walking manner due to carrying diverse goods when walking, and the uncertainty of the environments where the people are walking. In order to achieve a better gait recognition, this paper proposes a new method based on Weighted Binary Pattern (WBP). WBP first constructs binary pattern from a sequence of aligned silhouettes. Then, adaptive weighting technique is applied to discriminate significances of the bits in gait signatures. Being compared with most of existing methods in the literatures, this method can better deal with gait frequency, local spatial-temporal human pose features, and global body shape statistics. The proposed method is validated on several well known benchmark databases. The extensive and encouraging experimental results show that the proposed algorithm achieves high accuracy, but with low complexity and computational time.
5279454
Night-Time Traffic Surveillance: A Robust Framework for Multi-vehicle Detection, Classification and Tracking###Traffic data extraction is an increasing demand for applications such as traffic lights control, population evacuation, or to reduce traffic issues including congestion, pollution, delays, and accidents. We present in this paper a new framework to reliably detect, classify and track multiple vehicles at night-time. The system shows excellent performance after an evaluation procedure involving many cameras and different conditions. The vehicle detection consists of detecting its two headlights. To avoid false positives and make the detector reliable, a second stage seeks clues of vehiclepsilas presence through a decision tree composed of feature-based and appearance-based classifiers. Finally, the vehicles are tracked over frames. A Kalman filter is associated with a reasoning module. The tracker is designated to be fast, stable, as well as dealing safely with partial and total occlusions.
5279453
A Critical Assessment of 2D and 3D Face Recognition Algorithms###We present the results of a project aimed to evaluate 2D and 3D face recognition algorithms. In particular, we focused on the potentialities of 3D-based techniques to overcome typical limitations of 2D methods in non-controlled situations. According to the reference scenario of people identification at airport check points, we built a representative database on which we tested different face recognition algorithms. We implemented and tested an improved version of a well-known state-of-the-art 3D approach, and verified that on our dataset it performs better than a widely used commercial system.
5279618
Fast Compressed Domain Motion Detection in H.264 Video Streams for Video Surveillance Applications###This paper presents a novel approach to fast motion detection in H.264/MPEG-4 advanced video coding (AVC) compressed video streams for IP video surveillance systems. The goal is to develop algorithms which may be useful in a real-life industrial perspective by facilitating the processing of large numbers of video streams on a single server. The focus of the work is on using the information in coded video streams to reduce the computational complexity and memory requirements, which translates into reduced hardware requirements and costs. The devised algorithm detects and segments activity based on motion vectors embedded in the video stream without requiring a full decoding and reconstruction of video frames. To improve the robustness to noise, a confidence measure based on temporal and spatial clues is introduced to increase the probability of correct detection. The algorithm was tested on indoor surveillance H.264 sequences.
5279539
Video Analytics in Urban Environments###Urban environments present unique challenges from the perspective of surveillance and security. Threat activity in urban environments tends to be very similar to background activity, while the volume of activity is often very high. The widespread geographical area presents issues from the perspective of response. These characteristics of urban environments create challenges to traditional applications of video analytics technologies and opens up opportunities for novel approaches. This paper explores the applicability of video analytics in various scenarios presented in urban surveillance situations. We also describe novel technical solutions to some of the challenges of urban surveillance.
5279677
Combined Motion and Appearance Models for Robust Object Tracking in Real-Time###This paper proposes a tracking architecture that finds a trade-off between accuracy and efficiency, via a combined solution of motion and appearance information. We explore the use of color features into a tracking pipeline based on Kalman filtering. The devised architecture is made of simple modules, combined to reach a robust final result, while keeping the computation cost low (we perform 20 fps). The method has been evaluated on three benchmark datasets and is currently under use on real video-surveillance systems, reporting very good tracking results.
5279851
AVSS Multiple Camera Person Tracking Challenge Evaluation Overview###Technologies that track a specific person as they traverse a network of surveillance cameras can be used as the basis for a multitude of video surveillance applications including mass transit monitoring, large venue security, building security, and the like. In order to continue supporting the development robust people tracking technologies, the first AVSS Multiple Camera Person Tracking (MCPT) Challenge Evaluation was established to provide data and evaluation resources for researchers to build Single Person Tracking (SPT) technologies. This special session will focus on the AVSS MCPT Challenge Evaluation which will include a description of the evaluation task, the i-LIDS Multiple-camera tracking scenario data set used for the evaluation, and presentations by the challenge evaluation participants describing their systems.
5279986
Association and Identification in Heterogeneous Sensors Environment with Coverage Uncertainty###In this paper, we present an approach for providing dynamic object association and identification in heterogeneous sensor networks where identification sensors have coverage uncertainty. Detection uncertainty of identifications by the coverage uncertainty is managed by grouping unassociated identifications. In the system, visual sensors find corresponding objects between cameras by using homographic lines and track them by using multi-camera localization scheme. Identification sensors (i.e., RFID system, fingerprint or iris recognition system) are incorporated into the tracking system for objects identification. This paper elaborates possible identification cases and necessary conditions with the coverage uncertainty of identification sensors. Finally, the proposed association method is evaluated with a realistic simulation.
5280086
Bayesian Bio-inspired Model for Learning Interactive Trajectories###Automatic understanding of human behavior is an important and challenging objective in several surveillance applications. One of the main problems of this task consists in accurately defining models able to characterize in a discriminative but, at the same time, enough general way people actions. In this work a bio-inspired model is proposed to represent people interactions in a Bayesian framework using their patterns of movement. Couples of observed interacting trajectories are encoded into a Dynamic Bayesian Network (DBN) model where states and conditional probability densities are learned in an online manner in order to statistically describe interactions. Observed trajectories are processed by the Instantaneous Topological Map (ITM) algorithm that automatically creates a topological map used to define the states of the DBN. The transition probabilities are estimated by combining states frequency of occurrence, evaluated by a voting-based approach, and their temporal occurrence represented by Gaussian Mixture Models. The discriminative capabilities of this model to detect interactions are shown both in a simulated and in a real-world environment.
5279779
Omni-directional Polarization Image Sensor Based on an Omni-directional Camera and a Polarization Filter###An effective method for detecting road surface conditions is the use of polarization features. In this paper we describe this method, for which we use two cameras for taking vertical and horizontal polarized images simultaneously. Generally, camera calibrations have to be processed, however in this paper we explain how we managed to avoid this processing, by introducing the omni-directional polarization image capture method, using an omni-directional camera and a polarization filter. This method enables to take vertical and horizontal polarized images at the same time, without using the camera calibration.
5279775
Turning Surveillance Video into Structured Information and Actionable Events###Network-centric smart video surveillance has witnessed a surge of interest from both diverse business sectors and research communities over the last decade. BT's recent transformation from a dominant fixed line Telco in the UK to a leading networked ICT service provider worldwide has spurred our researches in this and allied field so as to provide value-added services and solutions, addressing the increasing needs of security, safety, cost reduction and intelligence gathering from multi-national corporate customers. Our research has been of both an applied nature, creating end-to-end robust solutions here and now, and as an enabler to track state-of-the-art technology trend allowing for innovative business propositions for emerging applications. In this presentation, I'll discuss several recent research projects within our Visual Computing and Multimedia Understanding Theme. These include real-time crowd congestion gauging; abnormal activities visualisation and detection in nonlinear subspace; skimming video from news genre to home videos; mixed traffic counting at distance, etc. In each case, a brief review is given in respect of the project's objective, practical challenges, technical approach and evaluation procedure. Video examples will then be shown to demonstrate the promising results obtained in realistic video scenarios, and to point out any opening problems. Where appropriate we will also discuss the issues how to bridge the gap between a prototype video analytic function and its applicability in real-time real-world surveillance environment.
5279913
A model change detection approach to dynamic scene modeling###In this work we propose a dynamic scene model to provide information about the presence of salient motion in the scene, and that could be used for focusing the attention of a pan/tilt/zoom camera, or for background modeling purposes. Rather than proposing a set of saliency detectors, we define what we mean by salient motion, and propose a precise model for it. Detecting salient motion becomes equivalent to detecting a model change. We derive optimal online procedures to solve this problem, which enable a very fast implementation. Promising results show that our model can effectively detect salient motion even in severely cluttered scenes, and while a camera is panning and tilting.
5279566
A Robust and Efficient Approach for Human Tracking in Multi-camera Systems###In this paper, a robust and efficient approach for multicamera human tracking is presented. The approach is integrated in an experimental surveillance system, based on a camera network with a task-oriented architecture. At sensor level, image processing algorithms are applied for object detection and feature extraction. Additionally, for each object that is to be tracked, an agent-based multi-sensor process is created, which autonomously performs multi-sensor data association and fusion. One of the major challenges in such systems is to robustly determine correspondences between observations from different sensors with different environmental conditions. Therefore, in this paper, efficient and robust spacial and appearance features for object description and recognition are proposed. For spacial description an approximated object position in world coordinates is estimated and evaluated by an inconsistency detector before associated to a Kalman filter. For appearance similarity calculation, an appearance model is proposed and a similarity metric based on the earth moverpsilas distance (EMD) is presented. Finally, the data fusion algorithm based on these features for tracking objects in overlapping and non-overlapping camera networks is presented.
5280001
Digital Video Event Detector Framework for Surveillance Applications###The paper introduces a video surveillance and event detection framework and application for semi-supervised surveillance use. The systempsilas intended use is in automatic mode on camera feeds that are not actively watched by surveillance personnel, and should raise alarms when unusual events occur. We present the current detector filters, and the extendable modular interface. Filters include local and global unusual motion detectors, left/stolen object detector, motion detector, tampering/failure detector, etc. The system stores the events and associated data, which can be organized, searched, annotated and (re)viewed. It has been tested in real life situation for police street surveillance.
5279680
Regressed Importance Sampling on Manifolds for Efficient Object Tracking###In this paper, a new integrated particle filter is proposed for video object tracking. After particles are generated by importance sampling, each particle is regressed on the transformation space where the mapping function is learned offline by regression on pose manifold using Lie algebra, leading to a more effective allocation of particles. Experimental results on synthetic and real sequences clearly demonstrate the improved pose (affine) tracking performance of the proposed method compared with the original regression tracker and particle filters.
5279681
Object Tracking from Unstabilized Platforms by Particle Filtering with Embedded Camera Ego Motion###Visual tracking with moving cameras is a challenging task. The global motion induced by the moving camera moves the target object outside the expected search area, according to the object dynamics. The typical approach is to use a registration algorithm to compensate the camera motion. However, in situations involving several moving objects, and backgrounds highly affected by the aperture problem, image registration quality may be very low, decreasing dramatically the performance of the tracking. In this work, a novel approach is proposed to successfully tackle the tracking with moving cameras in complex situations, which involve several independent moving objects. The key idea is to compute several hypotheses for the camera motion, instead of estimating deterministically only one. These hypotheses are combined with the object dynamics in a particle filter framework to predict the most probable object locations. Then, each hypothetical object location is evaluated by the measurement model using a spatiogram, which is a region descriptor based on color and spatial distributions. Experimental results show that the proposed strategy allows to accurately track an object in complex situations affected by strong ego motion.
5280004
A Semi-automatic System for Ground Truth Generation of Soccer Video Sequences###The problem of ground truth generation is fundamental for many approaches of computer vision and image processing. In order to test algorithms for object segmentation, object tracking, object interactions, it is necessary to have image sequences in which the ground truth is determined in an objective way. In the context of visual surveillance where many people moves in the scene occluding each other, it could be very complex and hard the work of generating for each image the position of all the moving objects and maintain this information for all the period in which they remain in the scene. In this paper we propose a semi-automatic system that generates an initial ground truth estimation, and then provides a user-friendly interface to manually validate or correct the track results. The proposed system has been tested on some soccer video sequences that have been published on-line for being available to the scientific community, but it can be used also in other surveillance contexts.
5279786
Architectural Considerations for Video Content Analysis in Urban Surveillance###Successfully deploying video content analysis (VCA) solutions for urban surveillance poses significant challenges for manufacturers and system integrators. Urban surveillance is typically characterized by a very large number of cameras (thousands and more) distributed over a large area and installed in both outdoor and indoor views. From the user perspective the primary rule of the surveillance system is to provide quick, reliable and high quality access to live and recorded video streams from all cameras. VCA is considered an important but secondary functionality that is required in order to provide features such as real time alerts for predefined rules, forensic search capabilities, statistical analysis of crowd and traffic flow and more. Ideally the user would like to have some form of VCA functionality for every camera deployed. In an urban environment the VCA system is required to handle a variety of detection tasks dealing with people, vehicles and objects and their behaviors and interactions with each other. Given unlimited computational resources this task is still a very challenging one and is expected to require significant research from the industry and academia in the foreseeable future. In a real life deployment where cost is a major factor the availability of sufficient computing resources for VCA becomes a limiting factor which may severely limit the usability of such a technology in a large scale installation. By nature of being a complementary system component, a VCA system deployment is expected to provide good detection performance (high POD and low FAR) while maintaining the following critical conditions: (a) acceptable cost relative to the other components and ( b) minimal impact on the performance of other system features. Additional considerations for such a deployment are: (c) complexity of setting up and configuring the analytics (d) ease of management and maintenance (e) upgrade path. This presentation will analyze the strengths and weaknes- ses of known VCA deployment architectures namely "server based" and "edge based" in the context of a large scale deployment scenario and will demonstrate an alternative architecture developed and patented by Agent Vi. This proven architecture known as image processing over IP networks (IPoIP) enables providing the end user with a system that scores very highly on all points (a)-(e) mentioned above. The cost/performance advantage of IPoIP is achieved through distribution of the VCA task between the edge device (IP camera or video encoder) and a server. The edge device is tasked with performing the initial analysis of the video stream and extracting information which is relevant in the context of video scene analysis. This information sent to the server as a continuous data stream where it is further analyzed and turned into metadata describing the objects in each and every camera view. The generated metadata is recorded for later offline search functionality and also analyzed in real time to detect deviation from any user defined rule and if this is detected an appropriate event is generated and distributed to any listening client. Using this architecture it is possible to support full VCA functionality for all cameras in a large surveillance installation with a minimal cost overhead while maintaining very high and feature rich performance.
5279448
Real-Time Moving Object Detection for Video Surveillance###A common method for real time moving object detection in image sequences is background removal, also referred to as background subtraction. The numerous approaches differ in the type of background model used and the procedure used to update the model. This paper discusses modeling each 4 times 4 pixel patch of an image through a set of coefficient vectors which are obtained by means of a discrete cosine transform. The amount of vectors used to model a patch is adapted online for each patch separately. In contrast to most other background removal techniques foreground detection and background adaptation procedure also incorporates temporal and spacial characteristics of an object motion. The presented methods was shown to be very robust to arbitrary changes in the observed environment and was successfully tested in several video surveillance scenarios.
5279449
Hybrid Background Model Using Spatial-Temporal LBP###Background modeling has been widely researched to detect moving objects from image sequences. It is necessary to adapt the background model various changes of illumination condition. A hybrid type of background model which consists of more than one background model has been used for object detection since it is very robust for illumination changes. In this paper, we also propose a new hybrid type of background model named "hybrid spatial-temporal background model". Our model consists of two different kinds of background models. One is pixel-level background model which is robust for long-term illumination changes. The other is spatial-temporal background model which is robust for short-term illumination changes. Our experimental results demonstrate superiority of our method to some related works.
5279445
Creating Human Activity Recognition Systems Using Pareto-based Multiobjective Optimization###This paper presents a method based on feature selection to obtain sets of human activity recognizers of different complexity. Classifiers for human activity recognition are built exploring a space of candidate feature subsets, trying to maximize the accuracy of a classifier trained with them. At the same time, the size of the selected feature subset is minimized. The accuracy of a classifier tends to grow with the number of features, but in a real time task, like human activity recognition, the number of features used has to be minimized, because its growing involves a slower processing rate. A set of solutions with different trade-offs between accuracy and number of features may be achieved modeling the problem of feature selection using multiobjective optimization (MO), where both measures are optimized at the same time. To solve the MO problem, multiobjective optimization evolutionary algorithms (MOEA) are going to be used. MOEA methods based on Pareto dominance not only find an optimal solution for the problem, they find a set of different optimal solutions so called Pareto-optimal set. A set of activity recognizers of different complexities is found using this approach. Having a set of different solutions allows the designer to choose the one that best fits its requirements. The method will be applied using a hidden Markov model as classifier. Results of the use of the method for recognizing different instantaneous human activities are discussed.
5279665
Real-Time Adaptive Camera Tamper Detection for Video Surveillance###Criminals often resort to camera tampering to prevent capture of their actions. Real-time automated detection of video camera tampering cases is important for timely warning of the operators. Tampering is generally done by obstructing the camera view by a foreign object, displacing the camera and changing the focus of the camera lens. In automated camera tamper detection systems, low false alarm rates are important as reliability of these systems is compromised by unnecessary alarms and consequently the operators start ignoring the warnings. We propose adaptive algorithms to detect and identify such cases with low false alarms rates in typical surveillance scenarios where there is significant activity in the scene.
5279666
Privacy-Enabled Object Tracking in Video Sequences Using Compressive Sensing###In a typical video analysis framework, video sequences are decoded and reconstructed in the pixel domain before being processed for high level tasks such as classification or detection.Nevertheless, in some application scenarios, it might be of interest to complete these analysis tasks without disclosing sensitive data, e.g. the identity of people captured by surveillance cameras. In this paper we propose a new coding scheme suitable for video surveillance applications that allows tracking of video objects without the need to reconstruct the sequence,thus enabling privacy protection. By taking advantage of recent findings in the compressive sensing literature, we encode a video sequence with a limited number of pseudo-random projections of each frame. At the decoder, we exploit the sparsity that characterizes background subtracted images in order to recover the location of the foreground object. We also leverage the prior knowledge about the estimated location of the object, which is predicted by means of a particle filter, to improve the recovery of the foreground object location. The proposed framework enables privacy, in the sense it is impossible to reconstruct the original video content from the encoded random projections alone, as well as secrecy, since decoding is prevented if the seed used to generate the random projections is not available.
5279667
Object Tracking via Multi-region Covariance and Particle Swarm Optimization###In this paper a particle swarm optimization based algorithm for object tracking in surveillance videos is proposed. Given the estimate of the object state, the particles are drawn from a Gaussian distribution in order to cover the promising object locations. The particle swarm optimization takes place afterwards in order to concentrate the particles near the true state of the object. The optimization aims at shifting the particles towards more promising regions in the search area. The region covariance is utilized in evaluation of the particle score. The object template is represented by multiple object patches. Every patch votes for the considered position of the object undergoing tracking. Owing to robust combining of such patch votes the object tracker is able to cope with considerable partial occlusions. A tracking algorithm built on the covariance score can recover after substantial temporal occlusions or large movements. Through the usage of multi-patch object representation the algorithm posses better recovery capabilities and it recovers earlier. Experimental results that were obtained in a typical office environment as well as surveillance videos show the feasibility of our approach, especially when the object undergoing tracking has a rapid motion or the occlusions are considerable. The resulting algorithm runs in real-time on a standard computer.
5279661
Object-Video Streams for Preserving Privacy in Video Surveillance###This paper presents a framework for preserving privacy in video surveillance. Raw video is decomposed into a background and one or more object-video streams. Object-video streams can be combined to render the scene in a variety of ways: (1) The original video can be reconstructed from object-video streams without any data loss; (2) individuals in the scene can be represented as blobs, obscuring their identities; (3) foreground objects can be color coded to convey subtle scene information to the operator, again without revealing the identities of the individuals present in the scene; (4) the scene can be partially rendered, i.e., revealing the identities of some individuals, while preserving the anonymity of others. We evaluate our approach in a virtual train station environment populated by autonomous, lifelike virtual pedestrians.
5279662
Global Illumination Compensation for Background Subtraction Using Gaussian-Based Background Difference Modeling###This paper presents a background segmentation technique, which is able to process acceptable segmentation masks under fast global illumination changes. The histogram of the frame-based background difference is modeled with multiple kernels. The model that represents the histogram at best, is used to determine the shift in luminance due to global illumination or diaphragm changes, such that the background difference can be compensated. Experimental results have revealed that the number of incorrectly classified pixels using global illumination compensation instead of only the approximated median method reduces from 77% to 19% shortly after a fast change. The performance of the proposed technique is similar to state-of-the-art related work for global illumination changes, despite the fact that only luminance information is used. The algorithm is computationally simple and can operate at 30 frames-per-second for VGA resolution on a P-IV 3-GHz PC.
5279719
A Sampling Algorithm for Occlusion Robust Multi Target Detection###Bayesian methods for visual tracking, with the particle filter as its most prominent instance, have proven to work effectively in the presence of clutter, occlusions, and dynamic background. When applied to track a variable number of targets, however, they become inefficient due to the absence of strong priors. In this paper we present an efficient sampling algorithm for target detection build upon an informed prior that is derived as the inverse of an occlusion robust image likelihood. It has the advantage of being fully integrated in the Bayesian tracking framework, and reactive as it uses sparse features not explained by tracked objects.
5279701
Multi-view Object Localization in H.264/AVC Compressed Domain###This paper presents a multi-view homography-based approach for object localization in H.264/AVC compressed video surveillance sequences. The proposed novel, low-complexity method is able to accurately localize moving objects on a ground plane using multiple camera data. Contrary to existing work that exploits motion vectors for object detection and tracking, our compressed domain multi-view object localization solely uses macroblock (MB) partition information. Foreground segmentation is performed on single view compressed video data using MB partition-based temporal differencing. Blob merging, convex hull fitting and noise removal are applied on the resulting foreground views to extract objects. Once relevant objects are found in single views, they are projected onto a ground plane by exploiting the homography constraint. Since projected foreground MB views of multiple cameras will only overlap on points where foreground intersects the ground plane, object locations can be extracted by detecting local maxima on the accumulated ground plane image.
5279700
Virtual Vision: Simulating Camera Networks in Virtual Reality for Surveillance System Design and Evaluation###Summary form only given. The author reviews his research with Faisal Qureshi towards smart camera networks capable of carrying out advanced surveillance tasks with little or no human supervision. A unique centerpiece of our work is the combination of computer vision, computer graphics, and artificial life simulation technologies to develop such networks and experiment with them. Our prototype simulator has enabled us to readily develop and experiment with smart camera networks comprising static and active simulated video surveillance cameras that provide extensive coverage of a large virtual public space, a train station populated by autonomously self animating virtual pedestrians. The simulated networks of smart cameras perform persistent visual surveillance of individual pedestrians with minimal intervention. Our virtual vision simulator has been a potent tool in our quest for innovative camera control strategies that naturally address camera aggregation and handoff, are robust against camera and communication failures, and require no camera calibration, detailed world model, or central controller.
5279668
Privacy Protection in Video Surveillance Systems Using Scalable Video Coding###Thanks to high-speed Internet access and feature-rich mobile devices, the demand for ubiquitous and secure surveillance systems has increased. In this paper, we propose a privacy-protected video surveillance system that makes use of scalable video coding (SVC). SVC can be used to fulfill the requirement of omnipresence. Further, to address privacy concerns, we detect face regions and subsequently scramble these regions-of-interest (ROIs) in the compressed domain. To demonstrate the feasibility of the proposed video surveillance system, simulation results are provided. The results show that our system is able to provide a good level of security, while offering access to surveillance video content in heterogeneous usage environments.
5279704
Multi-sensor Multi-cue Fusion for Object Detection in Video Surveillance###We here present a multi-sensor data fusion architecture that takes into account the performance of video sensors in detecting moving targets for video surveillance purposes. Target detection and tracking is performed via classification by an ensemble of classifiers learned online using heterogeneous features for each target. A novel approach is then used to estimate the position of the target on the ground plane map by temporally fusing likelihood maps, then by approximating likelihoods analytically by a Gaussian function, and eventually projecting and fusing the likelihood functions. Experimental results are shown on real-world video sequences.
5279967
Super-Resolution of Moving Vehicles Using an Affine Motion Model###This study addresses the problem of motion estimation and image registration for super-resolution (SR) algorithms. It appears that, simple assumptions such as planar motion are not always appropriate for dealing with real surveillance video of unconstrained moving objects. A new SR algorithm based on an affine motion model is developed and evaluated on a database, which contains videos of urban scene. Experiments show improved SR performances with respect to methods using only planar motion.
5279968
Dynamic Performance Measures for Object Tracking Systems###Performance evaluation of object tracking systems is typically performed after the data has been processed, by comparing tracking results to ground truth. Whilst this approach is fine when performing offline testing, it does not allow for real-time analysis of the systems performance, which may be of use for live systems to either automatically tune the system or report reliability. In this paper, we propose three metrics that can be used to dynamically asses the performance of an object tracking system. Outputs and results from various stages in the tracking system are used to obtain measures that indicate the performance of motion segmentation, object detection and object matching. The proposed dynamic metrics are shown to accurately indicate tracking errors when visually comparing metric results to tracking output, and are shown to display similar trends to the ETISEO metrics when comparing different tracking configurations.
5279471
Vehicle Tracking Using Projective Particle Filter###This article introduces a new particle filtering approach for object tracking in video sequences. The projective particle filter uses a linear fractional transformation, which projects the trajectory of an object from the real world onto the camera plane, thus providing a better estimate of the object position. In the proposed particle filter, samples are drawn from an importance density integrating the linear fractional transformation. This provides a better coverage of the feature space and yields a finer estimate of the posterior density. Experiments conducted on traffic video surveillance sequences show that the variance of the estimated trajectory is reduced, resulting in more robust tracking.
5279472
Traffic Density Estimation with On-line SVM Classifier###Information on the vehicular traffic density in an intelligent transport system (ITS) is presently obtained mainly through loop detectors (LD), traffic radars and surveillance cameras. However, the difficulties and cost of installing loop detectors and traffic radars tend to be significant. Currently, a more advanced method of circumventing this is to develop a sort of virtual loop detector (VLD) by using video content understanding technology to simulate behavior of a loop detector and to further estimate the traffic flow from a surveillance camera. Such a virtual loop detector that requires supervised training with human intervention for its setup. Difficulties also arise when attempting to obtain a reliable and real-time VLD under different illumination, weather conditions and static shadows. In this paper, we study the effectiveness of texture features in describing the traffic density, and propose a real-time VLD based on on-line SVM classifier and a background modeling technique (OSVM-BG) to estimate the traffic density information probabilistically and automatically. The system uses feedback from background modeling to train and update its SVM kernel to self-adapt to various lighting environments. Experimental results show that the system outperforms an existing algorithm and achieves an average accuracy of 89.43% under various illumination changes, weather conditions and especially changing static shadows in daytime.
5279651
Robust Motion Detection via the Fuzzy Fusion of 6D Feature Space Decompositions###A change detection framework which fuses both spatial and temporal data using fuzzy if-then rules is presented. Temporal data is used on a per-pixel basis to monitor the sequence for changes by employing a fuzzy codebook model. Spatial data is gathered using a fuzzy multithresholding algorithm that decomposes the RGB color space into three color pair histograms. This system is found to be robust to noise and allows the algorithm to process successfully even when the underlying sequences result in under-segmentation of the spatial data.
5279650
Bayesian Order-Consistency Testing with Class Priors Derivation for Robust Change Detection###In this paper we propose a formalization of change detection as a Bayesian order-consistency test, based on the assumption that disturbance factors such as illumination changes and variations of camera parameters do not change the ordering between noiseless intensities within a neighborhood of pixels. The assumption of additive, zero-mean, i.i.d. gaussian noise allows for testing the composite order-consistency hypothesis by efficient computation of the marginal likelihood. Moreover, since the above formalization enables to incorporate changed/unchanged class priors seamlessly, we also propose a simple method to derive informative priors based on the calculation of marginal likelihoods at reduced resolution. Experimental results on challenging test sequences characterized by sudden and strong illumination changes prove the effectiveness of the proposed approach.
5279652
Segmentation of Motion Objects from Surveillance Video Sequences Using Temporal Differencing Combined with Multiple Correlation###Identifying moving objects from a video sequence is a fundamental and critical task in many computer vision applications. We develop an efficient adaptive segmentation algorithm for color video surveillance sequence in real time with non-stationary background; background is modeled using multiple correlation coefficient using pixel-level based approach. At runtime, segmentation is performed by checking color intensity values at corresponding pixels P(x,y) in three frames using temporal differencing (frame gap three). The segmentation starts from a seed in the form of 3times3 image blocks to avoid the noise. Usually, temporal differencing generates holes in motion objects. After subtraction, holes are filled using image fusion, which uses spatial clustering as criteria to link motion objects. The emphasis of this approach is on the robust detection of moving objects even under noise or environmental changes (indoor as well as outdoor).
5279492
Relating "Pace' to Activity Changes in Mono- and Multi-camera Surveillance Videos###More and more cameras are being installed everyday for safety, security and intelligence gathering purposes, making the volume of storage videos increase all the time. It is therefore important to manage this resource to be able to cast a structured (hierarchical) view into the activities of long video files to catalogue only interesting or relevant domain events. This paper aims to address this issue by proposing a novel and efficient computational approach to ascertaining semantic segmentation of scene activities exhibited in monocular or multi-view surveillance videos. The key to achieve this is to derive the so-called dasiapacepsila descriptor, reflecting the change in underlying scene activities of a surveillance site, based on detecting key scene frames and modeling its temporal distribution. The former is performed by extracting 2D or 3D appearance-based subspace embedding features, followed by a time-constrained agglomerative data clustering. The latter models the density of such key frames distribution in the time domain, and then applies a visual curve segmentation algorithm to identify scene segments of different activities. The approach is especially suited for crowd scene segmentation, and it has been evaluated with real-world surveillance videos of both underground platforms and a busy industrial park entrance in rush hours with promising results.
5279491
Multisensor Fusion for Monitoring Elderly Activities at Home###In this paper we propose a new multisensor based activity recognition approach which uses video cameras and environmental sensors in order to recognize interesting elderly activities at home. This approach aims to provide accuracy and robustness to the activity recognition system. In the proposed approach, we choose to perform fusion at the high-level (event level) by combining video events with environmental events. To measure the accuracy of the proposed approach, we have tested a set of human activities in an experimental laboratory. The experiment consists of a scenario of daily activities performed by fourteen volunteers (aged from 60 to 85 years). Each volunteer has been observed during 4 hours and 14 video scenes have been acquired by 4 video cameras (about ten frames per second). The fourteen volunteers were asked to perform a set of household activities, such as preparing a meal, taking a meal, washing dishes, cleaning the kitchen, and watching TV. Each volunteer was alone in the laboratory during the experiment.
5280101
Video and Signal Based Surveillance for Airport Applications###In this paper a comparative study of three ground traffic surveillance systems for airports based on different sensing technologies is presented. The first two solutions are based on video-based surveillance, while the third one is based on signal-based surveillance. More specifically, the first solution employs a network of smart cameras, whereas the second utilizes multiple autonomous tracking units to capture and process images from one or more pre-calibrated cameras. The third solution is based on a novel magnetic sensing technology, which detects ferromagnetic objects such as vehicle motors, aircraft engines and landing gears through their deformation of the Earthpsilas magnetic field. Evaluation and analysis of the performance of these systems, based on real test results in different European airports are presented. The proposed systems are flexible, scalable and suitable for a broad field of monitoring and surveillance applications.
5279464
Incremental EM for Probabilistic Latent Semantic Analysis on Human Action Recognition###Human action recognition is a significant task in automatic understanding systems for video surveillance. Probabilistic Latent Semantic Analysis (PLSA) model has been used to learn and recognize human actions in videos. Specifically, PLSA employs the expectation maximization (EM) algorithm for parameter estimation during the training. The EM algorithm is an iterative estimation scheme that is guaranteed to find a local maximum of the likelihood function. However its convergence usually takes a large number of iterations. For action recognition with large amount of training data, this would result in long training time. This paper presents an incremental version of EM to speed up the training of PLSA without sacrificing performance accuracy. The proposed algorithm is tested on two challenging human action datasets. Experimental results demonstrate that the proposed algorithm converges with fewer number of full passes compared with the batch EM algorithm. And the trained PLSA models achieve comparable or better recognition accuracies than those using batch EM training.
5279780
What Would You Pay for Automated Video Analysis?###A review of commercial and research applications of automated video analysis in the Americas, EMEA and Asia a) offers a snapshot of the state-of-the-art, b) reveals some of the forces that determine future solutions, and c) suggests a price tag for this new technology. Despite a rapid increase in (video) data and the fact that this deluge cannot be managed with human resources alone people are expensive and ineffective customers are reluctant to accept help from a technology that occasionally makes really dumb mistakes. Will this reluctance vanish over time without radical improvements in the technology? Will the technology improve and prevent these mistakes in the future? If so, how? Are there applications where the current mistakes are acceptable? What is the right price tag for the technology?
5279787
Video Surveillance and Biometric Technology Applications###Summary form only given. The paper refers some recent experiences on Video Surveillance applications in public spaces, with particular attention to the airport scenario. After a brief discussion on the main open problems and the level of performance that is currently achieved by vision technology, the issue of integration with biometric technology is addressed. Some preliminary results of an Italian national research project are also referred, with an experimental demonstration to simulate the typical problems of security access control in an airport scenario. The MULTI-TRUST project was intended to study the main market trends and innovation technology in the airport field, to study the potential of 3D face recognition technology, and solutions of Intelligent Video Analysis for people tracking. The processing scheme is a layered architecture with different modules at the level of info-processing, entity fusion and high-level event detection and classification. A significant contribution came also from the development of an interactive station for people enrollment, check-in booth functions and passenger identity verification. Multi-Biometric combination has proved to be quite a promising approach to achieve a reliable person identification, including different biometric functions like fingerprint with face features (possibly 3D) and other personal identification data. Moreover Video Analysis is a key feature of new advanced Video Surveillance Systems to provide an intelligent support to security operators to highlight the critical situations while reducing the number of false alarm events. Further technological improvements are required in this field, since the current level of performance is not always appropriate for the severe requirements of the users. In such a context 3D modeling represent the most effective way for people/object detection and classification. Also the experience of MULTI-TRUST has demonstrated that Computer Vision technology is not yet reliab- le enough to manage very crowded scenes and multiple occlusions in variable light conditions. Robustness of processing remains a challenge. Finally, Behavior modeling and classification represents the new frontier of research with an increasing potential of security applications.
5279463
Landmark Localisation in 3D Face Data###A comparison of several approaches that use graph matching and cascade filtering for landmark localization in 3D face data is presented. For the first method, we apply the structural graph matching algorithm ldquorelaxation by eliminationrdquo using a simple ldquodistance to local planerdquo node property and a ldquoEuclidean distancerdquo arc property. After the graph matching process has eliminated unlikely candidates, the most likely triplet is selected, by exhaustive search, as the minimum Mahalanobis distance over a six dimensional space, corresponding to three node variables and three arc variables. A second method uses state-of-the-art pose-invariant feature descriptors embedded into a cascade filter to localize the nose tip. After that, local graph matching is applied to localize the inner eye corners. We evaluate our systems by computing root mean square errors of estimated landmark locations against ground truth landmark localizations within the 3D Face Recognition Grand Challenge database. Our best system, which uses a novel pose-invariant shape descriptor, scores 99.77% successful localization of the nose and 96.82% successful localization of the eyes.
5279461
Towards Generic Detection of Unusual Events in Video Surveillance###In this paper, we consider the challenging problem of unusual event detection in video surveillance systems. The proposed approach makes a step toward generic and automatic detection of unusual events in terms of velocity and acceleration. At first, the moving objects in the scene are detected and tracked. A better representation of moving objects trajectories is then achieved by means of appropriate pre-processing techniques. A supervised support vector machine method is then used to train the system with one or more typical sequences, and the resulting model is then used for testing the proposed method with other typical sequences (different scenes and scenarios). Experimental results are shown to be promising. The presented approach is capable of determining similar unusual events as in the training sequences.
5279646
Real Time Foreground-Background Segmentation Using a Modified Codebook Model###Real time segmentation of scene into objects and background is really important and represents an initial step of object tracking. Starting from the codebook method we propose some modifications which show significant improvements in most of the normal and also difficult conditions. We include parameter of frequency for accessing, deleting, matching and adding codewords in codebook or to move cache codewords into codebook. We also propose an evaluation method in order to objectively compare several segmentation techniques, based on receiver operating characteristic (ROC) analysis and on precision and recall method. We propose to summarize the quality factor of a method by a single value based on a weighted Euclidean distance or on a harmonic mean between two related characteristics.
5279483
Emerging Trends in Persistent Surveillance Information Fusion###Recent data collections in video and signals collection such as Electro-optical/Infrared video, synthetic aperture radar (SAR), and Hyperspectral (HSI) data afford persistent surveillance. As the rate of the imagery (or other products such as 3D terrain modeling) becomes available, there is a greater need for data exploitation to support and augment user needs for situational awareness. The presentation will focus on (a) emerging technologies, (b) tools and processing needs for the user, and (c) developments for persistent surveillance performance analysis. Standard methods of image processing and imagery collection have been accelerated based on the availability of emerging products such as Unmanned Aerial Vehicles (UAV) technology, traffic monitoring systems, and security products. Each of these systems require coordination over varying resolutions, distributed networks, and graphical interfaces. The sensor coordination in the system network enables surveillance over persistent coverage. Persistent surveillance implies that the information processed is to report the results to a user. Surveillance systems can report situational awareness results of target tracks and identifications, anomalies, and target behaviors. Focus should be placed not only on the processing, but include an interactive user to control the collections, determine priorities for the video processing, and support exploration analysis. Image processing, especially video, requires novel techniques to direct collections, process varying targets in complicated terrains, and efforts to evaluate the success. Evaluation includes assessing the performance over varying operation conditions (i.e. sensors, targets, and environments) to include obscurations, compression, and non-continuous data streams. Persistent surveillance coverage requires new techniques in image exploitation to include: (1) fusion with signals and database intelligence, (2) contextual modeling, and (3) tools for user interactive analy- sis.
5279484
Human Body Articulation for Action Recognition in Video Sequences###This paper presents a new technique for action recognition in video using human body part-based approach, combining both local feature description of each body part, and global graphical model structure of the human action. The human body is divided into elementary points from which a Decomposable Triangulated Graph will be built. The temporal variation of human activity is encoded in the velocity distribution of each node in the graph, while the graph structure shows the spatial configuration of all the nodes in the action. Tracking trajectories of unlabeled good feature points are correctly labeled using Maximum a Posterior probability. Dynamic Programming is then implemented to boost up the exhaustive search for the optimal labeling of unknown body parts and the best possible action. A simple and efficient technique for building the optimal structure of the human action graph is also implemented. Experimental results on the KTH dataset proves the success and potential applications of this proposed technique.
5279973
Robust Car License Plate Localization Using a Novel Texture Descriptor###This paper presents a novel texture descriptor based on line-segment features for text detection in images and video sequences, which is applied to build a robust car license plate localization system. Unlike most of existing approaches which use low level features (color, edge) for text/non-text discrimination, our aim is to exploit more accurate perceptual information. A - scale and rotation invariant - texture descriptor which describes the directionality, regularity, similarity, alignment and connectivity of group of segments is proposed. A improved algorithm for feature extraction based on local connective Hough transform has been also investigated. The robustness of our approach is proved throughout a real-time detection/verification scheme of car license plate. First, all possible candidates are detected using a rule based method, which is very robust to illumination change and in varying poses. Then, true license plates are identified by the mean of a SVM classifier trained with proposed descriptor. Comparison and evaluation are conducted with two complex datasets.
5279943
Stereo Localization Based on Network's Uncalibrated Camera Pairs###In this paper, a stereo framework for a robust real time localization of objects using networkpsilas camera pairs is presented. The stereo system contains a combination of static and pan-tilt-zoom (PTZ) cameras instead of traditional dual head mounted cameras. The proposed novelty consists in applying stereo vision to heterogeneous cameras belonging to a video-surveillance network. First, a look-up-table (LUT) is built with the rectification transformations computed for some predefined pan and tilt values. Then, the LUT is used to compute rectification transformations by means of neural networks for any arbitrary pan and tilt settings. Different zoom levels are compensated by resizing images according to their focal ratio and by applying zero padding. Localization of any object is made using its 3D position information obtained by a modified stereo concept. Experimental results are presented for the localization of moving objects in a parking lot scenario.
5279795
Noisy MPEG Motion Vector Reduction for Motion Analysis###In MPEG standards, motion compensation is used for inter-frame compression. Motion compensation generates motion vectors in order to predict the current frame regions from previously decoded frames. These motion vectors represent motion information between regions in different frames and are useful in motion analysis. However, the motion vectors of homogeneous, low-textured, and line regions tend to be unstable and noisy; therefore, it becomes difficult to conduct motion analysis. In this paper, we propose a noisy motion vector reduction method for motion analysis using MPEG motion vectors by introducing a global motion estimation method and a zero-comparison method. The proposed method outputs local motion vectors that are free of noise and high-quality global motion vectors that can be used for object detection, tracking, etc. Further, this method works even for videos captured by a moving camera. We demonstrate the effectiveness of the proposed method through several experiments using actual videos.
5279946
A New Optical Distortion Model for Multi-camera Calibration###A new optical distortion model is proposed, to recover the ideal rectified image for camera calibration. This method is applied as a preprocessing step of a vanishing point calibration procedure that is proved to get a sufficient level of precision for video surveillance applications. Some experimental results are referred in the paper to demonstrate the possibility of 3D model projection from multiple camera views as well as integration of different optical sensors (planar lens and fish eye panoramic cameras). Performance criteria are defined in terms of direct and inverse transformations between the image plane and the 3D reference system in the scene, by using 3D model projection.
5279798
Contradiction and Correlation for Camera Overlap Estimation###An accurate estimate of camera overlap is a key enabler for efficient network-wide surveillance processing (e.g. inter-camera tracking), especially in large-scale surveillance networks. Techniques based on contradictions in pair-wise occupancy data, such as the exclusion approach, have advantages in robustness and efficiency that make them particularly well suited for large surveillance networks. Correlation techniques share some of these advantages,but have a better understood statistical basis. This paper evaluates a set of contradiction and correlation techniques, using a novel metric, search space precision-recall. This metric reflects the activity-based overlap estimation required for camera handover, such as would be used in inter-camera tracking.Results are reported for a range of networks, including a 24-camera network setup in an office space, where the exclusion estimator showed the best performance.
5279799
Context-Based Multimedia Sensor Selection Method###Modern multimedia systems have large number of sensors spread across a wide area. In a time-shared multimedia system, many people will be making queries to the system simultaneously which requires sharing of computing resources. In such scenarios, processing information from all the sensors for each query will make the system inefficient. Considering the fact that only few sensors provide information relevant to the query, we can reduce the cost incurred in query evaluation by efficiently selecting a subset of sensors to be processed without compromising the system performance. This paper demonstrates a two-stage sensor selection method which uses contextual information and confidence in individual sensors to select sensors which provide more reliable answers to the queries.
5280058
Automatic Initiation of the Periorbital Signal Extraction in Thermal Imagery###User intervention in the periorbital thermal signal extraction process breaks down automation. This paper proposes a novel way to minimize user intervention. While previous work demonstrated the importance of accurate computation of the periorbital signal, the present method enables its automatic extraction at a reduced processing time. The proposed algorithm capitalizes on detection of involuntary eye blinking in the thermal imagery. The need for automation has emerged because of repetitive processing of the same subjects, aiming to validate improvements in the periorbital tissue tracking or segmentation algorithms. The proposed approach initiates the tracking and segmentation algorithms on the same spatio-temporal location in repetitive runs of the thermal clip. Thus, it does not only automate the process but also eliminates the variability introduced by manual intervention. We have tested the algorithm on thermal video clips of 39 subjects who faced stressful interrogation for a mock crime. The results show that the proposed method has reduced total processing time from a week down to a day.
5279466
A People Counting System Based on Face Detection and Tracking in a Video###Vision-based people counting systems have wide potential applications including video surveillance and public resources management. Most works in the literature rely on moving object detection and tracking, assuming that all moving objects are people. In this paper, we present our people counting approach based on face detection, tracking and trajectory classification. While we have used a standard face detector, we achieve face tracking combining a new scale invariant Kalman filter with kernel based tracking algorithm. From each potential face trajectory an angle histogram of neighboring points is then extracted. Finally, an Earth Mover's Distance-based K-NN classification discriminates true face trajectories from the false ones. Experimented on a video dataset of more than 160 potential people trajectories, our approach displays an accuracy rate up to 93%.
5280102
A Classification Architecture Based on Connected Components for Text Detection in Unconstrained Environments###The paper presents a method for efficient text detection in unconstrained environments, based on image features derived from connected components and on a classification architecture implementing a focus of attention approach.The main application motivating the work is container code detection with the final goal of checking freight trains composition. Although the method is strongly influenced by the application experimental evidence speaks in favour of its generality: we present results on container codes, car plates images and on the benchmark dataset ICDAR.
5279462
Recognizing Human Actions Using Silhouette-based HMM###This paper addresses the problem of silhouette-based human action modeling and recognition, specially when the number of action samples is scarce. The first step of the proposed system is the 2D modeling of human actions based on motion templates, by means of motion history images (MHI). These templates are projected into a new subspace using the Kohonen self organizing feature map (SOM), which groups viewpoint (spatial) and movement (temporal) in a principal manifold, and models the high dimensional space of static templates.The next step is based on the hidden Markov models (HMM) in order to track the map behavior on the temporal sequences of MHI. Every new MHI pattern is compared with the features map obtained during the training. The index of the winner neuron is considered as discrete observation for the HMM. If the number of samples is not enough, a sampling technique, the sampling importance resampling (SIR) algorithm, is applied in order to increase the number of observations for the HMM. Finally, temporal pattern recognition is accomplished by a maximum likelihood (ML) classifier. We demonstrate this approach on two publicly available dataset: one based on real actors and another one based on virtual actors.
5279810
Modelling and Managing Domain Context for Automatic Surveillance Systems###In this paper we propose an architecture for a surveillance application aimed to the automatic recognition of complex events. The main novelty of this work consists in the design of an effective and viable solution for the actual implementation of a complex automatic surveillance system that explicitly separates signal processing routines from the reasoning modules. We describe our ongoing efforts in the representation of the domain knowledge and in the development of a framework that allows the operator to easily check and update the systempsilas knowledge base. The taxonomical knowledge is expressed through ontologies (OWL), the event classification logic is expressed using a dedicated rule language (Jess), and the implementation is based on the java language.
5279954
Segment Model Based Vehicle Motion Analysis###Motion analysis is a very attractive research direction in computer vision field. In this paper, we propose a framework for analyzing real vehicle motion in visual traffic surveillance by using Segment Model (SM), which is a kind of probabilistic model. SM can grasp the underlying information of observation sequence by using segment distribution. It has been proved to be more precise than that of HMM. In the experiments, we compare our approach with the template matching method based on the Hausdorff distance and the state space method based on the Hidden Markov Model (HMM). The experimental results show the effectiveness of our approach.
5280160
Multimodal Abandoned/Removed Object Detection for Low Power Video Surveillance Systems###Low-cost and low-power video surveillance systems based on networks of wireless video sensors will enter soon the marketplace with the promise of flexibility, quick deployment and providing accurate and real-time visual data. Energy autonomy and efficiency of the implemented algorithms are undoubtedly the primary design challenges to be addressed on systems subject to low computational capabilities and memory constraints. In this paper we present a low-power video sensor node designed for low-cost video surveillance which is able to detect abandoned and removed objects. The system exploits multi-modal sensor integration which saves on-board power consumption. In particular a pyroelectric infrared (PIR) sensor is exploited to optimize the use of the camera, grabbing images only when required in order to obtain the maximum efficiency from event recognition. Our fixed-point ARM-based approach is characterized in terms of runtime execution and power consumption, while efficiency is demonstrated by experimental results and compared with floating point implementations.
5279952
Virtual Boundary Crossing Detection without Explicit Object Tracking###Virtual boundary (tripwire) crossing detection is an essential component in almost all modern digital visual surveillance systems. In this paper, we address the problem of achieving reliable tripwire crossing results in crowded scenarios and propose a new technique for the replacement of conventional tracking based tripwire techniques. We introduce the concept of "ground patches" which are a set of sub-regions sampled around the defined tripwire. Each ground patch is declared active when it is occupied by one or more foreground objects. Temporal and appearance features are extracted from each of the patches, and they are correlated across the virtual boundary to determine if a crossing occurs. The proposed method has been applied in situations with different traffic loads, and promising results are obtained.
5279721
An Abandoned Object Detection System Based on Dual Background Segmentation###An abandoned object detection system is presented and evaluated using benchmark datasets. The detection is based on a simple mathematical model and works efficiently at QVGA resolution at which most CCTV cameras operate. The pre-processing involves a dual-time background subtraction algorithm which dynamically updates two sets of background, one after a very short interval (less than half a second) and the other after a relatively longer duration. The framework of the proposed algorithm is based on the approximate median model. An algorithm for tracking of abandoned objects even under occlusion is also proposed. Results show that the system is robust to variations in lighting conditions and the number of people in the scene. In addition, the system is simple and computationally less intensive as it avoids the use of expensive filters while achieving better detection results.
5279450
Comparative Evaluation of Stationary Foreground Object Detection Algorithms Based on Background Subtraction Techniques###In several video surveillance applications, such as the detection of abandoned/stolen objects or parked vehicles,the detection of stationary foreground objects is a critical task. In the literature, many algorithms have been proposed that deal with the detection of stationary foreground objects, the majority of them based on background subtraction techniques. In this paper we discuss various stationary object detection approaches comparing them in typical surveillance scenarios (extracted from standard datasets). Firstly, the existing approaches based on background-subtraction are organized into categories. Then, a representative technique of each category is selected and described. Finally, a comparative evaluation using objective and subjective criteria is performed on video surveillance sequences selected from the PETS 2006 and i-LIDS for AVSS 2007 datasets, analyzing the advantages and drawbacks of each selected approach.
5279728
An Algorithm for Detection of Partially Camouflaged People###Several video analysis applications perform object detection using a background subtraction approach. Camouflage can be a serious problem for these applications, since the objects of interest may appear fragmented into small,disconnected pieces, with a dramatic negative impact on later processing phases such as classification or tracking. Nevertheless, this problem is largely underestimated in the literature. In this paper an effective, model-based solution is presented for the case of people detection. The proposed method acts as a post-processing phase, grouping together the fragmented blocks to restore the original object. A quantitative evaluation of the effectiveness of this method has been performed on real world videos from a video-surveillance application. The videos used for the experiments (with metadata) have been made publicly available on the Internet.
5279520
Intelligent Video for Protecting Crowded Sports Venues###Intelligent video in urban settings can be challenging due the presence of crowds, clutter, poor camera placement and continuously changing light conditions. The surveillance of sports venues is particularly difficult, because thousands of people can enter or exit a venue in short periods of time. This paper presents a case study of successfully monitoring a sports venue using a multi-camera multi-target tracking system. The system performed site-wide tracking throughout a network of calibrated cameras and was able to accurately track thousands of people in real-time under challenging conditions. The extracted tracking information was used to detect a range of real-time events such as crowd formation, left luggage, and loitering. In addition all video,track and event information was indexed and stored to allow operators to perform playback and forensic search. This paper will present an overview of the deployed system and discuss the challenges that were encountered during the deployment.
5279581
Tracking HoG Descriptors for Gesture Recognition###We introduce a new HoG (Histogram of Oriented Gradients) tracker for Gesture Recognition. Our main contribution is to build HoG trajectory descriptors (representing local motion) which are used for gesture recognition. First,we select for each individual in the scene a set of corner points to determine textured regions where to compute 2D HoG descriptors. Second, we track these 2D HoG descriptors in order to build temporal HoG descriptors. Lost descriptors are replaced by newly detected ones. Finally, we extract the local motion descriptors to learn offline a set of given gestures.Then, a new video can be classified according to the gesture occurring in the video. Results shows that the tracker performs well compared to KLT tracker. The generated local motion descriptors are validated through gesture learning-classification using the KTH action database.
5279585
Hierarchical Matching of 3D Pedestrian Trajectories for Surveillance Applications###In this paper we propose a string-based approach to effectively represent trajectories in the 3D space. The strategy is coupled with a syntactical matching algorithm that allows evaluating the similarity of the retrieved data with pre-stored templates. The symbolic representation of the trajectory, is the core of the proposed system, which helps discriminating among different tracks using a modified version of the edit-distance. The hierarchical application of the algorithm on the spatial and temporal components helps detecting anomalous trajectories, and has proven to be robust in automatically learning new instances or classes of paths. We present the results achieved by performing a number of tests in an indoor lab used as a testbed for assisted living applications. The algorithm can discriminate among different classes of trajectories and can recognize actions and detect anomalies within the same class.
5279624
Object-Wise Multilayer Background Ordering for Public Area Surveillance###Public area is one of the most significant places which need video surveillance. However, pixel-wise adaptive background subtraction methods are disturbed by incessantly passing or temporally staying foreground due to its adaptability. In such an environment, even the initialization of background is not free from the influence of foregrounds. If the adaptability is modified carelessly for selective learning, the stability of the background model will be damaged. Adjusting or fusing the learning rate slows down the false learning rate but cannot solve the problems. In this paper, we present a multilayer background modeling algorithm for public area surveillance. We efficiently cluster regions in object-wise using spatiotemporal cohesion together with spectral similarity by comparing inputs with background layer. And we classify the clustered regions and update the multi-layer model according to the results. Using the PETS data, we show that the proposed method not only maintain the background robustly but also initialize background with stationary object detection in crowded public area.
5279626
Multi-cue Based Visual Tracking in Clutter Scenes with Occlusions###Object tracking is important for video analysis applications. However, tracking through occlusions is a difficult task due to significant appearance changes of the objects. Approaches based on either global features or one kind of local features can not solve the problem completely. In this paper, a multi-cue based tracking approach is introduced. It combines a corner tracking with a color and a shape model to resolve the object tracking problem through occlusions for most scenes (indoor and outdoor).To obtain an objective evaluation of the proposed method, a set of detection and tracking measures are used to perform a quantitative analysis based on a large sequence dataset with ground-truth annotation. The experimental results show that the proposed approach works robustly under varying conditions.
5279627
An Adaptive Tracker for Assisted Living###We propose an adaptive tracking system for assisted living that integrates user information about emergency events. Information fusion between user data and visual data is performed in order to estimate and assess the situation at hand. The system is able to dynamically switch between different segmentation and tracking algorithms improving its performance, as shown by the proposed examples.
5279809
Distributed Cognitive Sensor Network Approach for Surveillance Applications###The application of intelligent systems composed by smart cameras is continuously spreading in a wide range of applications, playing a key role in public, military and commercial scenarios. As well, in the last years, the capability of wireless sensor networks to collect information from the environment in a distributed manner has been successfully applied in both civilian and military applications. In this paper, basing on recent studies on autonomous cognitive systems, we explore the concepts for designing interactive, adaptable and intelligent multi-sensor surveillance systems able to react to situations in a preventive way by using actuators placed in the monitored environment. To this end, taking inspiration from ambient intelligence (AmI) and cognitive radio (CR) paradigms, fusion of information provided by heterogeneous sensors is used to improve awareness regarding surrounding environment.
5279805
Self-Calibration and Control of a PTZ Camera Based on a Spherical Mirror###In video surveillance applications, PTZ cameras can focus and analyze in details specific zones of the scene. In a computer supervised intrusion detection, a single PTZ camera is unable to visualize the entire scene at once. This article proposes an original solution to this problem, by using an additional spherical mirror. Besides the equations needed to control the PTZ camera, this article presents also a self calibration processes of the camera with the mirror.
5279806
A Scalable Video Stabilization Algorithm for Multi-camera Systems###Images rendered by remote sensing multi-camera platforms typically contain jitter caused by decoding timing delays, target movement, and platform motion. In this paper, we address the problem of stabilizing large-frame, low-frame rate imagery acquired from a multi-camera array system for persistent surveillance and monitoring. The algorithm utilizes temporal coherence properties between the cameras, eliminating the need to perform motion estimation on each individual camera sequence. The video stabilization algorithm includes three main modes of scalability:1) quality, 2) resolution, and 3) camera. To demonstrate the feasibility of the developed algorithm in real-world scenarios, we present results with imagery collected from a prototype multi-camera array persistent surveillance system.
5279802
Robust Surveillance on Compressed Video: Uniform Performance from High to Low Bitrates###In this paper, we discuss methods to enable robust surveillance on compressed video. We show that if the particular surveillance algorithm that is likely to be run on the compressed video is known a priori, then steps can be taken during the encoding process to facilitate the performance of the algorithm. We show that by performing signal processing on the input video signal before it is encoded, or by adaptively changing the parameters of the encoding process, we can make the resulting signal more robust to degradations in the encoding process. The result is better and more consistent tracking on the compressed video from high to low bitrates, but with some loss in PSNR. We demonstrate the validity of this approach for mean shift tracking running on MPEG-4 coded video.
5280075
Trajectory Association and Fusion across Partially Overlapping Cameras###We present a novel unsupervised inter-camera trajectory correspondence algorithm that does not require prior knowledge of the camera placement. The approach consists of three steps, namely association, fusion and linkage. For association, local trajectory pairs corresponding to the same physical object are estimated using multiple spatio-temporal features on a common ground-plane. To disambiguate spurious associations, we employ a hybrid approach that utilizes the matching results on the image- and ground-plane. The trajectory segments after association are fused by adaptive averaging. Finally, linkage integrates segments and generates a single trajectory of an object across the entire observed area. We evaluated the performance of the proposed approach on a simulated and two real scenarios with simultaneous moving objects observed by multiple cameras and compared it with state-of-the-art algorithms. Convincing results are observed in favor of the proposed approach.
5279854
Learning People Trajectories Using Semi-directional Statistics###This paper proposes a system for people trajectory shape analysis by exploiting a statistical approach which accounts for sequences of both directional (the directions of the trajectory) and linear (the speeds) data. A semi-directional distribution (AWLG - Approximated Wrapped and Linear Gaussian) is used with a mixture to find main directions and speeds. A variational version of the mutual information criterion is proposed to prove the statistical dependency of the data. Then, in order to compare data sequences, we define an inexact method with a Kullback-Leibler-based distance measure and employ a global alignment technique is to handle sequences of different lengths and with local shifts or deformations. A comprehensive analysis of variable dependency and parameter estimation techniques are reported and evaluated on both synthetic and real data sets.
5279731
Local and Global Collaboration for Object Detection Enhancement with Information Redundancy###Object detection by visual sensors is a critical component of surveillance systems and has many challenging issues. This paper addresses enhancement of object detection with multiple visual sensors. The detection enhancement we introduce is to recover missed object detection given partially detected objects among multiple visual sensors. Once an object is detected by one or more visual sensors, the detected local object positions are transformed into a global object position. Based on a local and global collaboration, any missed local object position is recovered by the global to local transformation. However, the collaboration may degrade the detection performance by incorrectly recovering the local object position, which is propagated from false object detection. Furthermore, local object positions corresponding to an identical object are transformed into in equivalent global object positions due to detection uncertainty such as a shadow. In this paper, we minimize the performance degradation by preventing from the propagation of the false object detection. In addition, we present an evaluation method for a final global object position. Finally, the proposed method is analyzed and evaluated with case studies.
5279538
An Information Value Driven Architecture for Urban Video Surveillance in Data and Attention Bandwidth Constrained Environments###Urban surveillance networks are characterized by network (data) and attention (security professionals monitoring copious sensors) bandwidth constraints. Both of these challenges exist because scarce network and attention resources are allocated under the assumption that all data are equally important. The proposed intelligent camera and video recorder (iCVR) architecture addresses the two bandwidth challenges directly by (a) enabling value assessment at the sensor level and (b) endowing the sensor with sufficient memory to store data for an extended time period. The latter is significant because the sensor, based on information value, can choose how long data need to be retained rather than just choosing to discard untransmitted data based on an arbitrary value threshold. We present the iCVRpsilas architecture and the impact of the value assessment and storage framework in the context of a wide-area urban surveillance application.
5279737
A Fast Converging Algorithm for Acoustic Echo Cancellation in Time-Varying Channels###In this paper, we propose an acoustic echo cancellation method called MPNLMS++ which can adapt to time varying channels with fast convergence. The MPNLMS++ can converge much faster than conventional algorithms when the channel changes from dispersive to sparse, and at least as fast as other fast algorithms in other situations. The effectiveness of MPNLMS++ is verified in the simulation.
5279738
Cost-Effective Solution to Synchronized Audio-Visual Capture Using Multiple Sensors###Applications such as surveillance and human motion capture require high-bandwidth recording from multiple cameras. Furthermore, the recent increase in research on sensor fusion has raised the demand on synchronization accuracy between video, audio and other sensor modalities. Previously, capturing synchronized, high resolution video from multiple cameras required complex, inflexible and expensive solutions. Our experiments show that a single PC, built from contemporary low-cost computer hardware, could currently handle up to 470MB/s of input data. This allows capturing from 18 cameras of 780x580pixels at 60fps each, or 36 cameras at 30fps. Furthermore, we achieve accurate synchronization between audio, video and additional sensors, by recording audio together with sensor trigger- or timestamp signals, using a multi-channel audio input. In this way, each sensor modality can be captured with separate software and hardware, allowing maximal flexibility with minimal cost.
5279974
Robust Vehicle Detection for Tracking in Highway Surveillance Videos Using Unsupervised Learning###This paper presents a novel approach to vehicle detection in highway surveillance videos. This method incorporates well-studied computer vision and machine learning techniques to form an unsupervised system, where vehicles are automatically ldquolearnedrdquo from video sequences. First an enhanced adaptive background mixture model is used to identify positive and negative examples. Then a classifier is trained with these examples. In the detection phase, both background subtraction and the classifier are used to achieve very accurate results while not compromising efficiency. We tested our method with very low-, medium- and high-quality, crowded and very crowded surveillance videos and got detection accuracies ranging between 90% to 96%.
5279755
3D Face Recognition Using Multiview Keypoint Matching###A novel algorithm for 3D face recognition based point cloud rotations, multiple projections, and voted keypoint matching is proposed and evaluated. The basic idea is to rotate each 3D point cloud representing an individual's face around the x, y or z axes, iteratively projecting the 3D points onto multiple 2.5D images at each step of the rotation. Labeled keypoints are then extracted from the resulting collection of 2.5D images, and this much smaller set of keypoints replaces the original face scan and its projections in the face database. Unknown test faces are recognized firstly by performing the same multiview keypoint extraction technique, and secondly, the application of a new weighted keypoint matching algorithm. In an extensive evaluation using the GavabDB 3D face recognition dataset (61 subjects, 9 scans per subject), our method achieves up to 95% recognition accuracy for faces with neutral expressions only, and over 90% accuracy for face recognition where expressions (such as a smile or a strong laugh) and random face-occluding gestures are permitted.
5279751
A Multi-scale Piecewise-Linear Feature Detector for Spectrogram Tracks###Reliable feature detection is a prerequisite to higher level decisions regarding image content. In the domain of spectrogram track detection and classification, the detection problem is compounded by low signal-to-noise ratios and high variation in track appearance. Evaluation of standard feature detection methods in the literature is essential to determine their strengths and weaknesses in this domain. With this knowledge, improved detection strategies can be developed. This paper presents a comparison of line detectors and a novel, multi-scale, linear feature detector able to detect tracks of varying gradients. We outline improvements to the multi-scale search strategies which reduce run-time costs. It is shown that the Equal Error Rates of existing methods are high, highlighting the need for research into novel detectors. Results demonstrate that the proposed method offers an improvement in detection rates when compared to other, state of the art, methods whilst keeping false positive rates low. It is also shown that a multi-scale implementation offers an improvement over fixed scale implementations.
5279752
A Speech Based Approach to Surveillance Video Retrieval###This paper describes the anatomy of a pilot surveillance system with a speech-based interface for content-based retrieval of video data. The proposed system relies on an ontology-based information sharing architecture and lets components of the system communicate among each other through TCP/IP communication channels. The aim of developing the pilot system was to explore dependencies between image analysis, event detection, video annotation, and speech- based retrieval of the video content in the context of a broader spoken dialogue system.
5279759
Compact Signatures for 3D Face Recognition under Varying Expressions###We present a novel approach to 3D face recognition using compact face signatures based on automatically detected 3D landmarks. We represent the face geometry with inter-landmark distances within selected regions of interest to achieve robustness to expression variations. The inter-landmark distances are compressed through principal component analysis and linear discriminant analysis is then applied on the reduced features to maximize the separation between face classes. The classification of a probe face is based on a nearest mean classifier after transforming the probe onto the subspace. We analyze the performance of different landmark combinations (signatures) to determine a signature that is robust to expressions. The selected signature is then used to train a point distribution model for the automatic localization of the landmarks, without any prior knowledge of scale, pose, orientation or texture. We evaluate the proposed approach on a challenging publicly available facial expression database (BU-3DFE) and achieve 96.5% recognition rate using the automatically localized signature. Moreover, because of its compactness the face signature can be stored on 2D barcodes and used for radio-frequency identification.
5279591
Counting People in Groups###Cameras are becoming a common tool for automated vision purposes due to their low cost. In an era of growing security concerns, camera surveillance systems have become not only important but also necessary. Algorithms for several tasks such as detecting abandoned objects and tracking people have already been successfully developed. While tracking people is relatively easy, counting people in groups is much more challenging. The mutual occlusions between people in a group make it difficult to provide an exact count. The aim of this work is to present a method of estimating the number of people in group scenarios. Several considerations for counting people are illustrated in this paper, and experimental results of the method are described and discussed.
5279465
A Pruning Approach Improving Face Identification Systems###We propose, in this paper, a new biometric identification approach which aims to improve recognition performances in identification systems. We aim to split the identity database into well separated partitions in order to simplify the identification task. In this paper we develop a face identification system and we use the reference algorithms of eigenfaces and fisherfaces in order to extract different features describing each identity. These features, which describe faces, are generally optimized to establish the required identity in a classical identification process. In this work, we develop a novel criterion to extract features used to partition the identity database. We develop database partitioning with clustering methods which split the gallery by bringing together identities which have similar features and separating dissimilar features in different bins. Pruning the most dissimilar bins from the query identity features allows us to improve the identification performances. We report results from the XM2VTS database.
5279937
Affine Adaptation of Local Image Features Using the Hessian Matrix###Local feature detectors that make use of derivative based saliency functions to locate points of interest typically require adaptation processes after initial detection in order to achieve scale and affine covariance. Affine adaptation methods have previously been proposed that make use of the second moment matrix to iteratively estimate the affine shape of local image regions. This paper shows that it is possible to use the Hessian matrix to estimate local affine shape in a similar fashion to the second moment matrix. The Hessian matrix requires significantly less computation effort to compute than the second moment matrix, allowing more efficient affine adaptation. It may also be more convenient to use the Hessian matrix, for example, when the Determinant of Hessian detector is used. Experimental evaluation shows that the Hessian matrix is very effective in increasing the efficiency of blob detectors such as the Determinant of Hessian detector, but less effective in combination with the Harris corner detector.
4730386
Commentary Paper on "Recognizing Shapes in Video Sequences Using Multi-class Boosting"###This paper describes a learning-based approach to recognizing shapes in video sequences using spatial and temporal features of the shape. The spatial characteristics are encoded in the mean frame, while the temporal characteristics are extracted using the Iwasawa decomposition of the shape sequence. Training is done using logistic regression, namely the LogitBoost algorithm. The method obtains good results on outdoor surveillance datasets.
4730387
Camera Handoff with Adaptive Resource Management for Multi-camera Multi-target Surveillance###Camera handoff is a crucial step to generate a continuously tracked and consistently labeled trajectory of the object of interest in multi-camera surveillance systems. Most existing camera handoff algorithms concentrate on data association, namely consistent labeling, where images of the same object are matched across different cameras. However, most real-time object tracking systems see a decrease in the system's frame rate as the number of tracked objects increases. To address this issue, we propose to incorporate an adaptive resource management mechanism into camera handoff. In so doing, cameras resources can be dynamically allocated to multiple objects according to their priorities and hence the required minimum frame rate can be maintained. Experimental results illustrate that the proposed camera handoff algorithm is capable of maintaining a constant frame rate and of achieving a substantially improved handoff success rate by approximately 20% in comparison with the algorithm presented by Khan and Shah.
4730384
MPEG-7 Motion Descriptor Extraction for Panning Camera Using Sprite Generated###Sprite generation is extensively used for the video compression. Real time efficient video analytics (VA) for surveillance system need to make decision with in camera processing unit or at camera edge processing unit. The Video Analytics is required to work on good resolution footage to register tiny but important information that may otherwise be lost during subsequent compression process, especially in temporally exploited streams. This paper presents a novel approach to generate a full view panoramic mosaic for a surveillance sequence to help detect moving objects and extract MPEG-7 motion descriptors. Unlike the current panoramic transformation methods, in which pure horizontal panning motion is requiredis required to construct the mosaic, our method can deal with uncontrolled panning motion with slight camera tilt motion. This method provides a generic solution for real world surveillance camera issues such as undesired tilt motion because of the nonlinearity of camera moving mechanism, strong wind etc. The sprite generated helps to detect moving objects, constructing motion trajectories and also provides a clean background reference even for a panning camera. The algorithm has been evaluated with several test sequences.
4730385
Recognizing Shapes in Video Sequences Using Multi-class Boosting###We model the spatio-temporal variations of the shape of objects in a video sequence using a unique SVD-like decomposition. The decomposition is used to compute shape features, which form an approximation of the original shape sequence. The features are used to train separate classifiers using multi-class boosting strategy. We demonstrate the effectiveness of the proposed approach for shape recognition using the China Lake outdoor surveillance dataset; and compare the results using mean shapes as baseline. We illustrate the usefulness of the proposed shape features for detecting shapes of interest using the SIG group activity dataset.
4730382
Commentary Paper 2 on "On Stable Dynamic Background Generation Technique Using Gaussian Mixture Models for Robust Object Detection'"###In previous surveillance applications, algorithms for background modeling based on Gaussian mixture models (GMM) needed to specify two parameters: threshold T, which determines a proportion of the data that should be accounted for by the background, and a learning rate alpha specifying speed at which the distribution parameters change [Stauffer, CVPR 1999}. In the Basic Background Subtraction (BBS), foreground objects are found by subtracting a static foreground image. In the proposed algorithm, BBS is applied using background obtained from GMM. This way, threshold T is replaced by a foreground-background separation threshold S. The advantage is that S is less sensitive than T. To make the model respond faster to changes, recent observed value of the most dominant background component is used as a current value for a particular pixel, rather than the component mean value. Quantitative and qualitative results show the advantages of the proposed technique compared to GMM models.
4730383
An Integrated System for Moving Object Classification in Surveillance Videos###Moving object classification in far-field video is a key component of smart surveillance systems. In this paper, we propose a reliable system for person-vehicle classification which works well in challenging real-word conditions, including the presence of shadows, low resolution imagery, perspective distortions, arbitrary camera viewpoints, and groups of people. Our system runsin real-time (30 Hz) on conventional machines and has low memory consumption. We achieved accurate results by relying on powerful discriminative features, including a novel measure of object deformation based on differences of histograms of oriented gradients. We also provide an interactive user interface, enabling users to specify regions of interest for each class and correct for perspective distortions by specifying different sizes indifferent positions of the camera view. Finally, we use anautomatic adaptation process to continuously update the parameters of the system so that its performance increases for a particular environment. Experimental results demonstrate the effectiveness of our system in standard dataset and a variety of video clips captured with our surveillance cameras.
4730380
On Stable Dynamic Background Generation Technique Using Gaussian Mixture Models for Robust Object Detection###Gaussian mixture models (GMM) is used to represent the dynamic background in a surveillance video to detect the moving objects automatically. All the existing GMM based techniques inherently use the proportion by which a pixel is going to observe the background in any operating environment. In this paper we first show that such a proportion not only varies widely across different scenarios but also forbids using very fast learning rate. We then propose a dynamic background generation technique in conjunction with basic background subtraction which detected moving objects with improved stability and superior detection quality on a wide range of operating environments in two sets of benchmark surveillance sequences.
4730381
Commentary Paper 1 on "On Stable Dynamic Background Generation Technique Using Gaussian Mixture Models for Robust Object Detection"###In this paper a technique for motion detection that exploits the Gaussian mixture models (GMM) and basic background subtraction (BBS) is proposed. For every frame, each pixel is modeled with almost K Gaussian distributions. All the existing GMM based techniques use a threshold to set a priori the number of Gaussians to represent the background. The proposed approach avoids setting this threshold. The results show the effectiveness of the novel approach on benchmarks test sets sequences.
4730419
Uncalibrated Framework for On-line Camera Cooperation to Acquire Human Head Imagery in Wide Areas###This paper considers the problem of estimating on-line the time-variant transformation relating a person's feet position in the image of a first, fixed camera, to his head position in the image of a second, pan-tilt-zoom camera. The transformation allows to acquire high-resolution images by steering the PTZ camera at targets detected in a fixed camera view. Assuming a planar scene and modeling humans as vertical segments, we present the development of an uncalibrated framework which does not require any 3D known location to be specified, and it allows to take into account both zooming camera and target uncertainties. Results show good performances in slave camera target head localization, degrading when the high zoom factor causes a lack of feature points in the slave camera.
4730388
Commentary Paper on "Camera Handoff with Adaptive Resource Management for Multi-camera Multi-target Surveillance"###The topic on which this paper is focused is transfer process of tracking of moving objects between sensors in a distributed surveillance system.
4730389
Tracking People in Crowds by a Part Matching Approach###The major difficulty in human tracking is the problem raised by challenging occlusions where the target person is repeatedly and extensively occluded by either the background or another moving object. These types of occlusions may cause significant changes in the persons shape, appearance or motion, thus making the data association problem extremely difficult to solve. Unlike most of the existing methods for human tracking that handle occlusions by data association of the complete human body, in this paper we propose a method that tracks people under challenging spatial occlusions based on body part tracking. The human model we propose consists of five body parts with six degrees of freedom and each part is represented by a rich set of features. The tracking is solved using a layered data association approach, direct comparison between features (feature layer) and subsequently matching between parts of the same bodies (part layer) lead to a final decision for the global match (global layer). Experimental results have confirmed the effectiveness of the proposed method.
4730434
Visual Players Detection and Tracking in Soccer Matches###In this paper we present a people tracking algorithm which is able to detect and track soccer players in complex situations with varying light conditions, high frame rate, and real time processing. Object segmentation is performed by means of an algorithm based on background subtraction. In order to cope with presence of moving objects and light changes during the background modeling phase, an approach based on the evaluation of pixels energy content has been developed. Detected objects are then classified by means of an unsupervised clustering algorithm that allows the solution of blobs splitting and merging problems. For people tracking purpose we propose a stochastic approach based on the evaluation of the maximum a posteriori probability(MAP). First of all the algorithm evaluates geometrical information on the blob overlapping and then applies a color feature classification to track players and solve blob merging situations. Experimental tests have been carried out on long soccer image sequences in different weather and light conditions.
4730409
Video Surveillance for Biometrics: Long-Range Multi-biometric System###The human iris is hypothesized to be the best biometric characteristic in terms of uniqueness and robustness. Iris recognition algorithms developed over the last decade have matured significantly to address population-level cross comparisons. Yet iris acquisition systems remain borderline intrusive and less-friendly for subjects and operators. This paper addresses the issue of strictly-constrained iris acquisition in traditional systems. We highlight the observation that all traditional iris recognition systems impose substantial constraints on subject position and motion during iris acquisition. We further observe that the efforts to relax these constraints for iris acquisition of distant and/or moving subjects fall short of scalable system design. We present a novel iris recognition system for long-range human identification. The system is capable of acquiring face and iris images from multiple humans present anywhere in the capture volume. The iris acquisition system uses multiple cameras with hierarchically-ordered fields of views, a highly precise pan-tilt unit (PTU) and a long focal length zoom lens. The system is driven by innovative algorithms that perform wide-area video surveillance, object detection and tracking, and precision pointing. Experimental results are reported in an indoor environment for multiple subject iris recognition at a distance. Eagle-Eyes is a long-range multi-biometric system that improves on existing iris acquisition approaches in terms of stand-off distance and capture volume through the use of collaborative scene and face tracking.
4730420
Commentary Paper on "Uncalibrated Framework for On-line Camera Cooperation to Acquire Human Head Imagery in Wide Areas"###The focus of the paper is on establishing the mapping between a fixed camera and the PTZ camera using master-slave configuration. The authors proposed and developed a general framework for arbitrary camera topology. The method estimates online the time-variant transformation between a fixed master camera having global view and tracking the target and a slave camera taking close up images. In the experiment, the method transforms the target feet position of the master camera to head position of the slave camera. It takes into account both zooming camera and target uncertainties.
4730437
Commentary Paper 3 on Visual Players Detection and Tracking in Soccer Matches###This manuscript presents object detection and tracking in video clips of soccer matches. Background subtraction based framework on pixel energy is proposed to detect objects in the input video clip with varying light conditions, high frame rates, and real-time processing. Unsupervised clustering is then used classify detected objects into various classes. A stochastic approach based on maximum a posteriori probability (MAP) is proposed for object tracking.
4730430
Commentary Paper on "Foreground Object Detection Using Two Successive Images"###This paper describes a simple and novel algorithm for detecting foreground objects in video sequences using just two consecutive frames. The method isdivided in three layers: the perceptual layer detects regions of interest by looking for pixels whose values change significantly between the two frames. The memory layer allows for the detection of objects that may become stationary (these objects are added to the background after a period of time). The perceptual layer builds on information from the perceptual layer and from the previous iteration's memory layer to extract the actual foreground objects. Background edges are detected and removed first, followed by a level-set method that shrinks the boundary of the region of interest to the boundary of the object. The method is tested on a variety of sequences taken with different cameras in different environments, and obtains very good results.
4730431
Continuous Background Update and Object Detection with Non-static Cameras###Detecting moving objects is an important part of tracking. Most of the previous work on moving object detection concentrates on fixed cameras. Methods using moving cameras seldom deal with the problem of robustly and continuously updating the background model during all times including the periods when the camera is not static. We propose a method to build and continuously update a background model, and to detect foreground objects not only when the camera is static but also when it is zooming in/out or panning/tilting. For instance, the model built for the zoomed in (out) portion of a video is warped to the reference frame of the model of the zoomed out (in) portion to immediately incorporate changes that occurred in the background, such as objects that are placed or removed. This way, changes are incorporated to the model without requiring a learning period each time camera zooms in/out. This method addresses the problems of detecting moving objects during the zooming in and zooming out periods, detecting objects that are placed in the scene while the camera is non-static and gradually incorporating an overall illumination change to the scene model. We present different experiments covering three different scenarios to demonstrate the success of the proposed method in addressing these issues.
4730418
A Fast Linear Registration Framework for Multi-camera GIS Coordination###We propose a novel registration framework to map the field-of-coverage of pan-tilt cameras to a GIS (Geographic Information System) planar coordinate system. The camera's field-of-coverage is obtained by building a spherical panorama using an efficient active camera model. The pan-tilt orientation rays from the panoramic image are projected onto a GIS orthophoto ground plane and registered using a transformation matrix. The parameters of the transformation are learned in linear time using least squares. The proposed model is experimentally evaluated by registering panoramas from multiple cameras with an orthophoto and then overlaying them with GIS metadata ground truth to validate the accuracy of registration. We also demonstrate the applicability of such a GIS-based framework to a multi-camera, master-slave active tracking system.
4730408
Object and Scene-Centric Activity Detection Using State Occupancy Duration Modeling###We propose a video event analysis framework based on object segmentation and tracking, combined with a Hidden Semi-Markov Model (HSMM) that uses state occupancy duration modeling. The observations generated by a multi-object detector and tracker are used as emitting symbols and the corresponding probabilities are computed using multivariate Gaussians. Next, we recognize events by estimating the most likely object state sequence using a HSMM decoding strategy, based on the Viterbi algorithm. Moreover,the duration distribution enforces the state transition after certain time and hence better models the events constrained on time intervals. We demonstrate and evaluate the proposed framework on a dataset of approximately 20 K frames, and show that the duration modeling improves the event detection results by 7% to 11%, compared to state-of-the-art HMMs.
4730416
Annotation Collection and Online Performance Evaluation for Video Surveillance: The ViSOR Project###This paper presents the Visor (video surveillance online repository) project designed with the aim of establishing an open platform for collecting, annotating, retrieving, sharing surveillance videos, and of evaluating the performance of automatic surveillance systems. The main idea is to exploit the collaborative paradigm spreading in the web community to join together the ontology based annotation and retrieval concepts and the requirements of the computer vision and video surveillance communities. The ViSOR open repository is based on a reference ontology which integrates many concepts, also coming from LSCOM and MediaMill ontologies.The web interface allows video browse, query by annotated concepts or by keywords, compressed video preview, media download and upload. The repository contains metadata annotations, which can be either manually created as ground truth or automatically generated by video surveillance systems. Their automatic annotations can be compared each other or with the reference ground-truth exploiting an integrated on-line performance evaluator.
4730417
The Segmentation of the Supraorbital Vessels in Thermal Imagery###Thermal imaging techniques have been applied to detect and measure mental stress in polygraph screening and other applications. Mental stress is highly correlated with the activation of the corrugator muscle on the forehead. The vessels that supply blood to the corrugator muscle, proportionally to its degree of activation, are the supraorbital vessels. The rate of blood flow in these vessels can be indirectly measured via the intensity of heat emission from their segments. However, segmenting the thermal imprints of the supraorbital vessels is challenging because (1) they are fuzzy due to thermal diffusion, and (2) exhibit significant inter-individual and intra-individual variation. In this paper, a new segmentation method is proposed to extract the supraorbital vessels in thermal imagery. The new method features three steps: (1) automatic initialization of vessels; (2) automatic localization of the central lines of vessels; and (3) fast determination of vessel boundaries. The results show that the new method achieves high quality segmentation in both a simulated and a real dataset. The proposed method is expected to further increase the accuracy of stress measurements via thermal imaging.
4730414
Multi-camera Control through Constraint Satisfaction for Persistent Surveillance###We introduce a distributed camera coalition formation scheme for perceptive scene coverage and persistent surveillance by smart camera sensor networks. The proposed model supports task-dependent camera selection and grouping via a "contract net" task allocation protocol augmented with conflict resolution and error recovery mechanisms. Our technique avoids any central controller, and it is robust to node failures and imperfect communication. In the design and empirical evaluation of our camera networks, we exploit a visually and behaviorally realistic virtual environment simulator that is populated by autonomous, lifelike virtual pedestrians.
4730415
Fault Detection Framework for Video Surveillance Systems###We consider cameras whose outputs do not reflect true scenes as faulty cameras. To build a fault detection video surveillance system without using additional hardware devices, we use the video outputs from cameras to do self-checking. We study two categories of faults: spatial faults and temporal faults, and reduce the two sub-problems into graph theoretical problems on two graphs (surveillance sharing graph (SSG) and surveillance partitioning graph (SPG)). We prove a theoretical upper bound for the spatial fault detection, and develop two algorithms for detecting the two types of faults respectively.Then, we integrate both in a framework, which is capable of the following: given the outputs from a video surveillance system, it isolates cameras which are faulty or suspected to be faulty. It gives warnings with types of faults, locations, detection confidence. Our experiments confirm the effectiveness of the framework's methodologies.
4730412
Evaluation of Background Subtraction Algorithms with Post-Processing###Processing a video stream to segment foreground objects from the background is a critical first step in many computer vision applications. Background subtraction (BGS) is a commonly used technique for achieving this segmentation. The popularity of BGS largely comes from its computational efficiency, which allows applications such as human-computer interaction, video surveillance, and traffic monitoring to meet their real-time goals. Numerous BGS algorithms and a number of post-processing techniques that aim to improve the results of these algorithms have been proposed. In this paper, we evaluate several popular, state-of-the-art BGS algorithms and examine how post-processing techniques affect their performance. Our experimental results demonstrate that post-processing techniques can significantly improve the foreground segmentation masks produced by a BGS algorithm. We provide recommendations for achieving robust foreground segmentation based on the lessons learned performing this comparative study.
4730413
Spatial Scalable Region of Interest Transcoding of JPEG2000 for Video Surveillance###A new method for spatial scalable region of interest transcoding of JPEG2000 images for video surveillance applications is proposed in this paper. The method transcodes HD images into quarter HD images with a ROI in HD resolution. The transcoding method is based on the precinct feature as well as on the empty packet feature of the JPEG2000 standard. Based on a user defined ROI the transcoder extracts all packets which belong to the ROI or to the lower resolution of the background. All non-ROI packets of higher resolution levels are deleted and replaced by empty-packets. Thus, the extracted codestream contains no high frequency information for image regions outside the ROI. Because the transcoder operates on packets and not on codeblocks an expensive re-encoding of the codestream is not required. This leads to a short processing time and a low complexity of the transcoding algorithm. Therefore, our method is appropriate for real-time applications like video surveillance.
4730410
Commentary Paper on "Video Surveillance for Biometrics: Long-Range Multi-biometric System"###This paper introduces a long-range multi-biometric system by integrating hierarchical camera system design, human detection and tracking, face detection and pose estimation, NIR laser illumination, and iris acquisition by a PTU and long focal length zoom lens. The system proposed by the paper is sound. Hierarchical design and error-correction steps are introduced in an attempt to make the system robust in real world scenarios. The main concern is two folds: the low resolution of the acquired iris images, and the processing time between frames. Low resolution iris images may lead to significantly decreased accuracy in biometric-based recognition. And the long processing time (due to detection, tracking, etc.) may prevent the system from being applicable to acquiring iris images of moving subjects.
4730411
Super-Resolution of Facial Images in Video with Expression Changes###Super-resolution (SR) of facial images from video suffers from facial expression changes. Most of the existing SR algorithms for facial images make an unrealistic assumption that the perfect registration has been done prior to the SR process. However, the registration is a challenging task for SR with expression changes. This paper proposes a new method for enhancing the resolution of low-resolution (LR) facial image by handling the facial image in a non-rigid manner. It consists of global tracking, local alignment for precise registration and SR algorithms. A B-spline based resolution aware incremental free form deformation (RAIFFD) model is used to recover a dense local non-rigid flow field. In this scheme, low-resolution image model is explicitly embedded in the optimization function formulation to simulate the formation of low resolution image. The results achieved by the proposed approach are significantly better as compared to the SR approaches applied on the whole face image without considering local deformations. The results are also compared with two state-of-the-art SR algorithms to show the effectiveness of the approach in super-resolving facial images with local expression changes.
4730433
Commentary on "Experimental Analysis of Face Recognition on from Still Image to Video Image"###Evaluation of face recognition performance under varying illumination, poses, and image degradation due to sensor characteristics has been studied in depth for static images. This paper uses static and video images when evaluating a face recognition algorithm based on Adaptive Principal Components Analysis (APCA). The results show that the same challenges that happen in static images apply to video, and that when multiple images are available the algorithms perform better (e.g. using, mean frames for face recognition).
4730438
An Object- and Task-Oriented Architecture for Automated Video Surveillance in Distributed Sensor Networks###In this paper, an agent-based software architecture for automated wide area video surveillance systems is presented. The proposed concept is designed for detection and tracking of moving objects across multiple camera views. The surveillance system consists of a decentralized collaborative sensor network with object- and task-oriented architecture. At sensor node level, image processing algorithms are applied for event and object detection. In case of detection (e. g. motion) an agent-based multi-sensor processing cluster is created. Each instantiated cluster is responsible for observation of one object in the scene. Object handover is managed autonomously by the dynamic sensor clusters. The dynamic sensor clustering approach allows adding new sensors without resetting the system parameters, which is a big advantage in large sensor networks. Furthermore, by using the agent-based architecture it is possible to create a framework with an adaptive data and processing load. Additionally, upgrade of system capabilities can be done easily updating or adding new processing agents. The proposed concept has been proved on an experimental video surveillance system at the Fraunhofer IITB.
4730439
Commentary Paper on "An Object- and Task-Oriented Architecture for Automated Video Surveillance in Distributed Sensor Networks"###For original paper see, ibid.,p.339-46, (2008). This paper proposed an object- and task-oriented architecture for automated video surveillance in distributed sensor networks. The proposed work is implemented and evaluated in an experimental testbed consisting 25 nodes.
4730426
Color Retrieval for Video Surveillance###In this paper, we present retrieval methods for extracting colored moving objects from surveillance cameras. In particular, we describe a method to classify moving objects into one of six colors. The method includes two sets of parameters. The first set can be used to compensate for illumination conditions and camera differences. The second set is used to tune the color extraction for specific object types and optimal retrieval. The tuning can be performed after video analysis has extracted metadata in real-time. The metadata is fed into a database which can be interactively queried by the user. The ability to query with feedback makes it possible to successfully find events of interest during an investigation without performing real-time adaptation which might be error-prone. In addition, for situations in which tracking moving objects is difficult, the system can generate significant colored object snippets of moving colored objects for retrieval. If the event of interest is not found by the initial system, this backup system can be invoked ensuring that the relevant event is found.
4730429
Foreground Object Detection Using Two Successive Images###Detecting foreground object often need to face the problems of illumination change and image noise. In this paper, we propose an object detection method using two successive image frames. Illumination change would be very small in such short time, and then we can handle the first problem more easily. Image noise will confuse the detection of an object boundary. To handle this problem, we apply level set method to enclose the foreground object regions. The experiments show that our method can be applied to extract foreground objects in various environments and different cameras.
4730428
Commentary Paper on "Shadow Removal in Indoor Scenes"###The technique proposed in this paper combines three algorithms for shadow removal in indoor scenes. First algorithm takes an advantage of the assumption on the chromaticity consistency: the ambient light chromaticity is approximately the same as the chromaticity of the diffuse light. Magnitude of differences between chromaticity values of shadow and non-shadow regions for different hue values are different for RGB and HSV color spaces so both spaces are used in conjunction by setting thresholds on these differences. Second algorithm takes a potential shadow region and applies a threshold on the intensity reduction of each pixel and its neighboring pixels. It is ensured that the shadow regions are above minimum specified size. The third algorithm uses a threshold on the intensity reduction as a result of light being blocked by moving objects. This reduction depends on the background geometry, light source, moving object size, and position. The threshold reduction caused by a shadow is obtained by manually specifying shadow regions and recording these values which are later used for shadow removal in the same scene.
4730427
Shadow Removal in Indoor Scenes###In this paper, we propose a shadow removal algorithm for indoor scenes. This algorithm uses three types of constraints: chromaticity consistency, texture consistency and range of shadow intensity. The chromaticity consistency is verified in both HSV and RGB color spaces. The texture verification is based on the local coherency (over a pixel neighbourhood) of intensity reduction ratio between shadows and background. Finally, for the range of shadow intensity, we define a localized lower bound of the intensity reduction ratio so that dark mobile objects are not classified as shadows. Because the chromaticity constraint is only correct if the chromaticity of ambient light is the same as that of diffuse light, our algorithms only works in the indoor scenes.
4730441
People Detection and Tracking with TOF Sensor###This paper presents a method to detect, track and count people which pass a confined space using the latest 3D Time-of-Flight (ToF) sensor technology. A slicing algorithm is employed and a novel method is proposed which derives the slicing level based on the probability density function and histogram respectively. It was found that the algorithm, exploiting the data of one sensor only, works very well for normal situations. However, additional information needs to be made available to the system to solve specials cases, such as wheel chairs, push chairs or very closely spaced people.
4730436
Commentary Paper 2 on "Visual Players Detection and Tracking in Soccer Matches"###This paper presents an end-to-end video system for detection, tracking, and classifying objects within the scope of a soccer match.
4730440
Local Initiation Method for Multiple Object Association in Surveillance Environment with Multiple Cameras###Multiple object association is an important capability in visual surveillance system with multiple cameras. An association approach using the limits of field of View (FOV) of cameras is well accepted but this approach has to wait until the object crosses the limits for association. Also, FOV information has to be determined whenever the setup of camera is changed. Our approach is to dynamically generate the global homographic line whenever it is needed for multi-object association with the aim to work on dynamic camera environment, where the change of camera frequently occurs and objects move in a complicated fashion. We show that, with this approach, the system can initiate association procedure as needed and allow itself to actively adapt to the dynamic environment, while maintaining consistent states of the objects.
4730399
Commentary Paper 2 on Action Signature: A Novel Holistic Representation for Action Recognition###This paper describes a method for action recognition using a classification algorithm based on mixtures of von Mises distributions processing action signatures. An action signature is a ID sequence of angles, forming a trajectory, which are extracted from a 2D map of adjusted orientations (subtracting the average orientation) of the gradient of the motion-history image. To obtain the action signature, the authors scan the image along the direction given by the average gradient orientation, selecting only the points for which the motion energy is equal to 1. The authors use Mixture of von Mises distributions to describe the action signature. The parameters of these distributions are found by applying the Expectation-Maximization (EM) algorithm. A similarity measure based on global alignment (inexact matching) and optimized by dynamic programming is used for the training and the classification of actions. To cope with the huge variability of actions, the authors adopt a learn-and-predict strategy in order to update and refine continuously the action clusters of the learned database. The algorithm is validated with a set of 25 videos. Each video portrays a person performing a sequence of 8 actions.
4730398
Commentary Paper 1 on &#147;Action Signature: A Novel Holistic Representation for Action Recognition&#148;###The paper proposes a new holistic representation for actions, called action signature, which uses both global and local motion variations to classify an action. The action signatures are generated by estimating a sequence of orientations from the motion history images. A mixture of von Mises distributions is used in the classification stage of the system.
4730403
Multi-view Access Monitoring and Singularization in Interlocks###We present a method aimed at monitoring access to interlocks and secured entrance areas, which deploys two views in order to robustly perform intrusion detection and singularization. The main contributions are represented by an original approach to perform background subtraction, which is particularly robust against sudden illumination changes, shadows and photometric distortions, and by the use of a feature extraction and classification approach which allows to reliably determine an estimation of the number of people currently occupying the monitored area. Our system is designed to operate in very small interlocks and can work in a substantially unstructured environment.
4730402
Commentary Paper 2 on "A Localized Approach to Abandoned Luggage Detection with Foreground-Mask Sampling"###This paper proposes an approach to abandoned luggage detection that mimics human behavior in monitoring a scene: first the abandoned luggage is detected through a foreground-mask sampling; then people nearby the detected object are tracked to eventually associate the left object with its possessor; ultimately, MAP principle is applied to perform reasoning.
4730405
Commentary Paper 2 on "Multi-view Access Monitoring and Singularization in Interlocks"###This is a commentary paper on ldquoMulti-view access monitoring and singularization in interlocksrdquo. Stefano et al. (2008) presents a multi-view approach to access monitoring and classification of single or multiple occupants (singularization detection) in access restricted areas (interlocks). Two main contributions are made by Stefano et al. (2008). One is a robust background subtraction algorithm using multiple background models in various illuminations. This algorithm is used for floor area and floor border segmentation. The second contribution is to extract features from multiple views (two views in the experiments) for singularization detection.
4730404
Commentary Paper 1 on &#147;Multi-view Access Monitoring and Singularization in Interlocks&#148;###This paper presents a way to detect the presence and number of people in an "interlock" form of a security portal.
4730407
Commentary Paper on &#147;Learning and Classification of Trajectories in Dynamic Scenes: A General Framework for Live Video Analysis&#148;###The paper describes a general platform for live video analysis. The first stage of the platform is to build a topological scene description by learning the location of nodes (i.e. zones), which are called points of interest. There are two kinds of points of interest, the entry-exit zones (areas where moving object appear and disappear in the scene) and the stopping zones (areas where the moving objects have slow speed or remain in a circle of radius R for more than t seconds). The zones are modelled by 2D Gaussian methods. The routes between nodes are learned considering only the spatial location of trajectories in the image scene and using fuzzy C means (FCM) clusterization of the trajectories that begin in an entry zone, end in an exit zone and do not remain in a stop zone. The main trajectory cluster points are aligned using dynamic time warping and merged if the Euclidean distance is lower than a threshold.The second stage consists in the modelling of the paths by introducing not only the spatial location of the trajectories but the dynamics as well to analyze behaviour. The spatio-temporal path properties are encoded using Hidden Markov Models. The platform makes one model for each cluster computed in the previous stage. The training of each HMM model is done with the paths associated to each FCM cluster. The platform adds new models by using a batch update procedure. Trajectories that do not fit in any of the models are collected and re-clustered periodically. The HMMs are updated using maximum likehood linear regression (MLLR). Each time a new trajectory is classified into a path, a transformation is learned and applied to the mean of each of the HMM states updating its corresponding path model.The last stage comprises the behaviour analysis. Each novel trajectory detected is classified into a path by comparison with all the HMMs using forward-backward procedure finding the HMM with the maximum likelihood. Anomalous trajectories are recognized deciding that i- ts likelihood is low, by comparing the likelihood with a decision threshold. The decision threshold is learned during training. The platform also provides an online tracking analysis method. In this case a small window of the last trajectory points is analysed, this window is constantly updated with incoming points. The live tracking classification is done considering only the most recent points of the window by comparing the points with the HMMs to estimate the likelihood at each time the window is updated. The platform can detect abnormalities during live tracking by a similar method used with complete trajectories. Path prediction is described using the HMMs by calculating the top 3 best fit paths determined with the HMM likelihoods and then estimating the probability of the incomplete trajectory to remain in one of those paths.
4730406
Learning and Classification of Trajectories in Dynamic Scenes: A General Framework for Live Video Analysis###This paper presents a general framework for live video analysis. The activities of surveillance subjects are described using a spatio-temporal vocabulary learned from recurrent motion patterns. The repetitive nature of object trajectories is used to build a topographical scene description where nodes are points of interest (POT) and the edges correspond to activity paths (AP). The POI are learned through as a mixture of Gaussians and AP by clustering trajectories. The paths are probabilistically represented by hidden Markov models and adapt to temporal variations using online maximum likelihood regression (MLLR) and through a periodic batch update. Using the scene graph, new trajectories can be analyzed in online fashion to categorize past and present activity, predict future behavior, and detect abnormalities.
4730391
Commentary Paper 2 on "Tracking People in Crowds by a Part Matching Approach"###This paper is about an approach for tracking human targets through occlusions by applying a human model made of discrete parts.
4730390
AVSS 2008 Commentary Paper for: "Tracking People in Crowds by a Part Matching Approach"###One of the major problems remaining in tracking is occlusion handling. This paper presents a system for exactly this. A human model is defined and each body part is represented by a number of features. For each new image in a sequence a foreground mask is obtained and compared to each body part of a predicted model of the human. Head detection is utilized to stabilize the tracking. The system is tested on two sequences form two public databases.
4730393
Commentary Paper on "A Probabilistic Template Update Method"###This paper describes a novel approach to updating a template in a template tracking scheme. Specifically, the technique involves thermal imagery and makes appropriate use of domain knowledge to set thresholds based on physiological temperature constraints.
4730392
A Probabilistic Template Update Method for Tracking Facial Tissue in Thermal Infrared###A novel template update method is proposed for facial tissue tracking in thermal clips. It is a smoothed matte approach, which provides the location along with the rate of updating. The template is able to adapt to abrupt orientation and physiological changes, while remaining robust to noise disturbances. Furthermore, it addresses successfully the difficult template drift problem. The new method was tested on tracking face regions in 40 thermal clips of individuals in varying psycho-physiological and environmental conditions. It demonstrated stability and accuracy, outperforming other template update strategies. The method promises improved performance in contact-free polygraphy and thus, it is of value in this emerging form of close range surveillance.
4730395
Commentary Paper 1 on "A Probabilistic Bayesian Framework for Model-Based Object Tracking Using Undecimated Wavelet Packet Descriptors"###This paper presents a very good approach for tracking through occlusion by applying a probabilistic model to tracking features on an object. The authors present that the method works well even through partial occlusions.
4730394
A Probabilistic Bayesian Framework for Model-Based Object Tracking Using Undecimated Wavelet Packet Descriptors###The paper presents a probabilistic Bayesian framework for object tracking using a combination of a corner-based model and coefficients of Undecimated wavelet packet transform (UWPT) inside a patch around each corner. This combination uses the UWPT coefficients patch helps to enrich the global representation of the object shape model by local descriptors. The goal is to maximize the posterior of the object global position. To this end, a voting mechanism is used based on the coherency among the model corners. The role of the local wavelet-based descriptors is to filter out some irrelevant observation before the voting process. Experimental results indicate good performances of the algorithm in crowd scenes and partial occlusions.
4730397
Action Signature: A Novel Holistic Representation for Action Recognition###Recognizing different actions with a unique approach can be a difficult task. This paper proposes a novel holistic representation of actions that we called "action signature". This 1D trajectory is obtained by parsing the 2D image containing the orientations of the gradient calculated on the motion feature map called motion-history image. In this way, the trajectory is a sketch representation of how the object motion varies in time. A robust statistical framework based on mixtures of von Mises distributions and dynamic programming for sequence alignment are used to compare and classify actions/trajectories. The experimental results show a rather high accuracy in distinguishing quite complicated actions, such as drinking, jumping, or abandoning an object.
4730396
Commentary Paper 2 on "A Probabilistic Bayesian Framework for Model-Based Object Tracking Using Undecimated Wavelet Packet Descriptors"###This uses combination of corner-based model and coefficients of undecimated wavelet packet transform (UWPT) for the proposed probabilistic Bayesian framework for object tracking. The UWPT coefficients are calculated for patch around each corner. The proposed scheme uses local descriptors e.g. UWPT coefficients, to improve global representation of object shape model. The proposed scheme then estimates global position of the object using voting based on coherency among the model corners.
4730401
Commentary Paper 1 on "A Localized Approach to Abandoned Luggage Detection with Foreground-Mask Sampling"###The paper presents a method for the detection of abandoned luggage in video surveillance applications. The technique uses a foreground sampling method to localize abandoned luggage in the presence of cluttered scenes. A subsequent approach for person detection is proposed in order to detect the owners of the luggage, by using a combination of skin color detection and a generalized Hough transform for head-and-shoulders detection.
4730379
Commentary Paper on "Dynamic Models for People Detection and Tracking"###The paper presents an adaptive approach for person detection and tracking. The key feature of the proposed method is the ability to detect an object as a member of a generic class (in this case, a pedestrian) as it enters the scene, then dynamically build and maintain a model of its appearance that allows tracking of this specific instance of the class. Such an approach also addresses the problem of recognizing the object if it leaves and then re-enters the scene.
4730378
Dynamic Models for People Detection and Tracking###In this paper we propose a real-time algorithm for detecting and tracking moving objects in a video sequence. Based on the on-line boosting framework, our algorithm is able to detect an object as a member of a class, e.g. pedestrian, then a specific model for each instance of the class can be built on-line allowing at the same time robust tracking and recognition of the particular instance as it leaves and re-enters the scene. Promising experimental results have been performed on standard video sequences.
4730400
A Localized Approach to Abandoned Luggage Detection with Foreground-Mask Sampling###In this paper we propose a novel approach to the detection of abandoned luggage in video surveillance. Candidates of abandoned luggage items which may pose potential security threats are first identified and localized by our proposed foreground-mask sampling technique. Our approach can deal with luggage pieces of arbitrary shape and color without the need for prior learning, and it works well under crowded and highly-cluttered situations. This localization of suspicious luggage items in the scene enables us to focus attention and subsequent processing solely on their neighborhoods. The owner of the luggage is then located and tracked to determine whether or not the luggage has been abandoned deliberately. A probability model using the MAP principle is employed to calculate a posteriori confidence score for the luggage-abandonment event, and an alarm will be automatically triggered if the certainty of luggage abandonment is higher than a pre-defined threshold. We show our results on the video datasets provided by the 2007 IEEE International Conference on Advanced Video and Signal based Surveillance (AVSS 2007) and the 2006 IEEE International Workshop on Performance Evaluation of Tracking and Surveillance (PETS 2006).
4730373
Commentary Paper on "Textural Segmentation of Sidescan Sonar Images Based on Gabor Filters Bank and Active Contours without Edges"###In this paper the authors present a technique suitable for segmenting high resolution sidescan sonar images, which is a problem that may arise in military or civilian applications. To this end, they use the "active contours without edges" model that was proposed by Chan and Vese.
4730372
Textural Segmentation of Sidescan Sonar Images Based on Gabor Filters Bank and Active Contours without Edges###This work deals with textural segmenting of high resolution sidescan sonar images by using active contours and Gabor filters. In fact this method is a modification of Chan and Vese Active contour model. It makes the method suitable for textural segmenting of above said images. First, image is passed through a symmetric bank of Gabor filters. Then, filtered images that possess a significant component of the original image are subjected to morphological closing operator. At the end, we use multi channel C-V active contour model for segmenting areas with different textures. Results of the proposed method are presented for different real and simulated sidescan sonar images to demonstrate the robustness of it.
4730432
Experimental Analysis of Face Recognition on Still and CCTV Images###Although automatic identity inference based on faces has shown success when using high quality images, for CCTV based images it is hard to attain similar levels of performance. Furthermore, compared to recognition based on static images, relatively few studies have been done for video based face recognition. In this paper, we present an empirical analysis and comparison of face recognition using high quality and CCTV images in several important aspects: image quality (including resolution, noise, blurring and interlacing) as well as geometric transformations (such as translations, rotations and scale changes). The results show that holistic face recognition can be tolerant to image quality degradation but can also be highly influenced by geometric transformations. In addition, we show that camera intrinsics have much influence - when using different cameras for collecting gallery and probe images the recognition rate is considerably reduced. We also show that the classification performance can be considerably improved by straightforward averaging of consecutive face images from a CCTV video sequence.
4730377
Commentary Paper 2 on "Robust Unattended and Stolen Object Detection by Fusing Simple Algorithms"###The technique discussed in this article proposes to distinguish between unattended and stolen objects by combining shape and appearance similarity measures of foreground objects observed in consecutive frames of a video. Static objects are detected by examining trajectories and people are removed from consideration. Object shape boundary is first refined using active contours. Shape similarity is then defined by computing gradient magnitudes along the object boundaries and counting how many boundary pixels have values higher/lower than predefined thresholds. Appearance similarity is based on differences between histograms using the foreground mask on the current and background images. Probabilities are defined assuming the shape and appearance measures follow the Gaussian distribution (with trained parameters). Final measures of unattended/stolen objects are produced by averaging the probabilities and used to classify static-nonhuman objects. Experiments show that combining the three measures gives better results than using each of the measures alone.
4730376
Commentary Paper 1 on "Robust Unattended and Stolen Object Detection by Fusing Simple Algorithms"###The paper presents methods for the detection of abandoned or stolen objects in a scene monitored by a video camera. Three weak detectors are combined to improve the overall performance of the system.
4730375
Robust Unattended and Stolen Object Detection by Fusing Simple Algorithms###In this paper a new approach for detecting unattended or stolen objects in surveillance video is proposed. It is based on the fusion of evidence provided by three simple detectors. As a first step, the moving regions in the scene are detected and tracked. Then, these regions are classified as static or dynamic objects and human or nonhuman objects. Finally, objects detected as static and nonhuman are analyzed with each detector. Data from these detectors are fused together to select the best detection hypotheses. Experimental results show that the fusion-based approach increases the detection reliability as compared to the detectors and performs considerably well across a variety of multiple scenarios operating at realtime.
4730374
Vehicle Detection Using Multi-level Probability Fusion Maps Generated by a Multi-camera System###In this paper we describe a multi-camera traffic monitoring system relying on the concept of probability fusion maps (PFM) to detect vehicles in a traffic scene. In the PFM, traffic images from multiple cameras are inverse perspective-mapped and registered onto a common reference frame, combining the multiple camera information to reduce the impact of occlusions. Although the unconstrained perspective projection is non-invertible, imposing the condition that the image points be co-planar allows inversion. However, in a traffic scene, the co-planarity of image points is not strictly true, so the PFM are subject to distortions. We present a new approach that reduces these distortions by projecting the camera images onto planes at different offsets from the road plane. These PFM are combined to generate a multi-level (ML) PFM. We show that the distortions in the various projection planes offset and the ML PFM thus improves vehicle detection in the presence of occlusions.
4730435
Commentary Paper 1 on "Visual Players Detection and Tracking in Soccer Matches"###This paper provides comments to the paper "Visual Players Detection and Tracking in Soccer Matches". It was prepared as part of an experimental open review process for the 5th IEEE International Conference On Advanced Video and Signal Based Surveillance for which the author of this commentary paper acted as a reviewer. Due to the conference submission process, this comment was prepared for the review version of the paper and does not consider changes that the authors may have made for the print version of their work. The reviewed paper addresses the problems of automatically detecting, classifying and tracking players in soccer matches. It focuses on three separate sub-problems: estimation of a background model that represents the empty soccer field, classification of team players, and player tracking.
4730424
Commentary Paper 1 on "Automatic Detection of Adverse Weather Conditions in Traffic Scenes"###This paper describes two solutions for detecting snow and fog, respectively, in traffic scenes. The former weather condition is detected by modeling the video luminance with a mixture of Gaussians (MoG), while the latter is detected analyzing the Fourier harmonic frequencies.
4730421
Person Tracking with Audio-Visual Cues Using the Iterative Decoding Framework###Tracking humans in an indoor environment is an essential part of surveillance systems. Vision based and microphone array based trackers have been extensively researched in the past. Audio-visual tracking frameworks have also been developed. In this paper we consider human tracking to be a specific instance of a more general problem of information fusion in multimodal systems. Dynamic Bayesian networks have been the modeling technique of choice to build such information fusion schemes. The complexity and non-Gaussianity of distributions of the dynamic Bayesian networks for such multimodal systems have led to the use of particle filters as an approximate inference technique. In this paper we present an alternative approach to the information fusion problem. The iterative decoding algorithm is based on the theory of turbo codes and factor graphs used in communication systems. We modify and adapt the iterative decoding algorithm to do probabilistic inference for the problem of tracking humans in an indoor space, using multiple cameras and microphone arrays.
4730423
Automatic Detection of Adverse Weather Conditions in Traffic Scenes###Visual surveillance in outdoor environments requires the monitoring of both objects and events. The analysis is generally driven by the target application which, in turn, determines the set of relevant events and objects to be analyzed. In this paper we concentrate on the analysis of outdoor scenes, in particular for vehicle traffic control. In this scenario, the analysis of weather conditions is considered to signal particular and potentially dangerous situations like the presence of snow, fog, or heavy rain. The developed system uses a statistical framework based on the mixture of Gaussians to identify changes both in the spatial and temporal frequencies which characterize specific meteorological events. Several experiments performed on standard databases and real scenes demonstrate the applicability of the proposed approach.
4730425
Commentary Paper 2 on "Automatic Detection of Adverse Weather Conditions in Traffic Scenes"###The paper presents a methodology for the detection of adverse weather conditions (snow and fog) in video sequences of traffic scenes. The snow falling is detected by tuning the learning parameter of the background model, while the fog is detected by analyzing the frequency spectrum from the Fourier Transform of the image.
4730422
Commentary Paper on &#147;Person Tracking With Audio-Visual Cues Using the Iterative Decoding Framework&#148;###This paper presents an information theoretic approach to the problem of fusing information from multiple disparate sources for the problem of person tracking. Specifically, the approach is presented for the use of audio-visual cues in tracking people in indoor environments.
4425338
A LQR spatiotemporal fusion technique for face profile collection in smart camera surveillance###In this paper, we propose a joint face orientation estimation technique for face profile collection in smart camera networks. The system is composed of in-node coarse estimation and joint refined estimation between cameras. In-node signal processing algorithms are designed to be lightweight to reduce computation load, yielding coarse estimates which may be erroneous. The proposed model-based technique determines the orientation and the angular motion of the face using two features, namely the hair-face ratio and the head optical flow. These features yield an estimate of the face orientation and the angular velocity through least squares (LS) analysis. In the joint refined estimation step, a discrete-time linear dynamical model is defined. Spatiotemporal consistency between cameras is measured by a cost function, which is minimized through linear quadratic regulation (LQR) to yield a robust closed-loop feedback system that estimates the face orientation, angular motion, and relative angular difference to the face between cameras. Based on the face orientation estimates, a collection of face profile are accumulated over time as the human subject moves around. The proposed technique does not require camera locations to be known in prior, and hence is applicable to vision networks deployed casually without localization.
4425339
2D and 3D face localization for complex scenes###In this paper, we address face tracking of multiple people in complex 3D scenes, using multiple calibrated and synchronized far-field recordings. We localize faces in every camera view and associate them across the different views. To cope with the complexity of 2D face localization introduced by the multitude of people and unconstrained face poses, a combination of stochastic and deterministic trackers, detectors and a Gaussian mixture model for face validation are utilized. Then faces of the same person seen from the different cameras are associated by first finding all possible associations and then choosing the best option by means of a 3D stochastic tracker. The performance of the proposed system is evaluated and is found enhanced compared to existing systems.
4425330
Classification of gait types based on the duty-factor###This paper deals with classification of human gait types based on the notion that different gait types are in fact different types of locomotion, i.e., running is not simply walking done faster. We present the duty-factor, which is a descriptor based on this notion. The duty-factor is independent on the speed of the human, the cameras setup etc. and hence a robust descriptor for gait classification. The duty-factor is basically a matter of measuring the ground support of the feet with respect to the stride. We estimate this by comparing the incoming silhouettes to a database of silhouettes with known ground support. Silhouettes are extracted using the codebook method and represented using shape contexts. The matching with database silhouettes is done using the Hungarian method. While manually estimated duty-factors show a clear classification the presented system contains misclassifications due to silhouette noise and ambiguities in the database silhouettes.
4425331
View-invariant human feature extraction for video-surveillance applications###We present a view-invariant human feature extractor (shape+pose) for pedestrian monitoring in man-made environments. Our approach can be divided into 2 steps: firstly, a series of view-based models is built by discretizing the viewpoint with respect to the camera into several training views. During the online stage, the Homography that relates the image points to the closest and most adequate training plane is calculated using the dominant 3D directions. The input image is then warped to this training view and processed using the corresponding view-based model. After model fitting, the inverse transformation is performed on the resulting human features obtaining a segmented silhouette and a 2D pose estimation in the original input image. Experimental results demonstrate our system performs well, independently of the direction of motion, when it is applied to monocular sequences with high perspective effect.
4425332
Human activity recognition with action primitives###This paper considers the link between tracking algorithms and high-level human behavioural analysis, introducing the action primitives model that recovers symbolic labels from tracked limb configurations. The model consists of similar short-term actions, action primitives clusters, formed automatically and then labelled by supervised learning. The model allows both short actions and longer activities, either periodic or aperiodic. New labels are added incrementally. We determine the effects of model parameters on the labelling of action primitives using ground truth derived from a motion capture system. We also present a representative example of a labelled video sequence.
4425333
Image-based shape model for view-invariant human motion recognition###We propose an image-based shape model for view-invariant human motion recognition. Image-based visual hull explicitly represents the 3D shape of an object, which is computed from a set of silhouettes. We then use the set of silhouettes to implicitly represent the visual hull. Due to the fact that a silhouette is the 2D projection of an object in the 3D world with respect to a certain camera, which is sensitive to the point of view, our multi-silhouette representation for the visual hull entails the correspondence between views. To guarantee the correspondence, we define a canonical multi-camera system and a canonical human body orientation in motions. We then "normalize" all the constructed visual hulls into the canonical multi-camera system, align them to follow the canonical orientation, and finally render them. The rendered views thereby satisfy the requirement of the correspondence. In our visual hull's representation, each silhouette is represented as a fixed number of sampled points on its closed contour, therefore, the 3D shape information is implicitly encoded into the concatenation of multiple 2D contours. Each motion class is then learned by a Hidden Markov Model (HMM) with mixture of Gaussians outputs. Experiments using our algorithm over some data sets give encouraging results.
4425334
Compact representation and probabilistic classification of human actions in videos###This paper addresses the problem of classifying human actions in a video sequence. A representation eigenspace approach based on the PCA algorithm is used to train the classifier according to an incremental learning scheme based on a "one action, one eigenspace" approach. Before dimensionality reduction, a high dimensional description of each frame of the video sequence is constructed, based on foreground blob analysis. Classification is performed by matching incrementally the reduced representation of the test image sequence against each of the learned ones, and accumulating matching scores according to a probabilistic framework, until a decision is obtained. Experimental results with real video sequences are presented and discussed.
4425335
Fusion of background estimation approaches for motion detection in non-static backgrounds###Detection of moving objects is a fundamental task in video based surveillance and security applications. Many detection systems use background estimation methods to model the observed environment. In outdoor surveillance, moving backgrounds (waving trees, clutter) and illumination changes (weather changes, reflections, etc.) are the major challenges for background modelling and the development of a single model that fulfils all these requirements is usually not possible. In this paper we present a background estimation technique for motion detection in non-static backgrounds that overcomes this problem. We introduce an enhanced background estimation architecture with a long-term model and a short-term model. Our system showed that fusion of the detections of these two complementary approaches, improves the quality and reliability of the detection results.
4425336
On the development of an autonomous and self-adaptable moving object detector###Object detection is a crucial step in automating monitoring and surveillance. A classical approach to object detection employs supervised learning methods, which are effective in well-defined narrow application scopes. In this paper we propose a framework for detecting moving objects in video, which first learns autonomously and on-line the characteristic features of typical object appearances at various parts of the observed scene. The collected knowledge is then used to calibrate the system for the given scene, and to separate isolated appearances of a dominant moving object from other events. Compared to the supervised detectors, the proposed framework is self-adaptable, and therefore able to handle large diversity of objects and situations, typical for general surveillance and monitoring applications. We demonstrate the effectiveness of our framework by employing it to isolate pedestrians in public places and cars on a highway.
4425337
On the effect of motion segmentation techniques in description based adaptive video transmission###This paper presents the results of analysing the effect of different motion segmentation techniques in a system that transmits the information captured by a static surveillance camera in an adaptative way based on the on-line generation of descriptions and their descriptions at different levels of detail. The video sequences are analyzed to detect the regions of activity (motion analysis) and to differentiate them from the background, and the corresponding descriptions (mainly MPEG-7 moving regions) are generated together with the textures of the moving regions and the associated background image. Depending on the available bandwidth, different levels of transmission are specified, ranging from just sending the descriptions generated to a transmission with all the associated images corresponding to the moving objects and background. We study the effect of three motion segmentation algorithms in several aspects such as accurate segmentation, size of the descriptions generated, computational efficiency and reconstructed data quality.
4425305
Vision based anti-collision system for rail track maintenance vehicles###Maintenance trains travel in convoy. In Australia, only the first train of the convoy pays attention to the track signalization (the other convoy vehicles simply follow the preceding vehicle). Because of human errors, collisions can happen between the maintenance vehicles. Although an anti-collision system based on a laser distance meter is already in operation, the existing system has a limited range due to the curvature of the tracks. In this paper, we introduce an anti-collision system based on vision. The proposed system induces a 3D model of the track as a piecewise quadratic function (with continuity constraints on the function and its derivative). The geometric constraints of the rail tracks allow the creation of a completely self-calibrating system. Although road lane marking detection algorithms perform well most of the time for rail detection, the metallic surface of a rail does not always behave like a road lane marking. Therefore we had to develop new techniques to address the specific problems of the reflectance of rails.
4425304
Vehicular traffic density estimation via statistical methods with automated state learning###This paper proposes a novel approach of combining an unsupervised clustering scheme called AutoClass with Hidden Markov Models (HMMs) to determine the traffic density state in a Region Of Interest (ROI) of a road in a traffic video. Firstly, low-level features are extracted from the ROI of each frame. Secondly, an unsupervised clustering algorithm called AutoClass is then applied to the low-level features to obtain a set of clusters for each pre-defined traffic density state. Finally, four HMM models are constructed for each traffic state respectively with each cluster corresponding to a state in the HMM and the structure of HMM is determined based on the cluster information. This approach improves over previous approaches that used Gaussian Mixture HMMs (GMHMM) by circumventing the need to make an arbitrary choice on the structure of the HMM as well as determining the number of mixtures used for each density traffic state. The results show that this approach can classify the traffic density in a ROI of a traffic video accurately with the property of being able to handle the varying illumination elegantly.
4425307
Sphere detection and tracking for a space capturing operation###Capture mechanisms are used to transfer objects between two vehicles in the space with no physical contact. A sphere (canister) detection and tracking method using an enhanced Hough transform technique and H<sub>infin</sub> filter is proposed. The presented system aims to assist in the capture operation, currently investigated the European Space Agency and other partners, and to be used in space missions as an alternative to docking or berthing operations. Test results show the robustness and reliability of the proposed method. They also demonstrate the low computational and memory complexities needed.
4425306
An efficient particle filter for color-based tracking in complex scenes###In this paper, we introduce an efficient method for particle selection in tracking objects in complex scenes. First, we improve the proposal distribution function of the tracking algorithm, including current observation, reducing the cost of evaluating particles with a very low likelihood. In addition, we use a partitioned sampling approach to decompose the dynamic state in several stages. It enables to deal with high-dimensional states without an excessive computational cost. To represent the color distribution, the appearance of the tracked object is modelled by sampled pixels. Based on this representation, the probability of any observation is estimated using non-parametric techniques in color space. As a result, we obtain a probability color density image (PDI) where each pixel points its membership to the target color model. In this way, the evaluation of all particles is accelerated by computing the likelihood p(zx) using the integral image of the PDI.
4425301
Single camera calibration for trajectory-based behavior analysis###Perspective deformations on the image plane make the analysis of object behaviors difficult in surveillance video. In this paper, we improve the results of trajectory-based scene analysis by using single camera calibration for perspective rectification. First, the ground-plane view is estimated from perspective images captured from a single camera. Next, unsupervised fuzzy clustering is applied on the transformed trajectories to group similar behaviors and to isolate outliers. We evaluate the proposed approach on real outdoor surveillance scenarios with standard datasets and show that perspective rectification improves the accuracy of the trajectory clustering results.
4425300
Detection of abnormal behaviors using a mixture of Von Mises distributions###This paper proposes the use of a mixture of Von Mises distributions to detect abnormal behaviors of moving people. The mixture is created from an unsupervised training set by exploiting k-medoids clustering algorithm based on Bhattacharyya distance between distributions. The extracted medoids are used as modes in the multi-modal mixture whose weights are the priors of the specific medoid. Given the mixture model a new trajectory is verified on the model by considering each direction composing it as independent. Experiments over a real scenario composed of multiple, partially-overlapped cameras are reported.
4425303
Classifying and tracking multiple persons for proactive surveillance of mass transport systems###We describe a pedestrian classification and tracking system that is able to track and label multiple people in an outdoor environment such as a railway station. The features selected for appearance modelling are circular colour histograms for the hue and conventional colour histograms for the saturation and value components. We combine blob matching with a particle filter for tracking and augment these algorithms with colour appearance models to track multiple people in the presence of occlusion. In the object classification stage, hierarchical chamfer matching combined with particle filtering is applied to classify commuters in the railway station into several classes. Classes of interest include normal commuters, commuters with backpacks, commuters with suitcases, and mothers with their children.
4425302
Anomalous trajectory detection using support vector machines###One of the most promising approaches to event analysis in video sequences is based on the automatic modelling of common patterns of activity for later detection of anomalous events. This approach is especially useful in those applications that do not necessarily require the exact identification of the events, but need only the detection of anomalies that should be reported to a human operator (e.g. video surveillance or traffic monitoring applications). In this paper we propose a trajectory analysis method based on Support Vector Machines; the SVM model is trained on a given set of trajectories and can subsequently detect trajectories substantially differing from the training ones. Particular emphasis is placed on a novel method for estimating the parameter v, since it heavily influences the performances of the system but cannot be easily estimated a-priori. Experimental results are given both on synthetic and real-world data.
4425309
A 2D+3D face identification system for surveillance applications###A novel surveillance system integrating 2D and 3D facial data is presented in this paper, based on a low-cost sensor capable of real-time acquisition of 3D images and associated color images of a scene. Depth data is used for robust face detection, localization and 3D pose estimation, as well as for compensating pose and illumination variations of facial images prior to classification . The proposed system was tested under an open-set identification scenario for surveillance of humans passing through a relatively constrained area. Experimental results demonstrate the accuracy and robustness of the system under a variety of conditions usually encountered in surveillance applications.
4425308
A framework for track matching across disjoint cameras using robust shape and appearance features###This paper presents a framework based on robust shape and appearance features for matching the various tracks generated by a single individual moving within a surveillance system. Each track is first automatically analysed in order to detect and remove the frames affected by large segmentation errors and drastic changes in illumination. The object's features computed over the remaining frames prove more robust and capable of supporting correct matching of tracks even in the case of significantly disjointed camera views. The shape and appearance features used include a height estimate as well as illumination-tolerant colour representation of the individual's global colours and the colours of the upper and lower portions of clothing. The results of a test from a real surveillance system show that the combination of these four features can provide a probability of matching as high as 91 percent with 5 percent probability of false alarms under views which have significantly differing illumination levels and suffer from significant segmentation errors in as many as 1 in 4 frames.
4425312
Using social effects to guide tracking in complex scenes###This paper presents a new methodology for improving the tracking of multiple targets in complex scenes. The new method,Motion Parameter Sharing, incorporates social motion information into tracking predictions. This is achieved by allowing a tracker to share motion estimates within groups of targets which have previously been moving in a coordinated fashion. The method is intuitive and, as well as aiding the prediction estimates, allows the implicit formation of 'social groups' of targets as a side effect of the process. The underlying reasoning and method are presented, as well as a description of how the method fits into the framework of a typical Bayesian tracking system. This is followed by some preliminary results which suggest the method is more accurate and robust than algorithms which do not incorporate the social information available in multiple target scenarios.
4425313
Improving the robustness of particle filter-based visual trackers using online parameter adaptation###In particle filter-based visual trackers, dynamic velocity components are typically incorporated into the state update equations. In these cases, there is a risk that the uncertainty in the model update stage can become amplified in unexpected and undesirable ways, leading to erroneous behavior of the tracker. Moreover, the use of a weak appearance model can make the estimates provided by the particle filter inaccurate. To deal with this problem, we propose a continuously adaptive approach to estimating uncertainty in the particle filter, one that balances the uncertainty in its static and dynamic elements. We provide quantitative performance evaluation of the resulting particle filter tracker on a set of ten video sequences. Results are reported in terms of a metric that can be used to objectively evaluate the performance of visual trackers. This metric is used to compare our modified particle filter tracker and the continuously adaptive mean shift tracker. Results show that the performance of the particle filter is significantly improved through adaptive parameter estimation, particularly in cases of occlusion and erratic, nonlinear target motion.
4425310
CASSANDRA: audio-video sensor fusion for aggression detection###This paper presents a smart surveillance system named CASSANDRA, aimed at detecting instances of aggressive human behavior in public environments. A distinguishing aspect of CASSANDRA is the exploitation of the complimentary nature of audio and video sensing to disambiguate scene activity in real-life, noisy and dynamic environments. At the lower level, independent analysis of the audio and video streams yields intermediate descriptors of a scene like: "scream", "passing train" or "articulation energy". At the higher level, a Dynamic Bayesian Network is used as a fusion mechanism that produces an aggregate aggression indication for the current scene. Our prototype system is validated on a set of scenarios performed by professional actors at an actual train station to ensure a realistic audio and video noise setting.
4425311
Passive sensor based dynamic object association with particle filtering###This paper develops and evaluates the threshold based algorithm proposed in [S.H. Cho, J. Lee, and S. Hong, "Passive Sensor Based Dynamic Object Association Method in Wireless Sensor Network," Proceedings of MWSCAS07 and NEWCAS07, Aug. 2007. ] for dynamic data association in wireless sensor networks. The sensor node incorporates RFID reader and acoustic sensor where the signals are fused for tracking and associating multiple objects. The RFID tag is used for object identification and acoustic sensor is used for estimating object movement. For the better data association, we apply the particle filtering for the prediction of an object. The algorithm with the particle filtering has an effect on increasing the association case where even objects overlap. The simulation result is compared to that using only the original algorithm. The association performance under single node coverage and multiple node coverage is evaluated as a function of sampling time.
4425316
Detection of temporarily static regions by processing video at different frame rates###This paper presents an abandoned item and illegally parked vehicle detection method for single static camera video surveillance applications. By processing the input video at different frame rates, two backgrounds are constructed; one for short-term and another for long-term. Each of these backgrounds is defined as a mixture of Gaussian models, which are adapted using online Bayesian update. Two binary foreground maps are estimated by comparing the current frame with the backgrounds, and motion statistics are aggregated in a likelihood image by applying a set of heuristics to the foreground maps. Likelihood image is then used to differentiate between the pixels that belong to moving objects, temporarily static regions and scene background. Depending on the application, the temporary static regions indicate abandoned items, illegally parked vehicles, objects removed from the scene, etc. The presented pixel-wise method does not require object tracking, thus its performance is not upper-bounded to error prone detection and correspondence tasks that usually fail for crowded scenes. It accurately segments objects even if they are fully occluded. It can also be effectively implemented on a parallel processing architecture.
4425317
Stationary target detection using the objectvideo surveillance system###Detecting stationary objects, such as an abandoned baggage or a parked vehicle is crucial in a wide range of video surveillance and monitoring applications. ObjectVideo, the leader in intelligent video software has been deploying commercial products to address these problems for the last 5 years. The ObjectVideo VEW and OnBoard system addresses these problems using an array of algorithms optimized for various scenario types and can be selected dynamically. This paper describes the key challenges and algorithms, and presents results on the standard i-LIDS dataset.
4425314
MCMC based multi-body tracking using full 3D model of both target and environment###In this paper, we present a new approach for the stable tracking of variable interacting targets under severe occlusion in 3D space. We formulate the state of multiple targets as a union state space of each target, and recursively estimate the multi-body configuration and the position of each target in 3D space by using the framework of Trans-dimensional Markov Chain Monte Carlo(MCMC). The 3D environmental model, which replicates the real-world 3D structure, is used for handling occlusions created by fixed objects in the environment, and reliably estimating the number of targets in the monitoring area. Experiments show that our system can stably track multiple humans that are interacting with each other and entering and leaving the monitored area.
4425315
Tracking by using dynamic shape model learning in the presence of occlusion###The paper presents a new corner-model based learning method able to track non-rigid objects in the presence of occlusion. A voting mechanism followed by a probability density analysis of the voting space histogram is used to estimate new position of the target. The model is updated at any frame. The problem rises in the occlusion events where the occluder corners affect the model and the tracker may follow the occluder. The key point of the method toward success is automatically deciding on the corners to classify them into two classes, good and malicious corners. Good corners are used to update the model in a conservative way removing the corners that are voting to the highly voted wrong positions due to the occluder. This leads to a continuous model learning during occlusion. Experimental results show a successful tracking along with a more precise estimation of shape and motion during occlusion
4425318
Stationary objects in multiple object tracking###This paper presents an approach to detect stationary foreground objects in naturally busy surveillance video scenes with several moving objects. Our approach is inspired by human's visual cognition processes and builds upon a multi-tier video tracking paradigm with main layers being the spatially based "peripheral tracking" loosely corresponding to the peripheral vision and the object based "vision tunnels " for focused attention and analysis of tracked objects. Humans allocate their attention to different aspects of objects and scenes based on a defined task. In our model, a specific processing layer corresponding to allocation of attention is used for detection of objects that become stationary. The static object layer, a natural extension of this framework, detects and maintains the stationary foreground objects by using the moving object and scene information from Peripheral Tracker and the Scene Description layers. Simple event detection modules then use the enduring stationary objects to determine events such as Parked Vehicles or Abandoned Bags.
4425319
Real-time detection of illegally parked vehicles using 1-D transformation###With decreasing costs of high quality surveillance systems, human activity detection and tracking has become increasingly practical. Accordingly, automated systems have been designed for numerous detection tasks, but the task of detecting illegally parked vehicles has been left largely to the human operators of surveillance systems. We propose a methodology for detecting this event in realtime by applying a novel image projection that reduces the dimensionality of the image data and thus reduces the computational complexity of the segmentation and tracking processes. After event detection, we invert the transformation to recover the original appearance of the vehicle and to allow for further processing that may require the two dimensional data. The proposed algorithm is able to successfully recognize illegally parked vehicles in real-time in the i-LIDS bag and vehicle detection challenge datasets.
4425367
Watershed algorithm for moving object extraction considering energy minimization by snakes###MPEG-4, which is a video coding standard, supports object-based functionalities for high efficiency coding. MPEG-7, a multimedia content description interface, handles the object data in, for example, retrieval and/or editing systems. Therefore, extraction of semantic video objects is an indispensable tool that benefits these newly developed schemes. In the present paper, we propose a technique that extracts the shape of moving objects by combining snakes and watershed algorithm. The proposed method comprises two steps. In the first step, snakes extract contours of moving objects as a result of the minimization of an energy function. In the second step, the conditional watershed algorithm extracts contours from a topographical surface including a new function term. This function term is introduced to improve the estimated contours considering boundaries of moving objects obtained by snakes. The efficiency of the proposed approach in moving object extraction is demonstrated through computer simulations.
4425366
A fast algorithm for adaptive background model construction using parzen density estimation###Non-parametric representation of pixel intensity distribution is quite effective to construct proper background model and to detect foreground objects accurately. However, from the viewpoint of practical application, the computation cost of the distribution estimation should be reduced. In this paper, we present fast estimation of the probability density function (PDF) of pixel value using Parzen density estimation and foreground object detection based on the estimated PDF. Here, the PDF is computed by partially updating the PDF estimated at the previous frame, and it greatly reduces the computation cost of the PDF estimation. Thus, the background model adapts quickly to changes in the scene and, therefore, foreground objects can be robustly detected. Several experiments show the effectiveness of our approach.
4425365
Foreground object localization using a flooding algorithm based on inter-frame change and colour###A Bayesian, fully automatic moving object localization method is proposed, using inter-frame differences and background/foreground colour as discrimination cues. Change detection pixel classification to one of the labels "changed" or "unchanged" is obtained by mixture analysis, while histograms are used for statistical description of colours. High confidence, change detection based, statistical criteria are used to compute a map of initial labelled pixels. Finally, a region growing algorithm, which is named priority multi-label flooding algorithm, assigns pixels to labels using Bayesian dissimilarity criteria. Localization results on well-known benchmark image sequences as well as on webcam and compressed videos are presented.
4425364
Midground object detection in real world video scenes###Traditional video scene analysis depends on accurate background modeling to identify salient foreground objects. However, in many important surveillance applications, saliency is defined by the appearance of a new non-ephemeral object that is between the foreground and background. This midground realm is defined by a temporal window following the object's appearance; but it also depends on adaptive background modeling to allow detection with scene variations (e.g., occlusion, small illumination changes). The human visual system is ill-suited for midground detection. For example, when surveying a busy airline terminal, it is difficult (but important) to detect an unattended bag which appears in the scene. This paper introduces a midground detection technique which emphasizes computational and storage efficiency. The approach uses a new adaptive, pixel-level modeling technique derived from existing backgrounding methods. Experimental results demonstrate that this technique can accurately and efficiently identify midground objects in real-world scenes, including PETS2006 and AVSS2007 challenge datasets.
4425363
Facial biometry by stimulating salient singularity masks###We present a novel approach for face recognition based on salient singularity descriptors. The automatic feature extraction is performed thanks to a salient point detector, and the singularity information selection is performed by a SOM region-based structuring. The spatial singularity distribution is preserved in order to activate specific neuron maps and the local salient signature stimuli reveals the individual identity. This proposed method appears to be particularly robust to facial expressions and facial poses, as demonstrated in various experiments on well-known databases.
4425362
Learning gender from human gaits and faces###Computer vision based gender classification is an important component in visual surveillance systems. In this paper, we investigate gender classification from human gaits in image sequences, a relatively understudied problem. Moreover, we propose to fuse gait and face for improved gender discrimination. We exploit Canonical Correlation Analysis (CCA), a powerful tool that is well suited for relating two sets of measurements, to fuse the two modalities at the feature level. Experiments demonstrate that our multimodal gender recognition system achieves the superior recognition performance of 97.2% in large datasets.
4425361
A system for face detection and tracking in unconstrained environments###We describe a trainable system for face detection and tracking. The structure of the system is based on multiple cues that discard non face areas as soon as possible: we combine motion, skin, and face detection. The latter is the core of our system and consists of a hierarchy of small SVM classifiers built on the output of an automatic feature selection procedure. Our feature selection is entirely data-driven and allows us to obtain powerful descriptions from a relatively small set of data. Finally, a Kalman tracking on the face region optimizes detection results over time. We present an experimental analysis of the face detection module and results obtained with the whole system on the specific task of counting people entering the scene.
4425360
Representing and recognizing complex events in surveillance applications###In this paper, we investigate the problem of representing and maintaining rule knowledge for a video surveillance application. We focus on complex events representation which cannot be straightforwardly represented by canonical means. In particular, we highlight the ongoing efforts for a unifying framework for computable rule and taxonomical knowledge representation.
4425369
Adaptive summarisation of surveillance video sequences###We describe our studies on summarising surveillance videos using optical flow information. The proposed method incorporates motion analysis into a video skimming scheme in which the playback speed is determined by the detectability of interesting motion behaviours according to prior information. A psycho-visual experiment was conducted to compare human performance and viewing strategy for summarised videos using standard video skimming techniques and a proposed motion-based adaptive summarisation technique.
4425368
An efficient method for detecting ghost and left objects in surveillance video###This paper proposes an efficient method for detecting ghost and left objects in surveillance video, which, if not identified, may lead to errors or wasted computation in background modeling and object tracking in surveillance systems. This method contains two main steps: the first one is to detect stationary objects, which narrows down the evaluation targets to a very small number of foreground blobs; the second step is to discriminate the candidates between ghost and left objects. For the first step, we introduce a novel stationary object detection method based on continuous object tracking and shape matching. For the second step, we propose a fast and robust inpainting method to differentiate between ghost and left objects by constructing the real background using the candidate 's corresponding regions in the input and the background images. The effectiveness of our method has been validated by experiments over a variety of video sequences.
4425329
Data fusion with a multisensor system for damage control and situational awareness###The U.S. Naval Research Laboratory has developed an affordable, multisensory, real-time detection system for damage control and situational awareness, called "volume sensor." The system provides standoff identification of events within a space (e.g. flaming and smoldering fires, pipe ruptures, and gas releases) for U.S. Navy vessels. A data fusion approach was used to integrate spectral sensors, acoustic sensors, and video image detection algorithms. Bayesian-based decision algorithms improved event detection rates while reducing false positives. Full scale testing demonstrated that the prototype Volume Sensor performed as well or better than commercial video image detection and point-detection systems in critical quality metrics for fire detection while also providing additional situational awareness. The design framework developed for volume sensor can serve as a template for the integration of heterogeneous sensors into networks for a variety of real-time sensing and situational awareness applications.
4425328
Using behavior analysis algorithms to anticipate security threats before they impact mission critical operations###The objective of this research is to identify, develop, adapt, prototype, integrate and demonstrate open access force protection and security technologies and processes. The goal is to provide more open public access to recreational and other non-restricted facilities on military bases and to improve the overall base safety and security utilizing advanced video and signal based surveillance. A testbed was created at the Pacific Missile Range Facility (PMRF), Kauai, Hawaii to demonstrate novel and innovative security solutions that serve these objectives. The testbed consists of (1) novel sensors (video cameras, radio frequency identification tags, and seismic, lidar, microwave, and infrared sensors), (2) a computer, data storage, and network infrastructure, and (3) behavior analysis software. The behavior analysis software identifies patterns of behavior and discriminates "normal" and "anomalous" behavior in order to anticipate and predict threats so that they can be interdicted before they impact mission critical operations or cause harm to people and infrastructure.
4425374
Multitarget association and tracking in 3-D space based on particle filter with joint multitarget probability density###This paper addresses the problem of 3-dimensional (3D) multitarget tracking using particle filter with the joint multitarget probability density (JMPD) technique. The estimation allows the nonlinear target motion with unlabeled measurement association as well as non-Gaussian target state densities. In addition, we decompose the 3D formulation into multiple 2D particle filters that operate on the 2D planes. Both selection and combining of the 2D particle filters for 3D tracking are presented and discussed. Finally, we analyze the tracking and association performance of the proposed approach especially in the cases of multitarget crossing and overlapping.
4425375
3-D model-based people detection &#x00026; tracking###The paper describes a method for people detection and tracking from multi-camera views. The proposed approach is based on 3D models of the person shape, where motion tracking is carried out in 3D space with re-projection onto calibrated images to perform target validation according to a prediction-verification paradigm. Multiple cameras with partial overlap can be used to cover a much wider area. The referred examples are based on the data base from PETS 2006 video sequences and a data base from EU-ISCAPS demonstration environment.
4425370
Efficient side information encoding for text hardcopy documents###This paper proposes a new coding method that increases significantly the signal-to-watermark ratio in document watermarking algorithms. A possible approach to text document watermarking is to consider text characters as a data structure consisting of several modifiable features such as size, shape, position, luminance, among others. In existing algorithms, these features can be modified sequentially according to bit values to be embedded. In contrast, the solution proposed here uses a positional information coding approach to embed information. Using this approach, the information is related to the position of modified characters, and not to the bit embedded on each character. This coding is based on combinatorial analysis and it can embed more bits in comparison to the usual methods, given a distortion constraint. An analysis showing the superior performance of positional coding for this type of application is presented. Experiments validate the analysis and the applicability of the method.
4425371
Camera tamper detection using wavelet analysis for video surveillance###It is generally accepted that video surveillance system operators lose their concentration after a short period of time and may miss important events taking place. In addition, many surveillance systems are frequently left unattended. Because of these reasons, automated analysis of the live video feed and automatic detection of suspicious activity have recently gained importance. To prevent capture of their images, criminals resort to several techniques such as deliberately obscuring the camera view, covering the lens with a foreign object, spraying or de-focusing the camera lens. In this paper, we propose some computationally efficient wavelet domain methods for rapid camera tamper detection and identify some real-life problems and propose solutions to these.
4425372
High performance 3D sound localization for surveillance applications###One of the key features of the human auditory system, is its nearly constant omni-directional sensitivity, e.g., the system reacts to alerting signals coming from a direction away from the sight of focused visual attention. In many surveillance situations where visual attention completely fails since the robot cameras have no direct line of sight with the sound sources, the ability to estimate the direction of the sources of danger relying on sound becomes extremely important. We present in this paper a novel method for sound localization in azimuth and elevation based on a humanoid head. The method was tested in simulations as well as in a real reverberant environment. Compared to state-of-the-art localization techniques the method is able to localize with high accuracy 3D sound sources even in the presence of reflections and high distortion.
4425373
Tracking of two acoustic sources in reverberant environments using a particle swarm optimizer###In this paper we consider the problem of tracking multiple acoustic sources in reverberant environments. The solution that we propose is based on the combination of two techniques. A blind source separation (BSS) method known as TRINICON [5] is applied to the signals acquired by the microphone arrays. The TRINICON de-mixing filters are used to obtain the Time Differences of Arrival (TDOAs), which are related to the source location through a nonlinear function. A particle filter is then applied in order to localize the sources. Particles move according to a swarm-like dynamics, which significatively reduces the number of particles involved with respect to traditional particle filter. We discuss results for the case of two sources and four microphone pairs. In addition, we propose a method, based on detecting source inactivity, which overcomes the ambiguities that intrinsically arise when only two microphone pairs are used. Experimental results demonstrate that the average localization error on a variety of pseudo-random trajectories is around 40 cm when the T<sub>60</sub> reverberation time is 0.6s.
4425288
Camera mote with a high-performance parallel processor for real-time frame-based video processing###This paper describes a new smart camera mote with a high performance SIMD (single-instruction multiple-data) processor. Previous versions of our camera mote were equipped with IC3D, a line-based processor. The mote described in this paper is equipped with Xetal-II, a processor designed for frame-based real-time video analysis. The processor uses 320 processing elements in parallel to achieve performance figures of more than 100 GOPS with a power consumption of 600 mWatt at peak performance. The IC has a 10 Mbit internal memory cache to store and work on 4 VGA frames. The internal bandwidth to this memory is more than 1.5 Tbit/s allowing multiple passes over the images within frametime. Augmented with hardware tools for object processing, the new mote opens the door for embedded active vision applications and other iterative techniques such as watershedding and distance transforms in collaborative camera networks.
4425289
Searching surveillance video###Surveillance video is used in two key modes, watching for known threats in real-time and searching for events of interest after the fact. Typically, real-time alerting is a localized function, e.g. airport security center receives and reacts to a "perimeter breach alert", while investigations often tend to encompass a large number of geographically distributed cameras like the London bombing, or Washington sniper incidents. Enabling effective search of surveillance video for investigation &amp; preemption, involves indexing the video along multiple dimensions. This paper presents a framework for surveillance search which includes, video parsing, indexing and query mechanisms. It explores video parsing techniques which automatically extract index data from video, indexing which stores data in relational tables, retrieval which uses SQL queries to retrieve events of interest and the software architecture that integrates these technologies.
4425341
Multiple appearance models for face tracking in surveillance videos###Face tracking is a key component for automated video surveillance systems. It supports and enhances tasks such as face recognition and video indexing. Face tracking in surveillance scenarios is a challenging problem due to ambient illumination variations, face pose changes, occlusions, and background clutter. We present an algorithm for tracking faces in surveillance video based on a particle filter mechanism using multiple appearance models for robust representation of the face. We propose color based appearance model complemented by an edge based appearance model using the Difference of Gaussian (DOG) filters. We demonstrate that combined appearance models are more robust in handling the face and scene variations than a single appearance model. For example, color template appearance model is better in handling pose variations but they deteriorate against illumination variations. Similarly, an edge based model is robust in handling illumination variations but they fail in handling substantial pose changes. Hence, a combined model is more robust in handling pose and illumination changes than either one of them by itself. We show how the algorithm performs on a real surveillance scenario where the face undergoes various pose and illumination changes. The algorithm runs in real-time at 20 fps on a standard 3.0 GHz desktop PC.
4425340
Face localization by neural networks trained with Zernike moments and Eigenfaces feature vectors. A comparison###Face localization using neural network is presented in this communication. Neural network was trained with two different kinds of feature parameters vectors; Zernike moments and eigenfaces. In each case, coordinate vectors of pixels surrounding faces in images were used as target vectors on the supervised training procedure. Thus, trained neural network provides on its output layer a coordinate's vector (rho,thetas) representing pixels surrounding the face contained in treated image. This way to proceed gives accurate faces contours which are well adapted to their shapes. Performances obtained for the two kinds of training feature parameters were recorded using a quantitative measurement criterion according to experiments carried out on the XM2VTS database.
4425343
People tracking across two distant self-calibrated cameras###People tracking is of fundamental importance in multi-camera surveillance systems. In recent years, many approaches for multi-camera tracking have been discussed. Most methods use either various image features or the geometric relation between the cameras or both as a cue. It is a desire to know the geometry for distant cameras, because geometry is not influenced by, for example, drastic changes in object appearance or in scene illumination. However, the determination of the camera geometry is cumbersome. The paper tries to solve this problem and contributes in two different ways. On the one hand, an approach is presented that calibrates two distant cameras automatically. We continue previous work and focus especially on the calibration of the extrinsic parameters. Point correspondences are used for this task which are acquired by detecting points on top of people's heads. On the other hand, qualitative experimental results with the PETS 2006 benchmark data show that the self-calibration is accurate enough for a solely geometric tracking of people across distant cameras. Reliable features for a matching are hardly available in such cases.
4425342
Optimal deployment of cameras for video surveillance systems###This article describes a new method which aims at the optimal deployment of sensors for video-surveillance systems, taking realistic models of fixed and PTZ cameras into account, as well as video analysis requirements. The approach relies on a spatial translation of constraints, a method for fast exploration of potential solutions and hardware acceleration of inter-visibility computation. This operational tool allows the evaluation of complex surveillance systems prior installation thanks to a precise simulation of their spatial coverage.
4425345
What are customers looking at?###Computer vision approaches for retail applications can provide value far beyond the common domain of loss prevention. Gaining insight into the movement and behaviors of shoppers is of high interest for marketing, merchandizing, store operations and data mining. Of particular interest is the process of purchase decision making. What catches a customers attention? What products go unnoticed? What does a customer look at before making a final decision? Towards this goal we presents a system that detects and tracks both the location and gaze of shoppers in retail environments. While networks of standard overhead store cameras are used for tracking the location of customers, small in-shelf cameras are used for estimating customer gaze. The presented system operates robustly in real-time and can be deployed in a variety of retail applications.
4425344
Dense disparity estimation from omnidirectional images###This paper addresses the problem of dense estimation of disparities between omnidirectional images, in a spherical framework. Omnidirectional imaging certainly represents important advantages for the representation and processing of the plenoptic function in 3D scenes for applications in localization, or depth estimation for example. In this context, we propose to perform disparity estimation directly in a spherical framework, in order to avoid discrepancies due to inexact projections of omnidirectional images onto planes. We first perform rectification of the omnidirectional images in the spherical domain. Then we develop a global energy minimization algorithm based on the graph-cut algorithm, in order to perform disparity estimation on the sphere. Experimental results show that the proposed algorithm outperforms typical methods as the ones based on block matching, for both a simple synthetic scene, and complex natural scenes. The proposed method shows promising performances for dense disparity estimation and can be extended efficiently to networks of several camera sensors.
4425347
Detecting shopper groups in video sequences###We present a generalized extensible framework for automated recognition of swarming activities in video sequences. The trajectory of each individual is produced by the visual tracking sub-system and is further analyzed to detect certain types of high-level grouping behavior. We utilize recent findings in swarming behavior analysis to formulate a problem in terms of the specific distance function that we subsequently apply as part of the two-stage agglomerative clustering method to create a set of swarming events followed by a set of swarming activities. In this paper we present results for one particular type of swarming: shopper grouping. As part of this work the events detected in a relatively short time interval are further integrated into activities, the manifestation of prolonged high-level swarming behavior. The results demonstrate the ability of our method to detect such activities in congested surveillance videos. In particular in three hours of indoor retail store video, our method has correctly identified over85% of valid '"shopper-groups'" with a very low level of false positives, validated against human coded ground truth.
4425346
Video verification of point of sale transactions###Loss prevention is a significant challenge in retail enterprises. A significant percentage of this loss occurs at point of sale (POS) terminals. POS data mining tools known collectively as exception based reporting (EBR) are helping retailers, but they have limitations as they can only work statistically on trends and anomalies in digital POS data. By applying video analytics techniques to POS transactions, it is possible to detect fraudulent or anomalous activity at the level of individual transactions. Very specific fraudulent behaviors that cannot be detected via POS data alone become clear when combined with video-derived data. ObjectVideo, a provider of intelligent video software, has produced a system called RetailWatch that combines POS information with video data to create a unique loss prevention tool. This paper describes the system architecture, algorithmic approach, and capabilities of the system, together with a customer case-study illustrating the results and effectiveness of the system.
4425349
Automatic people detection and counting for athletic videos classification###We propose a general framework that focuses on automatic individual/multiple people motion-shape analysis and on suitable features extraction that can be used on action/activity recognition problems under real, dynamical and unconstrained environments. We have considered various athletic videos from a single uncalibrated, possibly moving camera in order to evaluate the robustness of the proposed method. We have used an easily expanded hierarchical scheme in order to classify them to videos of individual and team sports. Robust, adaptive and independent from the camera motion, the proposed features are combined within Transferable Belief Model (TBM) framework providing a two level (frames and shot) video categorization. The experimental results of 97% individual/team sport categorization accuracy, using a dataset of more than 250 videos of athletic meetings indicate the good performance of the proposed scheme.
4425348
Video analytics for retail###We describe a set of tools for retail analytics based on a combination of video understanding and transaction-log. Tools are provided for loss prevention (returns fraud and cashier fraud), store operations (customer counting) and merchandising (display effectiveness). Results are presented on returns fraud and customer counting.
4425279
Verbal aggression detection in complex social environments###The paper presents a knowledge-based system designed to detect evidence of aggression by means of audio analysis. The detection is based on the way sounds are analyzed and how they attract attention in the human auditory system. The performance achieved is comparable to human performance in complex social environments. The SIgard system has been deployed in a number of different real-life situations and was tested extensively in the inner city of Groningen. Experienced police observers have annotated ~1400 recordings with various degrees of shouting, which were used for optimization. All essential events and a small number of nonessential aggressive events were detected. The system produces only a few false alarms (non-shouts) per microphone per year and misses no incidents. This makes it the first successful detection system for a non-trivial target in an unconstrained environment.
4425275
Technology, applications and innovations in physical security - A home office perspective###Summary form only given. This overview talk will first introduce the Home Office Scientific Development Branch (HOSDB) as organisation and then will offer a summary of our programmes in the area of the physical security sector. The talk will explain how HOSDB is contributing to protection and law enforcement. I will use a series of examples to cover this area. In the second part, the talk shall focus on vision based systems and on HOSDB initiatives on this technology. I will provide a strategic view of initiatives aimed to cause innovation in the industry and academic research. I will then cover our initiatives in bench marking and in video evidence analysis. Finally, I will provide an overview of future technology trends from the HOSDB perspective.
4425277
Detecting hidden objects: Security imaging using millimetre-waves and terahertz###There has been intense interest in the use of millimetre wave and terahertz technology for the detection of concealed weapons, explosives and other threats. Radiation at these frequencies is safe, penetrates barriers and has short enough wavelengths to allow discrimination between objects. In addition, many solids including explosives have characteristic spectroscopic signatures at terahertz wavelengths which can be used to identify them. This paper reviews the progress which has been made in recent years and identifies the achievements, challenges and prospects for these technologies in checkpoint people screening, stand off detection of improvised explosive devices (<i>lEDs</i>) and suicide bombers as well as more specialized screening tasks.
4425276
Directions in automatic video analysis evaluations at NIST###NIST has been conducting a series of evaluations in the automatic analysis of information in video since 2001. These began within the NIST text retrieval evaluation (TREC) as a pilot track in searching for information in large collections of video. The evaluation series was spun off into its own evaluation/workshop series called TRECVID. TRECVID continues to examine the challenge of extracting features for search technologies. In 2004, NIST also began an evaluation series dedicated to assessing video object detection and tracking technologies using training and test sets that were significantly larger than those used in the past -facilitating novel machine learning approaches and supporting statistically-informative evaluation results. Eventually this effort was merged with other video processing evaluations being implemented in Europe under the classification of events, activities, and relationships (CLEAR) consortium. NIST's goal is to evolve these evaluations of video processing technologies towards a focus on the detection of visually observable events and 3D modeling and to help the computer vision community make strides in the areas of accuracy, robustness, and efficiency.
4425358
A profile of MPEG-7 for visual surveillance###This paper builds on previous work to propose a meta-data standard for video surveillance. The motivation is to promote interoperability. The starting point is the set of requirements under consideration for a Multimedia Application Format. These requirements cover a description of the surveillance system and of the activity in the scene. In addition to this set, appropriate descriptions for the relation between camera and scene are also considered. To improve interoperability between systems and between components of a system, two types of restrictions are proposed. The first proposal is a restricted subset of the MPEG-7 elements that are applicable to the surveillance domain. The second proposal is to use the MPEG-7 tools to include domain-specific taxonomies to restrict the names of elements used in the semantic descriptions. Both proposals are incorporated into examples which demonstrate the use of the standard.
4425359
Resolution limits of closely spaced random signals given the desired success rate###Fundamental limitations on estimation accuracy are well known and include a variety of lower bounds including the celebrated Cramer Rao Lower Bound. However, similar theoretical limitations on resolution have not yet been presented. We exploit results from detection theory for deriving fundamental limitations on resolution. In this paper we discuss the resolution of two zero mean complex random Gaussian signals with a general and predefined covariance matrix observed with additive white Gaussian noise. The results are not based on any specific resolution technique and thus hold for any method and any resolution success rate. The theoretical limit is a simple expression of the observation interval, the user's pre-specified resolution success rate and the second derivative of the covariance matrix. We apply the results to the bearing resolution of two emitters with closely spaced direction of arrival impinging on an array of sensors. The derived limits are verified experimentally by model order selection methods such as the Akaike Information Criterion and the Minimum Description Length.
4425297
Combination of self-organization map and kernel mutual subspace method for video surveillance###This paper addresses the video surveillance issue of automatically identifying moving vehicles and people from continuous observation of image sequences. With a single far-field surveillance camera, moving objects are first segmented by simple background subtraction. To reduce the redundancy and select the representative prototypes from input video streams, the self-organizing feature map (SOM) is applied for both training and testing sequences. The recognition scheme is designed based on the recently proposed kernel mutual subspace (KMS) model. As an alternative to some probability-based models, KMS does not make assumptions about the data sampling processing and offers an efficient and robust classifier. Experiments demonstrated a highly accurate recognition result, showing the model's applicability in real-world surveillance system.
4425296
Improved one-class SVM classifier for sounds classification###This paper proposes to apply optimized one-class support vector machines (1-SVMs) as a discriminative framework in order to address a specific audio classification problem. First, since SVM-based classifier with gaussian RBF kernel is sensitive to the kernel width, the width will be scaled in a distribution-dependent way permitting to avoid under-fitting and over-fitting problems. Moreover, an advanced dissimilarity measure will be introduced. We illustrate the performance of these methods on an audio database containing environmental sounds that may be of great importance for surveillance and security applications. The experiments conducted on a multi-class problem show that by choosing adequately the SVM parameters, we can efficiently address a sounds classification problem characterized by complex real-world datasets.
4425295
An audio-visual sensor fusion approach for feature based vehicle identification###In this article we present our software framework for embedded online data fusion, called I-SENSE. We discuss the fusion model and the decision modeling approach using support vector machines. Due to the system complexity and the genetic approach a data oriented model is introduced. The main focus of the article is targeted at our techniques for extracting features of acoustic-and visual-data. Experimental results of our "traffic surveillance" case study demonstrate the feasibility of our multi-level data fusion approach.
4425294
Experiments with patch-based object classification###We present and experiment with a patch-based algorithm for the purpose of object classification in video surveillance. A feature vector is calculated based on template matching of a large set of image patches, within detected regions-of-interest (ROIs, also called blobs), of moving objects. Instead of matching direct image pixels, we use Gabor-filtered versions of the input image at several scales. We present results for a new typical video surveillance dataset containing over 9,000 object images. Additionally, we show results for the PETS 2001 dataset and another dataset from literature. Because our algorithm is not invariant to the object orientation, the set was split into four subsets with different orientation. We show the improvements, resulting from taking the object orientation into account. Using 50 training samples or higher, our resulting detection rate is on the average above 95%, which improves with the orientation consideration to 98%. Because of the inherent scalability of the algorithm, an embedded system implementation is well within reach.
4425293
A particle filter based fusion framework for video-radio tracking in smart spaces###One of the main issues for Ambient Intelligence (AmI) systems is to continuously localize the user and to detect his/her identity in order to provide dedicated services. A video-radio fusion methodology, relying on the Particle Filter algorithm, is here proposed to track objects in a complex extensive environment, exploiting the complementary benefits provided by both systems. Visual tracking commonly outperforms radio localization in terms of precision but it is inefficient because of occlusions and illumination changes. Instead, radio measurements, gathered by a user's radio device, are unambiguously associated to the respective target through the "virtual" identity (i.e. MAC/IP addresses). The joint usage of the two data typologies allows a more robust tracking and a major flexibility in the architectural setting up of the AmI system. The method has been extensively tested in a simulated and off-line framework and on real world data proving its effectiveness.
4425292
Bottom-up/top-down coordination in a multiagent visual sensor network###In this paper an approach for multi-sensor coordination in a multiagent visual sensor network is presented. A belief-desire-intention model of multiagent systems is employed. In this multiagent system, the interactions between several surveillance-sensor agents and their respective fusion agent are discussed. The surveillance process is improved using a bottom-up/top-down coordination approach, in which a fusion agent controls the coordination process. In the bottom-up phase the information is sent to the fusion agent. On the other hand, in the top-down stage, feedback messages are sent to those surveillance-sensor agents that are performing an inconsistency tracking process with regard to the global fused tracking process. This feedback information allows to the surveillance-sensor agent to correct its tracking process. Finally, preliminary experiments with the PETS 2006 database are presented.
4425291
Distributed video surveillance using hardware-friendly sparse large margin classifiers###In contrast to video sensors which just "watch " the world, present-day research is aimed at developing intelligent devices able to interpret it locally. A number of such devices are available on the market, very powerful on the one hand, but requiring either connection to the power grid, or massive rechargeable batteries on the other. MicrelEye, the wireless video sensor node presented in this paper, targets a different design point: portability and a scanty power budget, while still providing a prominent level of intelligence, namely objects classification. To deal with such a challenging task, we propose and implement a new SVM-like hardware-oriented algorithm called ERSVM. The case study considered in this work is people detection. The obtained results suggest that the present technology allows for the design of simple intelligent video nodes capable of performing local classification tasks.
4425290
Camera selection in visual sensor networks###Wireless networks of visual sensors have recently emerged as a new type of sensor-based intelligent system, with performance and complexity challenges that go beyond that of existing wireless sensor networks. The goal of the visual sensor network we examine is to provide a user with visual information from any arbitrary viewpoint within the monitored field. This can be accomplished by synthesizing image data from a selection of cameras whose fields of view overlap with the desired field of view. In this work, we compare two methods for the selection of the camera-nodes. The first method selects cameras that minimize the difference between the images provided by the selected cameras and the image that would be captured by a real camera from the desired viewpoint. The second method considers the energy limitations of the battery powered camera-nodes, as well as their importance in the 3D coverage preservation task. Simulations using both metrics for camera-node selection show a clear trade-off between the quality of the reconstructed image and the network's ability to provide full coverage of the monitored 3D space for a longer period of time.
4425356
Towards robust face recognition for Intelligent-CCTV based surveillance using one gallery image###In recent years, the use of Intelligent Closed-Circuit Television (ICCTV) for crime prevention and detection has attracted significant attention. Existing face recognition systems require passport-quality photos to achieve good performance. However, use of CCTV images is much more problematic due to large variations in illumination, facial expressions and pose angle. In this paper we propose a pose variability compensation technique, which synthesizes realistic frontal face images from non-frontal views. It is based on modelling the face via Active Appearance Models and detecting the pose through a correlation model. The proposed technique is coupled with adaptive principal component analysis (APCA), which was previously shown to perform well in the presence of both lighting and expression variations. Experiments on the FERET dataset show up to 6 fold performance improvements. Finally, in addition to implementation and scalability challenges, we discuss issues related to on-going real life trials in public spaces using existing surveillance hardware.
4425357
ETISEO, performance evaluation for video surveillance systems###This paper presents the results of ETISEO, a performance evaluation project for video surveillance systems. Many other projects have already evaluated the performance of video surveillance systems, but more on an end-user point of view. ETISEO aims at studying the dependency between algorithms and the video characteristics. Firstly we describe ETISEO methodology which consists in addressing each video processing problem separately. Secondly, we present the main evaluation metrics of ETISEO as well as their benefits, limitations and conditions of use. Finally, we discuss about the contributions of ETISEO to the evaluation community.
4425354
Face recognition using non-linear image reconstruction###We present a face recognition technique based on a special type of convolutional neural network that is trained to extract characteristic features from face images and reconstruct the corresponding reference face images which are chosen beforehand for each individual to recognize. The reconstruction is realized by a so-called "bottle-neck" neural network that learns to project face images into a low-dimensional vector space and to reconstruct the respective reference images from the projected vectors. In contrast to methods based on the Principal Component Analysis (PCA), the Linear Discriminant Analysis (LDA) etc., the projection is non-linear and depends on the choice of the reference images. Moreover, local and global processing are closely interconnected and the respective parameters are conjointly learnt. Having trained the neural network, new face images can then be classified by comparing the respective projected vectors. We experimentally show that the choice of the reference images influences the final recognition performance and that this method outperforms linear projection methods in terms of precision and robustness.
4425355
Recognition through constructing the Eigenface classifiers using conjugation indices###The principal component analysis (PCA), also called the eigenfaces analysis, is one of the most extensively used face image recognition techniques. The idea of the method is decomposition of image vectors into a system of eigenvectors matched to the maximum eigenvalues. The method of proximity assessment of vectors composed of principal components essentially influences the recognition quality. In the paper the use of different indices of conjugation with subspace stretched on training vectors is considered as a proximity measure. It is shown that this approach is very effective in the case of a small number of training examples. The results of experiments for a standard ORL-face database are presented.
4425352
Recovering the linguistic components of the manual signs in American Sign Language###Manual signs in American sign language (ASL) are constructed using three building blocks -handshape, motion, and place of articulations. Only when these three are successfully estimated, can a sign by uniquely identified. Hence, the use of pattern recognition techniques that use only a subset of these is inappropriate. To achieve accurate classifications, the motion, the handshape and their three-dimensional position need to be recovered. In this paper, we define an algorithm to determine these three components form a single video sequence of two-dimensional pictures of a sign. We demonstrated the use of our algorithm in describing and recognizing a set of manual signs in ASL.
4425353
Model-based human posture estimation for gesture analysis in an opportunistic fusion smart camera network###In multi-camera networks rich visual data is provided both spatially and temporally. In this paper a method of human posture estimation is described incorporating the concept of an opportunistic fusion framework aiming to employ manifold sources of visual information across space, time, and feature levels. One motivation for the proposed method is to reduce raw visual data in a single camera to elliptical parameterized segments for efficient communication between cameras. A 3D human body model is employed as the convergence point of spatiotemporal and feature fusion. It maintains both geometric parameters of the human posture and the adoptively learned appearance attributes, all of which are updated from the three dimensions of space, time and features of the opportunistic fusion. In sufficient confidence levels parameters of the 3D human body model are again used as feedback to aid subsequent in-node vision analysis. Color distribution registered in the model is used to initialize segmentation. Perceptually Organized Expectation Maximization (POEM) is then applied to refine color segments with observations from a single camera. Geometric configuration of the 3D skeleton is estimated by Particle Swarm Optimization (PSO).
4425299
Camera auto-calibration from articulated motion###This paper presents a novel auto-calibration method from unconstrained human body motion. It relies on the underlying biomechanical constraints associated with human bipedal locomotion. By analysing positions of key points during a sequence, our technique is able to detect frames where the human body adopts a particular posture which ensures the coplanarity of those key points and therefore allows a successful camera calibration. Our technique includes a 3D model adaptation phase which removes the requirement for a precise geometrical 3D description of those points. Our method is validated using a variety of human bipedal motions and camera configurations.
4425298
Accurate self-calibration of two cameras by observations of a moving person on a ground plane###A calibration algorithm of two cameras using observations of a moving person is presented. Similar methods have been proposed for self-calibration with a single camera, but internal parameter estimation is only limited to the focal length. Recently it has been demonstrated that principal point supposed in the center of the image causes inaccuracy of all estimated parameters. Our method exploits two cameras, using image points of head and foot locations of a moving person, to determine for both cameras the focal length and the principal point. Moreover with the increasing number of cameras there is a demand of procedures to determine their relative placements. In this paper we also describe a method to find the relative position and orientation of two cameras: the rotation matrix and the translation vector which describe the rigid motion between the coordinate frames fixed in two cameras. Results in synthetic and real scenes are presented to evaluate the performance of the proposed method.
4425350
Sign language detection using 3D visual cues###A 3D visual hand gesture recognition method is proposed that detects correctly performed signs from stereo camera input. Hand tracking is based on skin detection with an adaptive chrominance model to get high accuracy. Informative high level motion properties are extracted to simplify the classification task. Each example is mapped onto a fixed reference sign by Dynamic Time Warping, to get precise time correspondences. The classification is done by combining weak classifiers based on robust statistics. Each base classifier assumes a uniform distribution of a single feature, determined by winsorization on the noisy training set. The operating point of the classifier is determined by stretching the uniform distributions of the base classifiers instead of changing the threshold on the total posterior likelihood. In a cross validation with 120 signs performed by 70 different persons, 95% of the test signs were correctly detected at a false positive rate of 5%.
4425351
Human body gesture recognition using adapted auxiliary particle filtering###In this paper we propose a tracking scheme specifically tailored for tracking human body parts in cluttered scenes. We model the background and the human skin using Gaussian mixture models and we combine these estimates to localize the features to be tracked. We further use these estimates to determine the pixels which belong to the background and those which belong to the subject's skin and we incorporate this information in the observation model of the used tracking scheme. For handling self-occlusion (i.e., when one body part occludes another), we incorporate the information about the direction of the observed motion into the propagation model of the used tracking scheme. We demonstrate that the proposed method outperforms the conventional condensation and auxiliary particle filtering when the hands and the head are the tracked body features. For the purposes of human body gesture recognition, we use a variant of the longest common subsequence algorithm (LCSS) in order to acquire a distance measure between the acquired trajectories and we use this measure in order to define new kernels for a relevance vector machine (RVM) classification scheme. We present results on real image sequences from a small database depicting people performing 15 aerobic exercises.
4425284
Automated 3D Face authentication &#x00026; recognition###This paper presents a fully automated 3D face authentication (verification) and recognition (identification) method and recent results from our work in this area. The major contributions of our paper are: (a) the method can handle data with different facial expressions including hair, upper body, clothing, etc. and (b) development of weighted features for discrimination. The input to our system is a triangular mesh and it outputs a matching % against a gallery. Our method includes both surface and curve based features that are automatically extracted from a given face data. The test set for authentication consisted of 117 different people with 421 scans including different facial expressions. Our study shows equal error rate (EER) at 0.065% for normal faces and 1.13% in faces with expressions. We report verification rates of 100% in normal faces and 93.12% in faces with expressions at 0.1% FAR. For identification, our experiment shows 100% rate in normal faces and 95.6% in faces with expressions. From our experiment we conclude that combining feature points, profile curve, and partial face surface matching gives better authentication and recognition rate than any single matching method.
4425285
2D face pose normalisation using a 3D morphable model###The ever growing need for improved security, surveillance and identity protection, calls for the creation of evermore reliable and robust face recognition technology that is scalable and can be deployed in all kinds of environments without compromising its effectiveness. In this paper we study the impact that pose correction has on the performance of 2D face recognition. To measure the effect, we use a state of the art 2D recognition algorithm. The pose correction is performed by means of 3D morphable model. Our results on the non frontal XM2VTS database showed that pose correction can improve recognition rates up to 30%.
4425286
View adaptive detection and distributed site wide tracking###Using a detect and track paradigm, we present a surveillance framework where each camera uses local resources to perform real-time person detection. These detections are then processed by a distributed site-wide tracking system. The detectors themselves are based on boosted user-defined exemplars, which capture both appearance and shape information. The detectors take integral images of both intensity and Sobel responses as input. This data representation enables efficient processing without relying on background subtraction or other motion cues. View-specific person detectors are constructed by iteratively presenting the boosting algorithm with training data associated with each individual camera. These detections are then transmitted from a distributed set of tracking clients to a server, which maintains a set of site-wide target tracks. Automatic calibration methods allow for tracking to be performed in a ground plane representation, which enables effective camera hand-off. Factors such as network latencies and scalability will be discussed.
4425287
The Intelligent vision sensor: Turning video into information###Video analytics for security and surveillance applications is becoming commonplace. Advances in algorithm robustness and low-cost video platforms have allowed analytics to become an ingredient for many different devices ranging from cameras to encoders to routers to storage. As algorithms become more refined, the analytics paradigm shifts from a human-support model to an automation model. In this context, ObjectVideo, the leader in intelligent video, has created a new concept in video analytics devices - the intelligent vision sensor (IVS). This device consists of a video imager and lens combined with an onboard processor and communication channel. This low-cost device turns video imagery into actionable information that can be used in building automation and business intelligence applications. This paper describes the technical and market drivers that facilitate the creation and adoption of the IVS device as well as a specific case study involving an application for heating, ventilation, and air conditioning (HVAC) and lighting control.
4425280
Scream and gunshot detection and localization for audio-surveillance systems###This paper describes an audio-based video surveillance system which automatically detects anomalous audio events in a public square, such as screams or gunshots, and localizes the position of the acoustic source, in such a way that a video-camera is steered consequently. The system employs two parallel GMM classifiers for discriminating screams from noise and gunshots from noise, respectively. Each classifier is trained using different features, chosen from a set of both conventional and innovative audio features. The location of the acoustic source which has produced the sound event is estimated by computing the time difference of arrivals of the signal at a microphone array and using linear-correction least square localization algorithm. Experimental results show that our system can detect events with a precision of 93% at a false rejection rate of 5% when the SNR is 10dB, while the source direction can be estimated with a precision of one degree. A real-time implementation of the system is going to be installed in a public square of Milan.
4425281
Acoustic Doppler sonar for gait recogination###A person's gait is a characteristic that might be employed to identify him/her automatically. Conventionally, automatic for gait-based identification of subjects employ video and image processing to characterize gait. In this paper we present an Acoustic Doppler Sensor(ADS) based technique for the characterization of gait. The ADS is very inexpensive sensor that can be built using off-the-shelf components, for under $20 USD at today's prices. We show that remarkably good gait recognition is possible with the ADS sensor.
4425282
Compression for 3D face recognition applications###This paper proposes a novel 3D lossy compression algorithm tailored for 3D faces. We analyse the effects of compression on the face verification rate and measure recognition performances on the face recognition grand challenge database. Whilst preserving the spatial resolution enabling reconstruction of surface details, the proposed scheme achieves substantial compression to the extent that personal 3D biometric data could fit on a 2D barcode.
4425283
Towards fast 3D ear recognition for real-life biometric applications###Three-dimensional data are increasingly being used for biometric purposes as they offer resilience to problems common in two-dimensional data. They have been successfully applied to face recognition and more recently to ear recognition. However, real-life biometric applications require algorithms that are both robust and efficient so that they scale well with the size of the databases. A novel ear recognition method is presented that uses a generic annotated ear model to register and fit each ear dataset. Then a compact biometric signature is extracted that retains 3D information. The proposed method is evaluated using the largest publicly available 3D ear database appended with our own database, resulting in a database containing data from multiple 3D sensor types. Using this database it is shown that the proposed method is not only robust, accurate and sensor invariant but also extremely efficient, thus making it suitable for real-life biometric applications.
4425323
Real-time tracking and identification on an intelligent IR-based surveillance system###We implement a fixed-point real-time identification system and provide tools for the optimal design of exponential lookup-tables. This intelligent surveillance system is based on infrared image processing, which allows to detect and track people and trigger different actions depending on the region of the monitored area in which they are. The system automatically segments the body to get the face and includes a face classifier based on the support vector machine.
4425322
Detection of abandoned objects in crowded environments###With concerns about terrorism and global security on the rise, it has become vital to have in place efficient threat detection systems that can detect and recognize potentially dangerous situations, and alert the authorities to take appropriate action. Of particular significance is the case of unattended objects in mass transit areas. This paper describes a general framework that recognizes the event of someone leaving a piece of baggage unattended in forbidden areas. Our approach involves the recognition of four sub-events that characterize the activity of interest. When an unaccompanied bag is detected, the system analyzes its history to determine its most likely owner(s), where the owner is defined as the person who brought the bag into the scene before leaving it unattended. Through subsequent frames, the system keeps a lookout for the owner, whose presence in or disappearance from the scene defines the status of the bag, and decides the appropriate course of action. The system was successfully tested on the i-LIDS dataset.
4425321
Real time detection of stopped vehicles in traffic scenes###Computer vision techniques are widely employed in Traffic Monitoring Systems (TMS) to automatically derive statistical information on traffic flow and trigger alarms on significant events. Research in this field embraces a wide range of methods developed to recognize moving objects and to infer their behavior. Tracking systems are used to reconstruct trajectories of moving objects detected often by using background difference approaches. Errors in either motion detection or tracking can perturb the position of the object centroids used to build the trajectories. To cope with the unavoidable errors, we have conceived a method to detect centers of non-motion through recognizing short stability intervals. These are further connected to build the long stability interval used to measure the overall vehicle stopping time. Extensive experiments also accomplished on the sequences provided by AVSS 2007 prove the effectiveness of our approach to measure the maximum stopped delay, even through a comparison with the ground truth.
4425320
A DSP-based system for the detection of vehicles parked in prohibited areas###In this paper, a system for automatic robust video surveillance is described and in particular its application to the problem of locating vehicles that stop in prohibited area is discussed. The structure of software for video processing (alarm generation, interface with the operator and information storage) is outlined together with the hardware (Trimedia DSP boards and industrial computers) which constitutes an industrial-grade product. The emphasis on this paper is to demonstrate robust detection and hence we show the results of a performance evaluation process carried out with the UK's i-LIDS "Parked Vehicle " reference dataset.
4425327
Real time face recognition using decision fusion of neural classifiers in the visible and thermal infrared spectrum###This paper is dedicated to multispectral facial image recognition, using decision fusion of neural classifiers. The novelty of this paper is that any classifier is based on the model of Concurrent Self-Organizing Maps (CSOM), previously proposed by first author of this paper. Our main achievement is the implementation of a real time CSOM face recognition system using the decision fusion that combines the recognition scores generated from visual channels {(R, G, and B) or Y} with a thermal infrared classifier. As a source of color and infrared images, we used our VICFACE database of 38 subjects. Any picture has 160 times 120 pixels; for each subject there are pictures corresponding to various face expressions and illuminations, in the visual and infrared spectrum. The spectral sensitivity of infrared images corresponds to the long wave range of 7.5 - 13 mum. The very good experimental results are given regarding recognition score.
4425326
Enhancing the spatial resolution of presence detection in a PIR based wireless surveillance network###Pyroelectric sensors are low-cost, low-power small components commonly used only to trigger alarm in presence of humans or moving objects. However, the use of an array of pyroelectric sensors can lead to extraction of more features such as direction of movements, speed, number of people and other characteristics. In this work a low-cost pyroelectric infrared sensor based wireless network is set up to be used for tracking people motion. A novel technique is proposed to distinguish the direction of movement and the number of people passing. The approach has low computational requirements, therefore it is well-suited to limited-resources devices such as wireless nodes. Tests performed gave promising results.
4425325
Image enhancement in multi-resolution multi-sensor fusion###In multi-sensor image fusion, multi-resolution approaches became popular because they can preserve detailed information well. Among them, the gradient-based multi-resolution (GBMR) algorithm is known to effectively reduce ringing artifacts near edges compared with the discrete wavelet transform (DWT)-based algorithm. However, since the GBMR algorithm does not consider the diagonal direction, the ringing artifacts reduction is not satisfactory at diagonal edges. In this paper, we generalize the GBMR algorithm by adopting the wavelet structure. Thereby, the proposed algorithm improves the fusion process in high-frequency sub-bands so as to preserve details of input images. Meanwhile, the algorithm fuses the low-frequency sub-band by considering the overall contrast in the output image. To evaluate the proposed algorithm, we compare it with the DWT-based and GBMR algorithms. Experimental results clearly demonstrate that the proposed algorithm effectively reduces ringing artifacts for edges of all directions and greatly enhances the overall contrast while minimizing visual information loss.
4425324
Infrared image processing and its application to forest fire surveillance###This paper describes an scheme for automatic forest surveillance. A complete system for forest fire detection is firstly presented although we focus on infrared image processing. The proposed scheme based on infrared image processing performs early detection of any fire threat. With the aim of determining the presence or absence of fire, the proposed algorithms performs the fusion of different detectors which exploit different expected characteristics of a real fire, like persistence and increase. Theoretical results and practical simulations are presented to corroborate the control of the system related with probability of false alarm (PFA). Probability of detection (PD) dependence on signal to noise ration (SNR) is also evaluated.
4020724
Supplementing Markov Chains with Additional Features for Behavioural Analysis###The combination of decision structures has been proposed by numerous researchers in the behavioural analysis domain, and been shown to improve accuracy over network structures tested in isolation; however, the vast majority of researchers use a simplistic combination strategy, amounting to little more than bridging of the network structures. This paper introduces a fusion mechanism between Bayesian and Markovian networks, which provides the Markov states with additional low-level features. This hybrid approach affords users a simplified network structure and provides the basis for an automatic technique, which allows the transitional probabilities in the network to be learned during online running of the system without the need for a training phase. The hybrid technique is validated using two very different datasets and is shown to outperform a standard network approach tested.
4020725
An Efficient Video Enhancement Method Using LA*B* Analysis###In this paper, an efficient technique is proposed for real-time enhancement of video containing inconsistent and complex conditions like nonuniform and insufficient lighting. Beyond providing digital tools for video enhancement, this method provides a better approach to enhance a video in low lighting conditions without any loss of color information. This approach is based on histogram manipulations on La*b* color model of the video frame. This algorithm provides an effective way for video enhancement with simple computational procedures, which makes real-time enhancement for homeland security application successfully realized. Simulation is done on videos taken under bad lighting conditions and results are presented.
4020726
Color-Based Signal Light Tracking in Real-Time Video###Tracking or detecting the position and color of signal lights has an important role in transport industry. Auto detection of signal light colors and their position using computer vision techniques provides or acts as a proof against a fraudulent claim losses. The current technology, such as vehicle mounted recording system, provides event recognition videos and the cause behind an accident. But it does not provide the complete information about color associated with signal lights. The detection of the color of a signal light under different illuminations is a critical issue. In this research, an intelligent method for tracking color of signal lights using La*b* color model combined with contour tracking is proposed. This research finds application in transportation, law enforcement and insurance claims. The system increases the efficiency of the accident investigation process and reduces the economic loss associated with automobile accidents of all types.
4020727
The Application of RFID Technology in Production Control in the Discrete Manufacturing Industry###RFID (Radio Frequency Identification), a technology existing for years, has potential uses in a variety of applications. Though not without issues and challenges, RFID is a promising technology which analysts expect to become ubiquitous in the coming years, helping organizations solve problems in supply chain management, security, personal identification, and asset tracking. The purpose of this paper is to applying RFID technology in production control in a discrete manufacturing system, which needs control the production process in real time in order to improve the management level of production efficiency and quality. In particular, we build a RAMS (RFID Activity Monitor System), for sanitary ware manufacturing, which is connected to the existing ERP System by database so as to satisfy real time control requirement.
4020720
A Novel Statistical Model for Speech Recognition and POS Tagging###Hidden Markov model is a statistical model which has been applied successfully to speech recognition and natural language processing. However, it is based on three assumptions: (1) limited horizon, (2) time invariant (stationary), (3)the independence assumption of observations within a state. These assumptions are too strong from the view of the statistics and are also unreaistic. In order to overcome the defects of the classical HMM, Markov Family model, a new statistical models is proposed in this paper. The speaker independent continuous speech recognition experiments and the Part-of-Speech tagging experiments show that Markov Family models (MFMs) have higher performance than Hidden Markov models (HMMs).
4020721
Face Detection with High Precision Based on Radial-Symmetry Transform and Eye-Pair Checking###In this paper, a novel face detection algorithm is proposed which can detect both face and eye pupils efficiently at the same time. Interestingly, the results of face detection can be used to identify the regions of interest for pupil detection, and the results of pupil detection can be further contributed to detect more precise faces. A cascaded face filter is first constructed by using an adaboosting algorithm, which can rapidly filter out the non-face regions and keeps the possible face regions. Based on a radial-symmetry transform, the signal of eye pupil in a face candidate is considerably enhanced and becomes easy to detect. With an eye-pair checking process, the two pupil candidates are chosen as the outputted pupils if their corresponding face image obtains the highest verification score which is also larger than a predefined threshold. Experiments on the famous BioID face database have shown that 90.0% of faces can be successfully detected, and among the detected faces about 98% of eye pupils are detected with highly acceptable precision.
4020722
Visual Speech Recognition Method Using Translation, Scale and Rotation Invariant Features###This paper reports on a visual speech recognition method that is invariant to translation, rotation and scale. Dynamic features representing the mouth motion is extracted from the video data by using a motion segmentation technique termed as motion history image (MHI). MHI is generated by applying accumulative image differencing technique on the sequence of mouth images. Invariant features are derived from the MHI using feature extraction algorithm that combines Discrete Stationary Wavelet Transform (SWT) and moments. A 2-D SWT at level one is applied to decompose MHI to produce one approximate and three detail sub images. The feature descriptors consist of three moments (geometric moments, Hu moments and Zernike moments) computed from the SWT approximate image. The moments features are normalized to achieve the invariance properties. Artificial neural network (ANN) with back propagation learning algorithm is used to classify the moments features. Initial experiments were conducted to test the sensitivity of the proposed approach to rotation, translation and scale of the mouth images and obtained promising results.
4020723
Behavior Recognition in Human Object Interactions with a Task Model###Behavior recognition can be greatly levitated by a model of the task with which the behavior is associated. We present a Markovian task model that captures the temporal relations between subtasks, and provides prior information that helps behavior recognition from simple and noisy sensory data. A Dynamic Bayesian Network is used to integrate multi-model evidence and infer underlying task states. Experiments demonstrate that this system can recognize human behavior in everyday tasks such as making sandwiches.
4020759
3-D Virtual Environments on Mobile Devices for Remote Surveillance###In this paper we present a distributed videosurveillance framework. Our end is the remote monitoring of the behavior of people moving in a scene exploiting a virtual reconstruction on low capabilities devices, like PDAs and cell phones. The main novelty of this system is the effective integration of the computer vision and computer graphics modules. The first, using a probabilistic frameworks, can detect the position, the trajectory and the posture of peoples moving in the scene. The second exploits the new possibility of both standard 3D graphics libraries on mobile (namely JSR184 and M3G graphic format) and new PDAs processing capability in order to reconstruct the remote surveillance data in real-time.
4020728
Visual Recognition of Manual Tasks Using Object Motion Trajectories###Motion trajectories are powerful cues for event detection and recognition. In this paper we present a system for manual task analysis that distinguishes between skin and object motion and learns activity patterns through analysing object trajectories. It is particularly suited to the recognition of common object handling tasks. Our vision system performs hand skin detection and object segmentation for each frame in a sequence. The object trajectories are then modelled as motion time series. We have compared the performance of several different time series indexing schemes: symbolic, polynomial and orthonormal basis functions used for trajectory similarity retrieval and classification. We then attempt to cluster objectcentred motion patterns in the coefficient feature space. The proposed technique is validated on two different datasets, Australian Sign Language and object handling data obtained in the laboratory. Applications to task recognition and motion data mining in industrial surveillance applications are envisaged.
4020729
Pedestrian Detection and Tracking for Counting Applications in Crowded Situations###This paper describes a vision based pedestrian detection and tracking system which is able to count people in very crowded situations like escalator entrances in underground stations. The proposed system uses motion to compute regions of interest and prediction of movements, extracts shape information from the video frames to detect individuals, and applies texture features to recognize people. A search strategy creates trajectories and new pedestrian hypotheses and then filters and combines those into accurate counting events. We show that counting accuracies up to 98 % can be achieved.
4020758
Dynamic Scene Reconstruction for Efficient Remote Surveillance###In this paper a system is presented able to reproduce the actions of multiple moving objects into a 3D model. A multi-camera surveillance system is used for automatically detect, track and classify the objects. Data fusion from multiple sensors allows to get a more precise estimation of the position of detected moving objects and to solve occlusions problem. These data are then used to automatically place and animate objects avatars in a 3D virtual model of the scene, thus allowing a human operator to remotely visualize the dynamic 3D reconstruction by selecting a arbitrary point of view.
4020711
Near- and Far- Infrared Imaging for Vein Pattern Biometrics###This paper investigates two infrared imaging technologies, far-infrared thermography and near-infrared imaging, to acquire hand vein pattern images for biometric purposes. The imaging principles for both technologies are studied in depth. Experiments involving data acquisition from various parts of hand, including the back of the hand, palm, and wrist are described using a population of 150 participants using both near and far infrared imaging techniques. Comparison and analysis of the data collected show that far-infrared thermography has difficulties in capturing vein images in the palm, and wrist. However, while it is more suitable for capturing the large veins in the back of the hand, it is sensitive to ambient conditions and human body condition and does not provide a stable image quality. On the other hand, near-infrared imaging produces good quality images when capturing vein patterns in the back of the hand, palm, and wrist. It is more tolerant to changes in environmental and body condition, but it also faces the problem of disruption due to skin features such as hairs and line patterns. An initial vein pattern biometric system is implemented. The results show that all the test subjects can be correctly identified.
4020710
An Optical System for Guidance of Terrain Following in UAVs###There is considerable interest in designing guidance systems for UAVs that use passive sensing (such as vision), rather than active sensing which can be bulky, expensive and stealth-compromising. Here we describe an optical sensor, based partly on principles of insect vision and optic flow analysis, for measurement and control of height above the ground. A video camera is used in conjunction with a specially shaped reflective surface to simplify the computation of optic flow, and extend the range of aircraft speeds over which accurate data can be obtained. The imaging system also provides a useful geometrical remapping of the environment, which facilitates obstacle avoidance and computation of 3-D terrain maps.
4020713
A Smith-Waterman Local Alignment Approach for Spatial Activity Recognition###In this paper we address the spatial activity recognition problem with an algorithm based on Smith-Waterman (SW) local alignment. The proposed SW approach utilises dynamic programming with two dimensional spatial data to quantify sequence similarity. SW is well suited for spatial activity recognition as the approach is robust to noise and can accommodate gaps, resulting from tracking system errors. Unlike other approaches SW is able to locate and quantify activities embedded within extraneous spatial data. Through experimentation with a three class data set, we show that the proposed SW algorithm is capable of recognising accurately and inaccurately segmented spatial sequences. To benchmark the techniques classification performance we compare it to the discrete hidden markov model (HMM). Results show that SW exhibits higher accuracy than the HMM, and also maintains higher classification accuracy with smaller training set sizes. We also confirm the robust property of the SW approach via evaluation with sequences containing artificially introduced noise.
4020712
Measuring Skin Topographic Structures through Capacitance Image Analysis###In dermatology and in cosmetic science, the detailed analysis of the skin surface is still a key requirement to evaluate the effectiveness of medical or cosmetic treatments. Nowadays, the assessment of skin surface topographic structures such as wrinkles or micro-relief 3D profile is mainly obtained by profilometric analysis. Even though such an analysis gives a high level of detail, it is not suitable for in vivo studies since it requires the use of silicone cast replica of the skin. However, in the last few years a portable capacitive device has been proposed for in vivo skin topography characterization. This work presents the method we have developed to assess the capability of the capacitive device to provide reliable absolute measures of the skin surface structures. Extensive experiments carried out by comparing the measures achieved by means of the capacitive device and an optical profilometer allow us to validate our method.
4020715
Skin Colour-Based Face Detection in Colour Images###We propose in this work a method for detecting faces in colour images with complex backgrounds. The approach starts with the transformation of the image pixels from the RGB colour space to the chrominance space (YCbCr). Secondly, a Gaussian model is fitted on the transformed image in order to calculate the likelihood of skin for each pixel and to create a likelihood image. Thirdly, by thresholding the likelihood image, skin pixels are segmented to form a binary skin map, which contains the candidate face regions. Finally, a verification process is carried out to determine whether these candidate face regions are real faces or not.
4020714
Principal Component Analysis of Multi-view Images for Viewpoint-Independent Face Recognition###We consider the problem of recognizing a specific human face in different poses (viewing direction) when only one frontal face image exists in the face database. To solve this problem, prior knowledge is learned by using principal component analysis on a set of multi-view images to obtain aligned principal components. They are used together with the idea of linear object classes to synthesize a virtual view of the frontal face from a given face image taken from a different viewing direction. The estimated virtual frontal view is then compared with the stored frontal face images in the face database to identify the person. Experimental results are shown using face images captured from different viewpoints.
4020717
The Role of Motion Models in Super-Resolving Surveillance Video for Face Recognition###Although the use of super-resolution techniques has demonstrated the ability to improve face recognition accuracy when compared to traditional upsampling techniques, they are difficult to implement for real-time use due to their complexity and high computational demand. As a large portion of processing time is dedicated to registering the lowresolution images, many have adopted global motion models in order to improve efficiency. The drawback of such global models is that they can not accommodate for complex local motions, such as multiple objects moving independently across and static or dynamic background as frequently occurs in a surveillance environment. Local methods like optical flow can compensate for these situations, although it is achieved at the expense of computation time. In this paper, experiments have been carried out to investigate how motion models of different super-resolution reconstruction algorithms affect reconstruction error and face recognition rates in a surveillance environment. Results show that lower reconstruction error doesnt necessarily imply better recognition rates and the use of local motion models yields better recognition rates than global motion models.
4020716
Feature Modelling of PCA Difference Vectors for 2D and 3D Face Recognition###This paper examines the the effectiveness of feature modelling to conduct 2D and 3D face recognition. In particular, PCA difference vectors are modelled using Gaussian Mixture Models (GMMs) which describe Intra-Personal (IP) and Extra-Personal (EP) variations. Two classifiers, an IP and IPEP classifier, are formed using these GMMs and their performance is compared to that of the Mahalanobis cosine metric (MahCosine). The best results for the 2D and 3D face modalities are obtained with the IP and IPEP classifiers respectively. The multi-modal fusion of these two systems provided consistent performance improvement across the FRGC database v2.0.
4020719
Analysis of LIDAR Data Fused with Co-Registered Bands###In the past decade, LIght Detection And Ranging (LIDAR) has been recognised by both the commercial and public sector as a reliable and accurate source for land surveying. Object classification in LIDAR data tends towards data fusion by employing additional simultaneously recorded bands. In this paper, a rule-based approach is presented for improving classification accuracy obtained in a supervised Maximum Likelihood classification. Simultaneously recorded co-registered bands are used such as high resolution LIDAR first, last echo and intensity data, aerial and near infra-red photos. Issues regarding feature and class selection and differentiated accuracy assessment are addressed. Furthermore, the individual influence of each band on the classification is investigated. The results show that incorporating additional knowledge and considering contextual relationships among classes is beneficial for improving classification accuracy in fused LIDAR datasets.
4020718
Human Face Reconstruction Using Bayesian Deformable Models###This paper presents a Bayesian framework for 3D facial reconstruction. The framework iteratively deforms a generic face mesh to fit a set of range points representing a face. The generic mesh is generated from the extensive FRGC database of face images. The deformation process is conducted within a Bayesian framework and is driven by a Markov Chain Monte Carlo (MCMC) sampler which uses information from the likelihood and prior distributions of the generic face mesh. The paper presents results on the construction of a generic face model, the deformation framework and fitting results to both synthetic and real data. The results verify the effectiveness of the proposed technique, accurately deforming a generic face mesh to captured 3D data points of human faces.
4020665
Discovering the Local Co-occurring Patterns in Visual Categorization###We present a novel visual representation, called local co-occurring patterns (LCPs), which consists of characteristic local features and the statistical co-occurance relations between them. The LCPs can be discovered using an associate rule mining algorithm. Experiments show that LCPs widely exist in a large image corpus, and are more discriminant than individual local features in visual categorization tasks such as subcategory and face recognition. Furthermore, state-of-the-art categorization performance was achieved on two test data-sets.
4020664
Dynamic Control of Adaptive Mixture-of-Gaussians Background Model###We propose a method for create a background model in non-stationary scenes. Each pixel has a dynamic Gaussian mixture model. Our approach can automatically change the number of Gaussians in each pixel. The number of Gaussians increases when pixel values often change because of Illumination change, object moving and so on. On the other hand, when pixel values are constant in a while, some Gaussians are eliminated or integrated. This process helps reduce computational time. We conducted experiments to investigate the effectiveness of our approach.
4020667
Recognizing Facial Expressions in Videos Using a Facial Action Analysis-Synthesis Scheme###In this paper, we propose a novel approach for facial expression analysis and recognition. The proposed approach relies on tracked facial actions provided by an appearance-based 3D face tracker. For each universal expression, a dynamical model for facial actions given by an auto-regressive process is learned from training data. We classify a given image in an unseen video into one of the universal facial expression categories using an analysis-synthesis scheme. This scheme uses all models and select the one that provides the most consistent synthesized spatio-temporal facial actions. The dynamical models can be utilized in the tasks of synthesis and prediction. Experiments using unseen videos demonstrated the effectiveness of the developed method.
4020666
Analyzing Human Movements from Silhouettes Using Manifold Learning###A novel method for learning and recognizing sequential image data is proposed, and promising applications to vision-based human movement analysis are demonstrated. To find more compact representations of high-dimensional silhouette data, we exploit locality preserving projections (LPP) to achieve low-dimensional manifold embedding. Further, we present two kinds of methods to analyze and recognize learned motion manifolds. One is correlation matching based on the Hausdorrf distance, and the other is a probabilistic method using continuous hidden Markov models (HMM). Encouraging results are obtained in two representative experiments in the areas of human activity recognition and gait-based human identification.
4020661
An Online Discriminative Approach to Background Subtraction###We present a simple, principled approach to detecting foreground objects in video sequences in real-time. Our method is based on an on-line discriminative learning technique that is able to cope with illumination changes due to discontinuous switching, or illumination drifts caused by slower processes such as varying time of the day. Starting from a discriminative learning principle, we derive a training algorithm that, for each pixel, computes a weighted linear combination of selected past observations with time-decay. We present experimental results that show the proposed approach outperforms existing methods on both synthetic sequencse and real video data.
4020660
Multimedia Surveillance and Monitoring###In spite of the development of various media sensors, multimedia (and computer vision) researchers have mostly adopted a video-centric approach to solve the automated surveillance and monitoring related problems. We look at the monitoring/surveillance problem from an information-centric perspective and advocate the use of diverse sources of information which enables the use of multiple correlated media. We advocate a design methodology for building systems which can explicitly take performance into account. We then propose that the surveillance problem can be better posed as an "information-search" problem in which the user can query for the information of his/her interest. We will present a framework for multimedia monitoring that uses a domain-data transformation model based approach to map domain-events to their equivalent data-events. We will motivate the new approach, present the architecture and highlight the information assimilation aspects. We will also present some open problems and issues arising from the novel way of looking at monitoring.
4020663
Detecting Changes in Grey Level Sequences by ML Isotonic Regression###We present a robust and efficient change detection algorithm for grey-level sequences. A deep investigation of the effects of disturbance factors (illumination changes and automatic or manual adjustments of the camera transfer function, such as AGC, AE and gamma-correction) on image brightness allows to assume locally an order-preservation of pixel intensities. By a simple statistical modelling of camera noise, an ML isotonic regression procedure can thus be applied to perform change detection. Although the proposed approach may be used as a stand-alone pixel-level change detector, here we apply it to reduced-resolution images. In fact, we aim at using the algorithm as the coarse-level of a coarse-to-fine change detector we presented in [2].
4020662
Nonparametric Background Modeling Using the CONDENSATION Algorithm###Background modeling for dynamic scenes is an important problem in the context of real time video surveillance systems. Several nonparametric background models have been proposed to model dynamic scenes and promising results have been reported. However, a critical problem with existing nonparametric models is their high computational requirement because a large set of background samples is usually needed to model the background. In this paper, a nonparametric background model that uses an importance sampling method is proposed to overcome the problem of high computational complexity of conventional nonparametric background models. Instead of using a large number of samples to model the background probability densities, much fewer background samples are maintained and updated using the CONDENSATION algorithm. A Markov Random Field model is used to enhance the foreground detection results by imposing spatial constraints. Experimental results show that the proposed method is much faster and computationally more efficient than existing nonparametric background models. The proposed technique is observed to match the capabilities of existing nonparametric background models in terms of being able to effectively model dynamic backgrounds but with greatly reduced computational complexity.
4020669
Real-Time Detection of Camera Tampering###This paper presents a novel technique for camera tampering detection. It is implemented in real-time and was developed for use in surveillance and security applications. This method identifies camera tampering by detecting large differences between older frames of video and more recent frames. A buffer of incoming video frames is kept and three different measures of image dissimilarity are used to compare the frames. After normalization, a set of conditions is tested to decide if camera tampering has occurred. The effects of adjusting the internal parameters of the algorithm are examined. The performance of this method is shown to be extremely favorable in real-world settings.
4020668
Improved Vehicle Classification in Long Traffic Video by Cooperating Tracker and Classifier Modules###Visual surveillance systems intend to extract meaning from a scene. Two initial steps for this extraction are the detection and tracking of objects followed by the classification of these objects. Often times these are viewed as separate problems where each is solved by an individual module. These tasks should not be done individually because they can help one another. This paper demonstrates the benefit gained both in tracking and classification through the communication between these individual modules. This is shown on a real-time system monitoring highway traffic. The system retreives online video at 10 frames/sec and conducts tracking and classification simultaneously. Results show an improvement from 74% to 88% accuracy in classification results.
4020708
Holonic Multi-agent Systems to Integrate Independent Multi-sensor Platforms in Complex Surveillance###As far as a surveillance system is always integrated in an environment it has to adapt to possible changes that can occur in it. For this reason, it is not sufficient to install a series of sensors along the facilities to be guarded, as any modifications enormously increment the amount of data to be interpreted. Also, eventual failures or sabotages to the sensors produce the collapse of the system, which is not convenient at all in a potentially dangerous environment. Thus, the natural evolution of these systems is the integration in a compact system of intelligent platforms, which are able or not of moving in the environment, which possess several and complementary sensor types, and which interpret the information of each sensor coherently to offer the platform itself a fair service of surveillance. Quality of service is notably increased when there are a sufficient number of platforms forming a compact multi-agent system (MAS). Moreover, this MAS can itself be a compact subsystem of a superior hierarchy MAS composed of several subsystems. This is what we denominate recursive or holonic multi-agent systems.
4020709
On Person Authentication by Fusing Visual and Thermal Face Biometrics###Recognition algorithms that use data obtained by imaging faces in the thermal spectrum are promising in achieving invariance to extreme illumination changes that are often present in practice. In this paper we analyze the performance of a recently proposed face recognition algorithm that combines visual and thermal modalities by decision level fusion. We examine (i) the effects of the proposed data preprocessing in each domain, (ii) the contribution to improved recognition of different types of features, (iii) the importance of prescription glasses detection, in the context of both 1-to-N and 1-to-1 matching (recognition vs. verification performance). Finally, we discuss the significance of our results and, in particular, identify a number of limitations of the current state-of-the-art and propose promising directions for future research.
4020706
Signal Based Node Activation in Wireless Sensor Networks###The emerging technology of Wireless Sensor Networks offers the potential for a new and unparalleled level of surveillance for events occurring in an environment. The quality of surveillance will be directly related to the quantity and density of sensors that can be deployed, and that are actively participating in the monitoring at any given instant. In opposition to this is the requirement for judicious power management of the network in order to prolong its operational lifespan by minimizing node activity. In this paper we explore the effect on surveillance quality when using interpolation error as a mechanism for deciding node activations. More specifically we examine the effect of using this signal based hibernation technique on target localization error and node activity.
4020707
Sensor Bandwidth Assignment through Video Annotation###The state of the art of surveillance systems include a large set of techniques for both low level and high level tasks. In particular, the research community has witnessed in the last decade a high proliferation of techniques that span from object detection and tracking to object recogni- tion and event understanding. Although some techniques have been proven to be very effective those tasks cannot be considered solved. Although more effort is needed in the event analysis field, a new problem arises from the develop- ment of large scale networked surveillance systems: infor- mation sharing. The way information is shared between the nodes of the surveillance network today represents a key- point issue. To provide a first and novel solution to such a problem, we propose an innovative system architecture for a video surveillance system with distributed processing over multiple processing units and with distributed communica- tion over multiple heterogeneous channels (wireless, satel- lite, local IP networks, etc.). In particular, a new real-time technique for changing the video transmission parameters (e.g., frame rate, spatial/color resolution, etc.) according to the bandwidth available will be here presented.
4020704
Omni-Directional Camera Networks and Data Fusion for Vehicle Tracking in an Indoor Parking Lot###A fixed single camera is not sufficient for monitoring a wide area. More cameras can be used, but a problem with integrating all of them will arise. In this paper, a monitoring system to detect and track moving objects in an indoor environment using multiple omni-directional cameras is proposed. Objects captured from different cameras can be integrated automatically, and we can add more cameras to enlarge the monitoring range without changing the system architecture. Such a system is currently being applied to a model of a parking lot for detecting the paths of vehicles.
4020705
Fusion of Omnidirectional and PTZ Cameras for Accurate Cooperative Tracking###Dual camera systems (omnidirectional and slaved PTZ cameras) are widely used in public area monitoring and target tracking. However, due to their low and non-uniform resolution, omnidirectional cameras are only able to provide moderate accuracy in both motion/target detection and tracking. To overcome this disadvantage, two methods are proposed: geometry mapping based on a polynomial imaging model and closed loop cooperative tracking. Using a unified polynomial approximation [1], the geometry relationship between the omnidirectional and PTZ cameras can be formulated in a general solution from camera calibration with a fully automated model selection. Distributed Kalman filters are developed to exchange estimated trajectories among cameras forming closed loop sub-systems for individual cameras. The effectiveness of the proposed algorithms is illustrated via experiments and comparisons with existing systems.
4020702
Geometry of a Non-Overlapping Multi-Camera Network###Moving beyond single or stationary camera surveillance systems, we employ an automatically configurable network of non-overlapping cameras. These cameras need not have an overlapping Field of View (FoV) and should be able to move freely in space. In this paper, a practical framework is proposed that determines the geometry of such a dynamic camera network. Assuming each camera in the network is calibrated, it is shown that only one automatically computed vanishing point and a line lying on any plane orthogonal to the vertical direction is sufficient to infer the dynamic network configuration. Our method generalizes previous work which considers restricted camera motions. Using minimal assumptions, we are able to successfully demonstrate promising results on synthetic as well as on real data.
4020703
Activity Topology Estimation for Large Networks of Cameras###Estimating the paths that moving objects can take through the fields of view of possibly non-overlapping cameras, also known as their activity topology, is an important step in the effective interpretation of surveillance video. Existing approaches to this problem involve tracking moving objects within cameras, and then attempting to link tracks across views. In contrast we propose an approach which begins by assuming all camera views are potentially linked, and successively eliminates camera topologies that are contradicted by observed motion. Over time, the true patterns of motion emerge as those which are not contradicted by the evidence. These patterns may then be used to initialise a finer level search using other approaches if required. This method thus represents an efficient and effective way to learn activity topology for a large network of cameras, particularly with a limited amount of data.
4020700
Improving the Speed of Kernel PCA on Large Scale Datasets###This paper concerns making large scale Kernel Principal Component Analysis (KPCA) feasible on regular hardware. The KPCA has been proven a useful non-linear feature extractor in several computer vision applications. The standard computation method for KPCA, however, scales badly with the problem size, thus limiting the potential of the technique for large scale data. We propose a novel method to alleviate this problem. The essence of our solution lies in partitioning the data and greedily filtering each partition for a sparse representation. Incremental KPCA is then utilized to merge each partition to arrive at the overall KPCA. We also provide experimental results which demonstrate the effectiveness of the approach.
4020701
Learning a New Statistical Shape Prior Model for Object Detection by Geodesic Active Contours###A new statistical shape prior model is proposed in this paper which is incorporated into geodesic active contours for robust object detection. The object shapes that undergo nonlinear deformable changes are assumed to lie in a low dimensional feature subspace and form clusters after a nonlinear mapping. They are approximated by a probabilistic density model to explore the structure of data distribution. The obtained probability is treated as a shape energy term and is incorporated into geodesic active contour equation to constrain the further curve evolution process. This shape prior model is based on a more sophisticated statistical learning of the training data distribution and thus is more robust in presence of occlusions and cluttered background. Experiments demonstrate its promising detection performance for the intended tasks.
4020672
Number Plate Recognition Based on Support Vector Machines###Automatic number plate recognition method is required due to increasing traffic management. In this paper, we first briefly review some knowledge of Support Vector Machines (SVMs). Then a number plate recognition algorithm is proposed. This algorithm employs an SVM to recognize numbers. The algorithm starts from a collection of samples of numbers from number plates. Each character is recognized by an SVM, which is trained by some known samples in advance. In order to recognize a number plate correctly, all numbers are tested one by one using the trained model. The recognition results are achieved by finding the maximum value between the outputs of SVMs. In this paper, experimental results based on SVMs are given. From the experimental results, we can make the conclusion that SVM is bettr than others such as inductive learning-based number recognition
4020673
Generic Object Recognition Using a Combination of ICA and Shape Cues###This paper addresses the problem of Generic Object Recognition by modeling the perceptual capability of human beings. In contrast to the traditional approaches, we have approached the recognition problem by proposing a framework which involves two stages of processing. First, an intelligent generic recognizer based on independent component analysis (ICA) is employed to reduce the search space to a few rank-ordered samples. It is shown that ICA captures the appearance characteristics of objects. Shape cues (distance transform based matching) are then used to verify the result of the appearance-based classifier and identify the correct object class and pose. Experiments were conducted using objects with complex appearance and shape characteristics. Sensitivity of recognition to the number of independent components and number of learning samples is analyzed on COIL-100 database. The performance of the generic classifier using ICA with and without shape matching is also analyzed.
4020670
Support Vector Machine with Weighted Summation Kernel Obtained by Adaboost###This paper presents Support Vector Machine (SVM) with weighted summation kernel obtained by Adaboost. In recent years, SVM with local summation kernel is proposed to use local features in SVM effectively. However, the computational cost of original method is high because all local kernels are used. In general, the effective position and size are different for recognition task. However, original method applied local kernel with same size to all scalar features and all local kernels are integrated with equal weight. To improve the performance and reduce the computational cost, local kernels with various size are prepared at all positions of a recognition target and effective local kernels are selected by Adaboost. Since 1-Nearest Neighbor (1-NN) of the output of local Gaussian kernel at certain size and position is used as weak learner, a strong classifier obtained by Adaboost becomes a new weighted summation kernel specialized for given recognition task. The proposed method is applied to face detection task. We confirmed that the proposed weighted summation kernel gives better performance than original local summation kernel though the proposed method uses the smaller number of local kernels than local summation kernel.
4020671
Articulated Object Recognition: A General Framework and a Case Study###We present in this paper a general-purpose approach for articulated object recognition. We split the recognition process in two distinct phases. In the former we use standard model-based techniques in order to recognize and localize in the input image the rigid components the articulated object is composed of. In the second phase the spatial configurations formed by the recognized components are analyzed and compared with the valid configurations of the object we are searching. The comparison is based on a constraint satisfaction method which can deal with both missing components and false positives. The proposed method is based on a redundant set of constraints which represent the valid spatial configurations of the object's components. Such constraints are not embedded in the system nor are domain-specific but they are learned during a suitable training phase. We show how this approach can be used in different scenarios with different kinds of articulated objects and we present a case study concerning a robotic application.
4020676
An Abandoned/Removed Objects Detection Algorithm and Its Evaluation on PETS Datasets###In this paper, a new method for a robust and efficient analysis of video sequences is presented; it allows the extraction of foreground objects and the classification of static foreground regions as abandoned or removed objects (ghosts). As a first step, the moving regions in the scene are detected by subtracting to the current frame a background model continuously adapted. Then, a shadow removing algorithm is used to extract the real shape of detected objects. Finally, moving objects are classified as abandoned or removed by matching the boundaries of static foreground regions. The method was successfully tested on both real image sequences acquired in our laboratory and some sequences from the PETS 2006 Datasets.
4020677
A Novel Metric on Partitions for Image Segmentation###The explosion of image content is closely connected with segmentations efficiency. However, there is no agreement as to what a good segmentation is due to hard data and applications dependence. To reduce the gap between low-level features and high-level semantic, collections of image partitions produced by different segmentation algorithms are often considered. We propose, theoretically ground and experimentally explore a new metric on segmented images or on arbitrary partitions of finite sets in general.
4020674
Car Plate Detection Using Cascaded Tree-Style Learner Based on Hybrid Object Features###Car plate detection is a key component in automatic license plate recognition system. This paper adopts an enhanced cascaded tree style learner framework for car plate detection using the hybrid object features including the simple statistical features and Harr-like features. The statistical features are useful for simplifying the process on cascade classifier. The cascaded tree-style detector design will further reduce the false alarm and the false dismissal while retaining a high detection ratio. The experimental results obtained by the proposed algorithm exhibit the encouraging performance.
4020675
A Study on Image Enhancement Techniques for Fingerprint Identification###The aim of this paper is to propose a new method in fingerprint enhancement with application of wavelet transform which is more efficient than existing methods. At present the methods that are in use are the ones involving the use of Gabor filtering and Fourier filtering. But the accuracy of these techniques is far from satisfactory. A new technique is being proposed that incorporates wavelet transform and Gabor filtering. The performance of this technique is being discussed in the paper.
4020678
"Hybrid Cone-Cylinder" Codebook Model for Foreground Detection with Shadow and Highlight Suppression###In the interest of 24-7 long-term surveillance, a truly robust, adaptive, and fast background-foreground segmentation technique is required. This paper deals with the especially difficult but extremely common problems of moving backgrounds, shadows, highlights, and illumination changes. To produce reliable foreground extraction in the face of these problems, the best practical aspects of two algorithms, Codebook Segmentation[6] and HSV Shadow Suppression[2] are combined. The main contribution of this paper is the introduction of the "Hybrid Cone-Cylinder" Codebook (HC3) model. Results show superior speed and quantitatively better performance in many different conditions and environments. Applications include people-tracking with Omni-directional cameras and vehicle-counting with rectilinear cameras.
4020679
Template Matching Based on the L_p Norm Using Sufficient Conditions with Incremental Approximations###This paper proposes a novel algorithm aimed at speeding-up template matching based on the L_p norm. The algorithm is exhaustive, i.e. it yields the same results as a Full Search (FS) template matching process, and is based on the deployment of tight lower bounds that can be derived by using together the triangular inequality and partial evaluations of the L_p norm. In order to deploy this, template and image subwindows are properly partitioned. The experimental results prove that the proposed algorithm allows speeding-up the FS process and also (when applied to the L_2 norm) the exhaustive approach based on the Fast Fourier Transform.
4020689
An Active Head Tracking System for Distance Education and Videoconferencing Applications###We present a system for automatic head tracking with a single pan-tilt-zoom (PTZ) camera. In distance education the PTZ tracking system developed can be used to follow a teacher actively when s/he moves in the classroom. In other videoconferencing applications the system can be utilized to provide a close-up view of the person all the time. Since the color features used in tracking are selected and updated online, the system can adapt to changes rapidly. The information received from the tracking module is used to actively control the PTZ camera in order to keep the person in the camera view. In addition, the system implemented is able to recover from erroneous situations. Preliminary experiments indicate that the PTZ system can perform well under different lighting conditions and large scale changes.
4020688
Recovery of Circular Motion Geometry in Spite of Varying Intrinsic Parameters###Previous algorithms for recovering 3D geometry from uncalibrated circular motion image sequences of unknown rotation angles are mostly for constant intrinsic parameters. In this paper, a new and simple method for recovering circular motion geometry in spite of varying intrinsic parameters is proposed. It is shown that the movement of the camera forms two concentric circles on the motion plane. By identifying the concentric conic loci in 3D projective frame, the geometry of circular motion can be recovered. Compared with existing rotation angle recovery methods, the new method is (i) more flexible in that it allows the intrinsic parameters to vary from image to image; (ii) simpler by avoiding the calculation of the intersection points of two conics which is notoriously complicated. Experimental results for real images are provided to show the performance of the proposed method.
4020687
Enhanced Kernel-Based Tracking for Monochromatic and Thermographic Video###In this paper, we present an enhanced kernel-based tracker for monochromatic and thermographic video. The technique presented here employs the image intensity and the Local Binary Pattern (LBP) to construct a two dimensional histogram representative of the grayscale values and the texture of the target under study. With the histogram at hand, we proceed to compute its power density function. The new location of the object is then determined making use of a mean-shift optimisation approach. We illustrate the performance of our method in both, thermographic and monochromatic footages and compare our results to an alternative.
4020686
VHDL-Based Simulation of a Parallel Implementation of a Phase-Based Algorithm for Optical Flow###The computation of optical flow can be an important part in a diverse number of applications. However, optical flow algorithms can be categorized as either very accurate and slow or very fast and highly inaccurate. None of the optical flow algorithms combined both accuracy and efficiency. Among these algorithms was the phase-based fleet and Jepson algorithm. Although this algorithm has proved to produce relatively accurate results, it can not be exploited in many real-life applications due to its relatively long run-time. The goal of this paper is to combine the accuracy of the phase-based optical flow algorithm by Fleet and Jepson and exploit the parallelism and high performance capabilities of the FPGAs to provide an accurate and efficient optical flow algorithm for FPGA-based applications.
4020685
Multi-view Intelligent Vehicle Surveillance System###This paper presents a multi-view intelligent surveillance system used for the automatic tracking and monitoring of vehicles in a short-term parking lane. The system has the ability to track multiple vehicles in real-time across four cameras monitoring the area using a combination of both motion detection and optical flow modules. Automated alerts of events such as parking time violations, breaching of restricted areas or improper directional flow of traffic can be generated and communicated to attending security personnel. Results are shown using surveillance data captured from a real multi-camera network to illustrate the robust and real-time performance of the system.
4020684
A Multi-Class Tracker Using a Scalable Condensation Filter###Tracking systems are typically targeted towards tracking a single class of object. In many real world situations, and in the ETISEO evaluation, it is advantageous to be able to track multiple classes of objects. In this paper we describe the adaptation of a single class tracking system to a multi-class tracking system, and describe a modified version of the condensation filter that can be used to track all objects, of all classes. We show that by using simple targeted detectors, we can achieve accurate tracking and can accurately distinguish between classes.
4020683
Grouped-People Splitting Based on Face Detection and Body Proportion Constraints###This paper presents a method based on skin colormodel face detection and human body proportion constraints to estimate the number and position of people entering the monitored scene as a compact group. This helps to split the group into individual persons and solve a common lack in traditional background subtraction based detection and tracking methods: despite common systems, this algorithm can recognize the number and position of the people in a single change detection blob. The hypotheses are: standing subjects, face visibility from the point of view of the camera, a calibrated map to estimate objects distance from the sensor and to estimate expected peoples height on the image plane. These estimations allow dynamic thresholding of several shape parameters and lead to very interesting results.
4020682
High-Quality Real Time Motion Detection Using PTZ Cameras###The approaches based on background difference are the most used with fixed cameras to perform motion detection, because of the high quality of the segmentation achieved. However, real time requirements prevent most of the algorithms proposed in literature to exploit the background difference with Pan-Tilt-Zoom (PTZ) cameras in real world applications. Nevertheless, using color information to detect motion yields a sensible improvement in terms of accuracy of segmented masks, by helping reducing camouflage and detecting shadows. To our knowledge, the algorithm we have conceived is the first to exploit color information and perform real time alignment and background difference based on background mosaicing, with PTZ cameras. In addition, no prior information regarding scene or camera parameters have been used for either spatial or tonal alignment. Accurate experiments performed on indoor and outdoor sequences allow to assess both quality and performance of the method we devised.
4020681
Learning Feature Extraction and Classification for Tracking Multiple Objects: A Unified Framework###A great challenge in tracking multiple objects is how to locate each object when they interact and form a group. We view it as a binary classification problem. It is important to base the classification on the currently most discriminative features. We derive a unified framework for learning feature extraction and classification in appearance-spatial space for multiple object tracking. In this framework, both classifier design and feature evaluation are accomplished by minimizing an criterion which corresponds to an upperbound of classification error. There, the most discriminative features, as variables, minimize the criterion function, whereas the classifier, as a function, minimizes the criterion functional. The resulting system offers high accuracy for real-time tracking of nearby multiple objects in complex and dynamic scenes.
4020680
Classification of Unattended and Stolen Objects in Video-Surveillance System###This paper describes a video surveillance system aimed at the automatic identification of events of interest, especially of abandoned and stolen objects in a guarded indoor environment. In particular the implemented system combines three phases of data processing: object extraction, object recognition and tracking, and decision about actions. Extracted objects are classified as "human" or "non-human" and static or dynamic, an event of interest following from a split between a "human" and a static "non-human" object, finally static "nonhuman" is analyzed to discriminate between abandoned or stolen object.
4020768
On the Performance and Use of Speaker Recognition Systems for Surveillance###We model the performance of a speaker recognition system used for surveillance to prioritize a large number of candidate speakers in search of a single target speaker. It is assumed that the system operates by ordering all speakers in order from best match to worst match, with the goal of having the true speaker sample positioned as high as possible on the list. Some performance measures for prioritization systems are given and are applied to a real speaker recognition system. An analytic expression for the probability density function of the true speakers position on the list is found, subject to basic assumptions concerning the distribution of true speaker and false speaker scores. A comparison is made to the performance of a system which is operating only by making verification decisions, and it is shown that making soft decisions results in significantly better surveillance performance.
4020769
A Knowledge-Based Approach for Detecting Unattended Packages in Surveillance Video###This paper describes a novel approach for detecting unattended packages in surveillance video. Unlike the traditional approach to just detecting stationary objects in monitored scenes, our approach detects unattended packages based on accumulated knowledge about human and non-human objects from continuous object tracking and classification. We design different reasoning rules for detecting different scenarios of the unattended package events. In the case where a package is left unattended by a single person explicitly, a rule using human activity recognition is introduced to decide the package ownership. In the case where a suspicious package is dropped down by a group of humans or under heavy occlusions, a rule based on historic tracking and classification information is proposed. Furthermore, an additional rule is given to reduce false alarms that may happen with traditional stationary object detection methods.
4020760
A Prototype of Autonomous Intelligent Surveillance Cameras###This paper presents an architecture and an FPGAbased prototype of an autonomous intelligent video surveillance camera. The camera takes the advantage of high resolution of CMOS image sensors and enables instantly automatic pan, tilt and zoom adjustment based upon motion activity. It performs automated scene analysis and provides immediate response to suspicious events by optimizing camera capturing parameters. The video output of the camera can be optimized to any region of interest while the camera continues to monitor the entire scene. Field trials of the prototyped camera have verified the proposed architecture.
4020761
A Compact Architecture for Wireless Video Surveillance over CDMA Network###Wireless video surveillance over CDMA network enables transfer of high quality live video via public wireless broadband, which is accessible anywhere with CDMA mobile phone network coverage. Real time video can be received on an internet connected PC, laptop or even mobile phone. This makes possible surveillance from moving vehicles, or quick deployment in almost unrestricted locations. While many general purpose solutions exist for sending video over CDMA, they have not taken into consideration certain specific features of the network nor the requirements of the related applications. This paper presents a new architecture for video transmission over CDMA with simple hardware complexity, high reliability and rich functions. The compact and flexible system has been under trial in China, Australia, Singapore, Italy, Egypt and Brazil, amongst others.
4020762
Scalable Surveillance Software Architecture###Video surveillance is a key technology for enhanced protection of facilities such as airports and power stations from various types of threat. Networks of thousands of IP-based cameras are now possible, but current surveillance methodologies become increasingly ineffective as the number of cameras grows. Constructing software that efficiently and reliably deals with networks of this size is a distributed information processing problem as much as it is a video interpretation challenge. This paper demonstrates a software architecture approach to the construction of large scale surveillance network software and explores the implications for instantiating surveillance algorithms at such a scale. A novel architecture for video surveillance is presented, and its efficacy demonstrated through application to an important class of surveillance algorithms.
4020763
Real-Time Video Segmentation with VGA Resolution and Memory Bandwidth Reduction###This paper presents the implementation of a video segmentation unit used for embedded automated video surveillance systems. Various aspects of the underlying segmentation algorithm are explored and modifications are made with potential improvements of segmentation results and hardware efficiency. In addition, to achieve real-time performance with high resolution video streams, a dedicated hardware architecture with streamlined dataflow and memory access reduction schemes are developed. The whole system is implemented on a Xilinx FPGA platform, capable of real-time segmentation with VGA resolution at 25 frames per second. Substantial memory bandwidth reduction of more than 70% is achieved by utilizing pixel locality as well as wordlenghth reduction. The hardware platform is intended as a real-time testbench for observations of long term effects with different parameter settings, which is hard to achieve on a PC platform.
4020764
Open Source Vision Library (OpenVL) Based Local Positioning System###This paper presents an Open Source Vision Library (OpenVL) for hardware acceleration of video-based surveillance systems and other computer vision applications to facilitate low latency, real-time response. Our approach is inspired by the success of OpenGL in promoting the development of hardware acceleration for computer graphics. Our goal is to create OpenVL as a standard interface for computer vision applications that can work seamlessly on different software and hardware platforms supporting distributed camera arrays. It allows users to easily recover useful information about real dynamic scenes quickly, and in a portable manner across various software and hardware platforms. Finally, we implement an example surveillance system, called a Local Positioning System (LPS), to validate the critical underlying concepts of OpenVL.
4020765
The Audio Surveillance Eye###In this paper we present a novel signal processing algorithm accompanied with an array structure for audio signal localization and surveillance in three dimensional space. This method, which has similarities to the eye structure, consists of a novel hemispherical microphone array with microphones on the shell and one microphone in the sphere center. A signal processing scheme utilizes parallel creation of a special closeness function for each microphone direction on the shell. Contrary to traditional algorithmic sound source localization techniques, our method is based on some simple parallel mathematical calculations in the time domain; therefore it can be easily implemented on a custom designed integrated circuit.
4020766
Robust License Plate Detection Using Covariance Descriptor in a Neural Network Framework###We present a license plate detection algorithm that employs a novel image descriptor. Instead of using conventional gradient filters and intensity histograms, we compute a covariance matrix of low-level pixel-wise features within a given image window. Unlike the existing approaches, this matrix effectively captures both statistical and spatial properties within the window. We normalize the covariance matrix using local variance scores and restructure the unique coefficients into a feature vector form. Then, we feed these coefficients into a multi-layer neural network. Since no explicit similarity or distance computation is required in this framework, we are able to keep the computational load of the detection process low. To further accelerate the covariance matrix extraction process, we adapt an integral image based data propagation technique. Our extensive analysis shows that the detection process is robust against noise, illumination distortions, and rotation. In addition, the presented method does not require careful fine tuning of the decision boundaries.
4020767
Bicoherence Used to Predict Lucky Regions in Turbulence Affected Surveillance###Long-distance surveillance is an emerging technology which attracts more and more attention from researchers in different areas, particularly for security applications. One of the major challenges of such technology is how to remove the effect due to atmospheric turbulence to get highresolution images. A common practice is to take shortexposure images of the target so that the effect of atmospheric turbulence is frozen, and then the raw images are post-processed to estimate a good quality image (speckle imaging techniques). A new lucky region approach based on such techniques is presented in this paper. The lucky regions are extracted through bicoherence analysis, and the final output image is obtained by post-processing (dewarping and blind deconvolving) the lucky regions. The new technique allows for automatic identification and extraction of lucky regions, and can be easily implemented. Realworld results show that the algorithm is promising.
4020755
Effect of Finite Sample Size in Content-Based Image Retrieval###Finite sample size has always been a problem in determining the retrieval accuracy of a Content-Based Image Retrieval (CBIR) system. Though a good amount of research has been done in the statistical pattern recognition field, no such effort is shown in relation to CBIR. In this paper, we considered image retrieval as a dichotomous classification problem and studied the effect of sample size on the retrieval accuracy. We reported experimental results and analysis with two different image databases of size 2000 and 500, both having 10 semantic categories. For both data sets, we showed the variation of precision with sample size. We also studied the effect of sample size on retrieval accuracy as Relevance Feedback (RF) is applied. For both data sets, the nett improvement in precision with RF increases with sample size.
4020754
CBIR Approach to Building Image Retrieval Based on Linear Edge Distribution###In this paper, we propose a CBIR approach to retrieve building images. First, we use the Canny edge detector to extract edge information from the images. Secondly, the Hough transform is applied to the edge map in order to reveal the linear edge distribution in the Hough transform domain. Thirdly, by using a Band-wise matching (BWM) algorithm, we partition the Hough transform domain into a number of bands and calculate the centroid of the Hough peaks in each band. By carrying out the same aforementioned procedures on a query image and the images in the database, we measure the similarity between the centroids of the query image and the images in the database. Finally, based on the similarity measures, the CBIR system ranks the images in the database and retrieves a specified number of images with the highest rankings.
4020757
Shape Retrieval Using Matching Pursuit Decomposition###This paper presents an approach of shape retrieval using linear regression. This approach extracts object edges from decomposed images in different scale levels and approximates them by the linear regression algorithm Matching Pursuit (MP). MP uses linear combination of circular Gaussian basis functions to reconstruct target edges. Each Gaussian basis function contains several features: scale, position and amplitude, which are used to compute distance of two contours. Shapes are retrieved according to the distances between query image and all images in a database.
4020756
A Comparison on Histogram Based Image Matching Methods###Using colour histogram as a stable representation over change in view has been widely used for object recognition. In this paper, three newly proposed histogram-based meth- ods are compared with other three popular methods, includ- ing conventional histogram intersection (HI) method, Wong and Cheungs merged palette histogram matching (MPHM) method, and Gevers colour ratio gradient (CRG) method. These methods are tested on vehicle number plate images for number plate classification. Experimental results dis- close that, the CRG method is the best choice in terms of speed, and the GWHI method can give the best classifi- cation results. Overall, the CECH method produces the best performance when both speed and classification per- formance are concerned.
4020698
Data Fusion in Sensor Networks###There is a growing excitement about the potential application of large scale sensor networks in diverse applications such as precision agriculture, geophysical and environment monitoring, remote health care, and security. Rapid progress in sensing hardware, communications and low-power computing has resulted in a profusion of commercially available sensor nodes. The big challenge now is to develop effective methods for the automatic fusion and interpretation of the information generated by large-scale sensor networks. The success of future applications is predicated on finding solutions to this data fusion challenge. This talk will focus on probabilistic models and Bayesian data fusion methods appropriate to describing and solving sensor network data fusion problems. Over a number of years, we have used such methods to develop decentralised algorithms for point-target estimation in sensor networks. More recently, other researchers have developed distributed Bayesian algorithms for sensor networks to estimate field properties, such as temperature or humidity over an area. The prospect of developing holistic Bayesian methods for fusion in sensor networks now looks to be a real and exciting possibility. This talk will describe these potential developments. Notions of divergence and information appear naturally in probabilistic fusion algorithms. In turn these provide a handle on two other sensor network data fusion problems; how to model and manage sensor node performance and how to learn patterns in or interpret sensor network information. These ideas will also be developed in this talk. Interspersed amongst these developments we will describe some real sensor network applications, some solved, some currently being addressed, and some that remain as a challenge to network data fusion methods.
4020699
Learning Foveal Sensing Strategies in Unconstrained Surveillance Environments###In this paper we report on techniques for automatically learning foveal sensing strategies for an active pan-tiltzoom camera. The approach uses reinforcement learning to discover foveal actions maximizing the performance of visual detectors, that are in turn assumed to be highly correlated with the task at hand. In our case, the main goal is to recognize people, hence a frontal face detection module is employed. The system uses reinforcement learning to learn if, when and how to foveate on a subject, based on its previous experience in terms or successful actions in similar situations. An action is successful if it leads to a correct face detection in the high resolution images obtained when the subject is zoomed in. In contrast with existing methods, the proposed approach obviates the need for camera calibration and camera performance modeling. Also, the method does not rely on active tracking of targets. Experimental results show how the system is capable of learning foveation strategies without requiring extensive a priori information or environmental models. Results also illustrate how the system effectively learns a strategy that allows the camera to foveate only in situations where successful detection is highly likely.
4020753
Global-to-Local Histogram Match Culling for Epipolar Geometry Estimation###Estimation of the Epipolar Geometry and Fundamental Matrix for a pair of stereo images often begins with a stage of feature (corner) detection and correlation based feature matching. This generally results in a set of matches where features are matched multiple times and frequently incorrectly. This paper introduces a simple and fast histogram based technique for refining the set of matches prior to a final stage of robust Fundamental Matrix estimation that compares favourably to previously published techniques such as SVD and Relaxation.
4020752
Estimation of Internal and External Parameters for Camera Calibration Using 1D Pattern###Camera calibration is to estimate the intrinsic and extrinsic parameters of a camera. Most of object-based calibration methods used 3D or 2D pattern. A novel and more flexible 1D object-based calibration was introduced only a couple of years ago, but merely for estimation of intrinsic parameters. The estimation of extrinsic papers is essential when multiple cameras are involved for simultaneously taking images from different view angles and when the knowledge of relative locations between the cameras is required. Though it is relatively simple using 2D or 3D calibration pattern, the estimation of extrinsic parameters is not obvious using 1D pattern. In this paper, we will perform a 1D camera calibration involving both intrinsic and extrinsic parameters.
4020694
Object Contour Tracking in Videos by Matching Finite Mixture Models###In this paper, we propose a novel object tracking algorithm in video sequences. The method is based on object mixture matching between successive frames of the sequence by using active contours. Only the segmentation of the objects in the first frame is required for initialization. The evolution of the object contour on a current frame aims to find the maximum fidelity of the mixture likelihood for the same object between successive frames while having the best fit of the mixture parameters to the homogenous parts of the objects. To permit for a precise and robust tracking, region, boundary and shape information are coupled in the model. The method permits for tracking multi-class objects on cluttered and non-static backgrounds. We validate our approach on examples of tracking performed on real video sequences.
4020695
Group Detection at Camera Handoff for Collecting People Appearance in Multi-camera Systems###Logging information on moving objects is crucial in video surveillance systems. Distributed multi-camera systems can provide the appearance of objects/people from different viewpoints and at different resolutions, allowing a more complete and precise logging of the information. This is achieved through consistent labeling to correlate collected information of the same person. This paper proposes a novel approach to consistent labeling also capable to fully characterize groups of people and to manage miss segmentations. The ground-plane homography and the epipolar geometry are automatically learned and exploited to warp objects' principal axes between overlapped cameras. A MAP estimator that exploits two contributions (forward and backward) is used to choose the most probable label configuration to be assigned at the handoff of a new object. Extensive experiments demonstrate the accuracy of the proposed method in detecting single and simultaneous handoffs, miss segmentations, and groups.
4020696
A Random Field Model for Improved Feature Extraction and Tracking###This paper presents a novel method for illumination-invariant and contrast preserving feature extraction, aimed at improving performance of tracking under complex light condition. Features to be extracted are represented as a weight field. An energy function of the field is defined as an approximate variance in robust statistics. A simple non-linear iterative rule is derived to compute the optimal field. The optimal field is shown to be invariant to global illumination switching, and preserving target/background contrast. We incorporate the feature extraction method into a mean-shift tracker and this achieves reliable results on real-world sequences in complex scenes and varying illumination.
4020697
Human Body Part Labeling and Tracking Using Graph Matching Theory###Properly labeling human body parts in video sequences is essential for robust tracking and motion interpretation frameworks. We propose to perform this task by using Graph Matching. The silhouette skeleton is computed and decomposed into a set of segments corresponding to the different limbs. A Graph capturing the topology of the segments is generated and matched against a 3D model of the human skeleton. The limb identification is carried out for each node of the graph, potentially leading to the absence of correspondence. The method captures the minimal information about the skeleton shape. No assumption about the viewpoint, the human pose, the geometry or the appearance of the limbs is done during the matching process, making the approach applicable to every configuration. Some correspondences that might be ambiguous only relying on topology are enforced by tracking each graph node over time. Several results present the efficiency of the labeling, particularly its robustness to limb detection errors that are likely to occur in real situations because of occlusions or low level system failures. Finally the relevance of the labeling in an overall tracking system is described.
4020690
Independent Moving Object Detection Using a Colour Background Model###An independent moving objection detection system is described which uses a colour background model for a nonstationary sensor. Over time the RGB distribution of a static point in a scene, observed from a static or moving camera, is cylindrical rather than spherical and is modelled as such. The background model is recursively updated over time and is robustly aligned to the most recent frame. Discrepancies between the current observed frame and the background model are considered foreground events and are determined using a classification framework which combines per-pixel colour and brightness differences. In principle the colour (RGB) images provide greater discriminative power than greyscale (brightness). However for several sequences tested, which are of road scenes from an airborne sensor, it was found that the colour information did not improve the classification of foreground pixels significantly.
4020691
Mitigating the Effects of Variable Illumination for Tracking across Disjoint Camera Views###Tracking people by their appearance across disjoint camera views is challenging since appearance may vary significantly across such views. This problem has been tackled in the past by computing intensity transfer functions between each camera pair during an initial training stage. However, in real-life situations, intensity transfer functions depend not only on the camera pair, but also on the actual illumination at pixel-wise resolution and may prove impractical to estimate to a satisfactory extent. For this reason, in this paper we propose an appearance representation for people tracking capable of coping with the typical illumination changes occurring in a surveillance scenario. Our appearance representation is based on an online K-means color clustering algorithm, a fixed, data-dependent intensity transformation, and the incremental use of frames. Moreover, a similarity measurement is proposed to match the appearance representations of any two given moving objects along sequences of frames. Experimental results presented in this paper show that the proposed methods provides a viable while effective approach for tracking people across disjoint camera views in typical surveillance scenarios.
4020692
Classification-Based Likelihood Functions for Bayesian Tracking###The success of any Bayesian particle filtering based tracker relies heavily on the ability of the likelihood function to discriminate between the state that fits the image well and those that do not. This paper describes a general framework for learning probabilistic models of objects for exploiting these models for tracking objects in image sequences. We use a discriminative classifier to learn models of how they appear in images. In particular, we use a support vector machine (SVM) for training, which is able to extract useful non-linear information, and thus represent more complex characteristics of the tracked object and background. This is a particular advantage when tracking deformable objects and where appearance changes due to the unstable illumination and pose occur. A by-product of the SVM training procedure is the classification function, with which the tracking problem is cast into a binary classification problem. An object detector directly using the classification function is then available. To make the tracker robust, an object detector that directly uses the classification function is combined into the tracker for object verification. This provides the capability for automatic initialisation and recovery from momentary tracking failures. We demonstrate improved robustness in image sequences.
4020693
Motion Trajectory Classification for Visual Surveillance and Tracking###In this paper we present a video surveillance system for automated border and checkpoint analysis. The described system employs automated feature extraction and tracking to ascertain vehicle size, speed, and response to an interrogating vibration for vehicle bounce signature analysis. To increase the overall robustness of the surveillance system, we introduce a novel approach to invalid feature filtering. In particular, we use a hidden Markov model trained to simultaneously recognize specific coarse motion trajectories and tracking failures. The proposed recognition and filtering scheme effectively identifies erroneously tracked features and removes them prior to any subsequent motion analysis tasks. The result is a significant increase in classification and recognition accuracy. We demonstrate the efficacy of the suggested technique on a variety of video surveillance sequences.
4020742
Combined 2D/3D Face Recognition Using Log-Gabor Templates###The addition of Three Dimensional (3D) data has the potential to greatly improve the accuracy of Face Recognition Technologies by providing complementary information. In this paper a new method combining intensity and range images and providing insensitivity to expression variation based on Log-Gabor Templates is presented. By breaking a single image into 75 semi-independent observations the reliance of the algorithm upon any particular part of the face is relaxed allowing robustness in the presence of occulusions, distortions and facial expressions. Also presented is a new distance measure based on the Mahalanobis Cosine metric which has desirable discriminatory characteristics in both the 2D and 3D domains. Using the 3D database collected by University of Notre Dame for the Face Recognition Grand Challenge (FRGC), benchmarking results are presented demonstrating the performance of the proposed methods.
4020743
A Secure Digital Watermarking Scheme for MPEG-2 Video Copyright Protection###Video watermarking is an important method of protecting the intellectual property copyright of the video media. It allows embedding of copyright information into the video pictures. In this paper a new hybrid approach of digital video watermarking scheme with an Error Correcting Code (ECC) is proposed. This watermarking scheme maximizes the watermark payload while minimizing the perceptual degradation of video quality caused by the embedded watermark by means of an appropriate choice of embedding position. Two hybrid error correcting codes, BCH(31,8) and Turbo (3,1) with repetition code were implemented and compared. We found that the hybrid approach of BCH(31,8) with repetition code achieved higher error correcting capability than Turbo (3,1) with repetition code under the simulated noise tests.
4020740
A Validated Method for Dense Non-rigid 3D Face Registration###Deformable surface fitting methods have been widely used to establish dense correspondence across different 3D objects of the same class. Dense correspondence is a critical step in constructing morphable face models for face recognition. In this paper a mainstream method for constructing dense correspondences is evaluated on 912 3D face scans from the Face Recognition Grand Challenge FRGC V1 database. A number of modifications to the standard deformable surface approach are introduced to overcome limitations identified in the evaluation. Proposed modifications include multi-resolution fitting, adaptive correspondence search range and enforcing symmetry constraints. The modified deformable surface approach is validated on the 912 FRGC 3D face scans and is shown to overcome limitations of the standard approach which resulted in gross fitting errors. The modified approach halves the rms fitting error with 98% of points within 0.5mm of their true position compared to 67% with the standard approach.
4020741
Kernel Hetero-associative Memory for Robust Face Recognition###Associative memory models have been studied as efficient paradigm for visual information processing. In this paper we investigate a new hetero-associative memory (HAM) model based on the Kernel Partial Least Square (KPLS) regression recently proposed in the literature. Steming from the Partial Least Square (PLS) regression, a class of techniques for modeling relations between blocks of observed variables by means of latent variables, kernelized PLS methods have proved to be efficient in treating nonlinear data. By establishing the relations between sets of observed variables, KPLS can provide a general purpose HAM model, which construct nonlinear regression models in possibly high-dimensional feature spaces and uses a few latent factors to account for most of the variations in the response. For face recognition problem, we apply the HAM model to efficiently characterize each subject by relating some possible variations of a face image to a given face, using a modular strudcture by assigning an independent model to each subject. Several benchmark face databases have been used to test the performance.
4020746
Lossless Video Coding Using Lattice Based Distributed Source Coding Techniques###Information theoretic proof exists to support that independent encoding of distributed sources with a joint decoder by exploiting the correlation among the sources can be as efficient as encoding them jointly. This paper successfully attempts to apply this concept for lossless video coding using lattices to divide the multidimensional integer pixel intensity hyperspace of a block of pixels into a finite number of cosets and encoding each block with its coset index. This radical departure from conventional predictive coding techniques not only offers very low computational complexity by avoiding expensive learning of predictor coefficients but also avoids any coding loss due to rounding of real-valued predictions. On standard test video sequences, this scheme achieved compression within as low as 4.6% of the latest scheme with optimal learning of predictor coefficients. The former, however, outperformed the latter as soon as it started updating the optimal predictor coefficients less frequently to reduce the computational complexity.
4020747
Combining Shape-from-Motion Output with Partial Metadata###When the positions of the camera are not given, shape-from-motion methods can use target feature positions identified in a sequence of images to extract the three-dimensional positions of the features and the orientations of the camera relative to the target. These methods can be applied to video sequences taken from an aircraft, but do not reveal the overall size, orientation or geographic location of the target. If the camera is combined with a system that records its location, orientation and focal length, at least approximately for a few of the images, the target size, orientation and location can be estimated In certain cases, some of this information can be estimated from the image sequence itself. This paper considers the theory and practice of combining the shape extraction with the available camera information.
4020744
Steganographic Scheme for VQ Compressed Images Using Progressive Exponential Clustering###In this work, we propose a steganographic scheme for embedding secret message in VQ-compressed images, which aims to achieve high embedding capacity while keeping distortion low. To achieve these objectives, we develop a progressive exponential clustering (PEC) algorithm for partitioning the VQ codebook into a set of clusters. To embed the secret message based on the clustering, we substitute the indexes of the codewords with others within the same cluster according to the size of the cluster and the secret message bits.
4020745
DNA Microarray Image Enhancement Using Conditional Sub-Block Bi-Histogram Equalization###In this paper, a new image enhancement approach is proposed, which has the ability to improve the gridding results in DNA microarray analysis. The proposed approach is implemented as a conditional sub-block bi-histogram equalization (CSBE). This is accomplished by first, decomposing an input image into a number of m x n sub-blocks. Second, the threshold of each sub-block is determined independently. Third, the sub-block is divided into two sub-images based on the threshold. Fourth, only pixels having value greater than the threshold are histogram equalized, and the two sub-images are then recombined. The proposed method is tested on various DNA microarray images, giving excellent results, compared to existing methods.
4020748
People Tracking Using a Time-of-Flight Depth Sensor###Visually track several moving persons engaged in close interactions is known to be a very hard problem, though 3-D approaches based on stereo vision and plan-view maps offer much promise for dealing effectively with major issues such as occlusions and quick changes in body pose and appearance. However, in case of untextured scenes due to homogeneous objects or poor illumination, stereo-based tracking systems rapidly drop their performance. In this work, we present a real time people tracking system able to work even under severe low-lighting conditions. The system relies on a novel active sensor that provides brightness and depth images based on a Time of Flight (TOF) technology. The tracking algorithm is simple yet efficient, being based on geometrical constraints and invariants. Experiments accomplished under changing lighting conditions and involving multiple people closely interacting with each other have proved the reliability of the system.
4020749
Active Appearance Models for Automatic Fitting of 3D Morphable Models###This paper presents a fast fitting method for 3D Morphable Models (3DMMs). In most cases fitting a Morphable Model to an image is done using slow non-linear optimization processes. We avoid this by introducing a relationship to Active Appearance Models (AAMs) that can be used to linearize the non-linear optimization problem of 3DMM fitting. Using the combination of a constrained AAM and closed form 2D-3D fitting method for 3DMMs we show that a perceptually close 3D shape can be extracted from the AAM fittings. We show preliminary results of the method and a simplified exterior orientation solution. Finally we conclude with a tracking algorithm that is based on the combination of the AAM and 3DMM, presenting the tracking and reconstruction errors.
4020737
Panoramic Appearance Map (PAM) for Multi-camera Based Person Re-identification###This paper proposes a concept of panoramic appearance map to perform reidentification of a people who leave the scene and reappear after some time. The map is a compact signature of appearance information of a person extracted from multiple cameras. The person is detected and tracked in multiple cameras and triangulation is used to accurately localize the person in 3-D. A virtual cylinder is formed around the persons location and mapped onto an image with the horizontal axis representing the azimuth angle and vertical axis representing the height. Each bin in the map image gets the appearance information from all the cameras which can observe it. The maps between different tracks are matched using a weighted metric. Experimental results showing person matching and reidentification show the effectiveness of the approach.
4020736
Dissecting the Image of the Absolute Conic###In this paper, we revisit the role of the image of the absolute conic (IAC) in recovering the camera geometry. We derive new constraints on IAC that advance our understanding of its underlying building blocks. The new constraints are shown to be intrinsic to IAC, rather than exploiting the scene geometry or the prior knowledge on the camera. We provide geometric interpretations for these new intrinsic constraints, and show their relations to the invariant properties of the IAC. This in turn provides a better insight into the role that IAC plays in determining the camera internal geometry. Since the new constraints are invariant properties of the IAC, they can be used to reparameterize its elements. We show that such reparameterization would allow to recover a more general camera geometry from a single view, compared to existing methods. We apply the new constraints to single view calibration using vanishing points, investigate the error resilience, and compare our results to Liebowitz-Zisserman (1999).
4020735
3D Human Motion Analysis in Monocular Video Techniques and Challenges###Human motion and action analysis in video is an actively growing field with a broad spectrum of applications including video browsing and indexing, entertainment, virtual reality, human-computer interaction and surveillance. However, human motion analysis systems face important scientific and computational challenges. The proportions of the human body vary across individuals due to gender, weight, age or race. Aside from this variability, any single human body has many degrees of freedom due to articulation and the individual limbs are deformable due to muscle and clothing. Finally many realworld scenes involve multiple interacting humans occluded by each other or by other objects, and the scene conditions may also vary due to the camera motion or lighting changes. These factors make accurate 3D human models difficult to build and difficult to reconstruct reliably from ?flat? 2D images. During this talk I will discuss learning and inference algorithms for estimating 3D human motion in monocular video. While the problem has been traditionally approached using the powerful machinery of generative models, operating in an analysis by synthesis loop, the main emphasis of this talk will be on an emerging class of complementary discriminative temporal estimation models. These can be viewed as upside down, bottom-up versions of classical temporal models used with Kalman filtering or particle filtering. But instead of inverting a generative imaging model, we will learn to cooperatively predict complex, feedforward 2D-to-3D mappings, using Conditional Bayesian Mixtures of Experts. These are embedded in a probabilistic temporal framework in order to enforce dynamic constraints and allow a principled propagation of uncertainty. We call the resulting model BM3E (a Conditional Bayesian Mixture of Experts Markov Model). During the talk, I will discuss how inference can be restricted, for efficiency, to low-dimensional non-linear state spaces, and how the framework can be extended - in order to deal with clutter and occlusion. I will also discuss the relative advantages of generative and initialize and recover from failure.
4020734
Data Fusion and Confidence Measure in Image Feature Detection###The data fusion approaches for uncorrelated and correlated data are carried out in image feature detection, which integrate information of the same feature based on multiple methods using a statistical approach. Validity of the scheme and properties of the fused data are discussed. A confidence measure is defined, and applied to evaluate credibility of the result. The technique can be used to reduce adverse effects of individual feature detection errors, and improve the rate of pattern recognition. Examples of facial canthus detection and the corresponding confidence levels are presented.
4020733
View Independent Gait Identification Using a Particle Filter###We challenge the human identification problem from the perspective of gait and body shape. Conventional methods depend on the camera viewing direction, and since they are based on matching image silhouettes or features their identification accuracy is low when there is a big difference between the camera viewing direction of the test and training data. Thus, if a person is walking in an arbitrary direction, they may not be accurately identified. In this paper, we propose a novel method that does not depend on the camera viewing direction. We develop a state space model called a "cyclic motion model" whose state variables are not only the phase of the motions but also the camera viewing direction. We learn model parameters for each candidate person, and represent their walking with the cyclic motion model. To identify a person from the observed image sequence, we first compute the model likelihoods for the sequence using a particle filter that represents a probability distribution by a set of weighted samples, We then identify the person from model likelihoods.
4020732
Optimal Power Scheduling for Data Fusion in Inhomogeneous Wireless Sensor Networks###We consider the problem of optimal power scheduling for the decentralized detection of a deterministic signal in an inhomogeneous wireless sensor network. The observation noise at local sensors is assumed to be independently and identically distributed (i.i.d.) and at the local sensors each node performs analog-relay amplifier processing for its observation independently. The communication between the local sensors and the fusion center is assumed to be through an inhomogeneous channel. The optimal power scheduling scheme suggests that the sensors with poor observation quality and channels should be inactive in order to save total power expenditure of the system. For the remaining active sensors the optimal transmit power is determined jointly by the individual channel gains, total number of active sensors, local observation signal to noise ratio (SNR) and the required probability of error at the fusion center. We show that the optimal scheme can provide significant system power savings compared to the uniform power allocation scheme when the number of sensors in the system is large.
4020731
Large System Decision Fusion Performance in Inhomogeneous Sensor Networks###The problem of decision fusion in a large wireless sensor system with many power-constrained distributed nodes is considered. The sensor network is assumed to be inhomogeneous. i.e. the channel statistics are not identical among the sensors. Assuming identical, binary local quantizing schemes at all the nodes, the optimal fusion scheme is derived. The large system performance of this optimal decision fusion detector is next analyzed. The asymptotic fusion performance is derived via the Lindberg-Feller central limit theorem for non-identical large samples. Numerical examples are used to show that the derived large system closed-form fusion error probability expressions provide a very close approximation to the exact finite-size sensor system fusion performance even for a relatively smaller number of nodes.
4020730
Video Surveillance at the Beginning of the Third Millennium: The Viewpoint of Research, Industry, Government Bodies, Research Funding Agencies and the Community###<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/04020730.png" border="0">
4020739
On Optimisation of Smart Card Face Verification Systems###The optimisation of a smart card face verification system (SCFVS) design is a complex task. As the parameters involved are not independent, the search space is of exponential complexity. We investigate simplified optimisation strategies and demonstrate that both system performance and speed of access can be improved by jointly optimised parameter setting and level of probe compression. Experimental results suggest that the choice of one strategy over another is a matter of the amount of time available for the system design, system performance and response time.
4020738
An LMI Approach for Reliable PTZ Camera Self-Calibration###PTZ (Pan-Tilt-Zoom) cameras are widely used for large-area video surveillance. For many visual tracking and video analysis tasks, an accurate camera calibration is very important. Traditional off-line camera calibration algorithms are often not satisfactory because some of the PTZ camera intrinsic parameters (e.g., focal length) may change during working. Despite of their theoretical elegance, existing on-line camera self-calibration algorithms are not satisfactory either, because of the lack of numerical stability. This paper proposes a new method based on LMI (linear matrix inequality) optimization. This method automatically incorporates the required positive-definiteness constraint into the computation, thus delivers more reliable and more stable results. Experiments on both synthetic data and real images have validated the advantages of our method.
4020751
Robust Auto-Calibration from Pedestrians###The knowledge of camera intrinsic and extrinsic parameters is useful, as it allows us to make world measurements. Unfortunately, calibration information is rarely available in video surveillance systems and it is difficult to obtain once the system is installed. Auto-calibrating cameras using moving objects (humans) has recently attracted a lot of interest. Two methods are proposed by Lv-Nevatia(2002) and Krahnstoever-Mendonca(2005). The inherent difficulty of the problem lies in the noise that is generally present in the data. We propose a robust and a general linear solution to the problem by adopting a formulation different from the existing methods. The uniqueness of formulation lies in recognizing two harmonic homologies present in the geometry obtained by observing pedestrians, and then using properties of these homologies to obtain linear constraints on the unknown camera parameters. Experiments with synthetic as well as on real data are presented - indicating the practicality of the proposed system.
4020750
Registration of Multimodal Stereo Images Using Disparity Voting from Correspondence Windows###This paper presents a method for registering multimodal imagery in short range surveillance situations when the differences in object depths preclude any global registration techniques. An analysis of multimodal registration approaches gives insight into the limitations of global assumptions and motivates the developed algorithm. Using calibrated stereo imagery, we use maximization of mutual information in sliding correspondence windows that inform a disparity voting scheme to demonstrate successful registration of color and thermal images. Extensive testing of scenes with multiple people at different depths and levels of occlusion shows high rates of successful registration and gives a reliable framework for further processing and analysis of the multimodal imagery.
1577285
Real-time vision at Siemens Corporate Research###Computer vision has found applicability in a wide variety of industrial applications. These include surveillance and security, industrial inspection and automation, medical and automotive. This paper gives an overview of the work performed at Siemens Corporate Research in these areas. Some of the basic technologies that are needed for such applications are highlighted along with a brief overview of the particular constraints existing in such applications. Then, our view of the systems methodology required in order to build robust, scalable and reusable systems and modules is presented. Finally, we present our view of the future directions in this field.
1577284
Computer vision for homeland security: a perspective on its promise and pitfalls###<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01577284.png" border="0">
1577287
Fast access control technology solutions (FACTS)###Positive identification (ID) verification of a large number of people (possibly thousands) in a short time, such as when people enter the gates of a manufacturing plant in the morning, can be a daunting task for the security guards. Current methods that use a password, card swipe system, proximity card reader system, or combination are slow and vulnerable. For example a card can be stolen or a password forgotten, copied or given to an unauthorized person. Hence the need for biometric-based access control systems (ACS). Many biometric systems address the ID verification problem; however, none provide quick and convenient positive (reliable) ID. Fingerprinting is unreliable and requires too much cooperation, face recognition systems (FRS) are unacceptable in a one-to-many application, and iris scan is slow and cumbersome. In this paper, we describe a fast access control technology solution (FACTS) system we developed and demonstrated at Honeywell Labs that enables many motorists to enter a secured parking lot without coming to a complete stop. The FACTS solution combines radio frequency identification (RFID) tags with FRS, reducing the one-to-many FRS problem by using a one-to-one match for facial verification (FV). This solution is dynamic, secure, positive, and hands-free for fast gate access control. At the heart of the Honeywell FV system is a unique tri-band imaging (TBI) camera that reliably locates and records the face of an individual or driver in motion while entering a gate.
1577286
Detecting and counting people in surveillance applications###A number of surveillance scenarios require the detection and tracking of people. Although person detection and counting systems are commercially available today, there is need for further research to address the challenges of real world scenarios. The focus of this work is the segmentation of groups of people into individuals. One relevant application of this algorithm is people counting. Experiments document that the presented approach leads to robust people counts.
1577281
Implementation of the watershed method in the HSI color space for the face extraction###The color segmentation is an important preprocessing step in the face detection methods. In this paper we present effective face color segmentation in the HSI (Hue, saturation and intensity) space. We propose to modify the merging algorithm of the catchment basins obtained by the watershed segmentation method by adding a criterion based on the relevance of the Hue component. The obtained experimental results are presented to demonstrate the effectiveness of our approach.
1577280
A model-free approach for posture classification###This paper describes a peculiar methodology for identifying and classifying the human body structures depicted in digital images. The methodology is articulated in a number of successive steps: an initial process of motion detection recognises human targets into the examined scene; subsequently, a synthetic representation of the previously detected human figures is obtained in form of skeleton, by means of a thinning operator. Finally, the pose estimation step is performed on the basis of a geometrical analysis conducted over a set of features related to the extracted skeletons. Experimental evidence of the appropriateness of the overall methodology is also presented.
1577283
Real-time illumination compensation for face processing in video surveillance###Face processing under illumination variations from video has long been considered as an important and still challenging research issue in video surveillance. In this paper, we propose a real-time pre-processing system to compensate illumination for face processing by using scene lighting modeling. Our contribution lies in the system capability of accommodating multiple local light sources and efficient lighting matching mechanism. Furthermore it can enhance the performance of face processing under both non-standard global and local illumination condition while still maintaining reasonable computing burden for real-time video surveillance. By verifications from face detection results with customized test video clips and public face detection database, the performance of our system outperforms other illumination compensation techniques. This performance improvement in turn will benefit the following face recognition or tracking.
1577282
Viseme recognition - a comparative study###Three classification algorithms for visual mouth appearances (visemes) which correspond to phonemes and their speech contexts, were compared w.rt. recognition rate, time complexity, and ROC performance. Two feature extraction procedures were verified. The first one is based on the normalized triangle MESH covering mouth area and the color image texture vector indexed by barycentric coordinates. The second procedure performs DFT on the image rectangle including mouth w.rt. small blocks of DFT coefficients. The classifiers has been designed by PCA approach and by the optimized LDA method which uses two singular subspaces approach. It appears that DFT+LDA exhibits higher recognition rate than MESH+LDA and MESH+PCA methods - 97.6% versus 94.4 and 90.2%, respectively. It is also much faster than MESH+PCA (5 ms per one video frame versus 26 ms on Pentium IV, 3.2 GHz) and slower than MESH+LDA (5 ms versus 1 ms).
1577289
Enhancing face recognition from video sequences using robust statistics###The aim of this work is to investigate a way of enhancing the performance of face recognition from video sequences by selecting only well-framed face images from those extracted from video sequences. It is known that noisy face images (e.g. not well-centered, non-frontal poses...) significantly reduce the performance of face recognition methods, and therefore, need to be filtered out during the training and the recognition. The proposed method is based on robust statistics, and more precisely, a recently proposed robust high-dimensional data analysis method, RobPCA. Experiments show that this filtering procedure improves the recognition rate by 10 to 20%.
1577288
IBM smart surveillance system (S3): a open and extensible framework for event based surveillance###As smart surveillance technology becomes a critical component in security infrastructures, the system architecture assumes a critical importance. This paper considers the example of smart surveillance in an airport environment. We start with a threat model for airports and use this to derive the security requirements. These requirements are used to motivate an open-standards based architecture for surveillance. We discuss the critical aspects of this architecture and its implementation in the IBM S3 smart surveillance system. Demo results from a pilot deployment in Hawthorne, NY are presented.
1577343
Classification of smart video surveillance systems for commercial applications###Video surveillance has a large market as the number of installed cameras around us can show. There are immediate commercial needs for smart video surveillance systems that can make use of the existing camera network (e.g. CCTV) for more intelligent security systems and to contribute in more applications (beside or) rather than security applications. This work introduces a new classification for smart video surveillance systems depending on their commercial applications. This paper highlights different links between the research and the commercial applications. The work reported here has both research and commercial motivations. Our goals are first to define a generic model of smart video surveillance systems that can meet requirements of strong commercial applications. Our second goal is to categorize different smart video surveillance applications and to relate capabilities of computer vision algorithms to the requirement of commercial application.
1577292
Normalized radial basis function networks and bilinear discriminant analysis for face recognition###In this paper, we present a novel approach for face recognition, using a new subspace method called bilinear discriminant analysis (BDA) and normalized radial basis function networks (NRBFNs). In a first step, BDA extracts the features that enhance separation between classes by using a generalized bilinear projection-based Fisher criterion, computed from image matrices directly. In a second step, the features are fed into a NRBFN that learns class conditional probabilities. This results in an efficient and computationally simple open-world identification process. Experimental results assess the performance and robustness of the proposed algorithm compared to other subspace methods combined with NRBFNs, in the presence of variations in head poses, facial expressions, and partial occlusions.
1577293
Facial feature extraction using a cascade of model-based algorithms###We present a cascaded framework for robust and accurate facial feature extraction. In this framework, we propose the following three model-based algorithms: (1) constrained global deformation using a sparse feature representation; (2) component texture fitting using direct parameter estimation by SVR, and (3) component feature refinement by direct optimization. The algorithms capture different characteristics of facial features, giving various extraction performances in terms of robustness (convergence) and accuracy. To achieve both high accuracy and robustness, we cascade these algorithms into a chain, where each algorithm progressively 'pulls' the model closer to the correct position. Experiments show that the combined algorithm achieves a large convergence area and high accuracy.
1577290
Recognizing facial expressions at low resolution###This paper focuses on recognizing facial expressions at low resolution. We introduce local binary patterns (LBP) as novel low-computation discriminative features for low-resolution facial expression recognition. Compared to Gabor wavelets, LBP features can be derived rapidly in a single scan of raw images, whilst still retaining enough facial information in a compact representation. Support vector machine (SVM) is adopted to classify facial expressions. Extensive experiments on the Cohn-Kanade database demonstrate that the LBP features are effective and efficient for facial expression recognition, and crucially perform robustly and stably over a useful range of low resolutions. Our method yields promising performance when processing compressed low-resolution video sequences from the PETS 2003 dataset.
1577291
Dual LDA - an effective feature space reduction method for face recognition###Linear discriminant analysis (LDA) is a popular feature extraction technique that aims at creating a feature set of enhanced discriminatory power. The authors introduced a novel approach dual LDA (DLDA) and proposed an efficient SVD-based implementation. This paper focuses on feature space reduction aspect of DLDA achieved in course of proper choice of the parameters controlling the DLDA algorithm. The comparative experiments conducted on a collection of five facial databases consisting in total of more than 10000 photos show that DLDA outperforms by a great margin the methods reducing the feature space by means of feature subset selection.
1577296
Heuristic approach for license plate detection###The license plate detection is one of the most important processes in license plate recognition (LPR) system. A number of techniques have been proposed in research literatures. Among the most promising techniques is text locating-based technique. However, in a complex scene the technique creates too many candidate regions with noisy background which result in segmentation difficulty. Toward the text locating approach, this paper presents a new license plate detection and segmentation technique. Improving on the existing technique, it creates cleaner connected regions by using our new morphological approach. The searching and segmentation technique proposed here is also efficient for this very application.
1577297
A texture-based approach for shadow detection###Shadows detection is a fundamental step in visual surveillance and monitoring systems. Shadow points are often misclassified as object points causing errors in localization, segmentation, measurements, tracking and classification of moving objects. In order to detect potential shadow points an automatic segmentation procedure is performed and, for all moving pixels, the approach evaluates the compatibility of photometric properties with shadow characteristics. The approach is improved using a new method focused on the similarity between little textured patches: this method is based on the observation that shadow regions present same textural characteristics in each frame of the gray-level video-sequence and in the corresponding adaptive background model. We suggest a new approach to describe textural information in terms of redundant functions. The algorithm is designed to be unaffected by scene type, background type or light conditions. Results validate the algorithm 's performance on a benchmark suite of indoor and outdoor video sequences.
1577294
Physiology-based face recognition###We present a novel approach for face recognition based on the physiological information extracted from thermal facial images. First, we delineate the human face from the background using a Bayesian method. Then, we extract the blood vessels present on the segmented facial tissue using image morphology. The extracted vascular network produces contour shapes that are unique for each individual. The branching points of the skeletonized vascular network are referred to as thermal minutia points (TMPs). These are reminiscent of the minutia points produced in fingerprint recognition techniques. During the classification stage, local and global structures of TMPs extracted from test images are matched with those of database images. We have conducted experiments on a large database of thermal facial images collected in our lab. The good experimental results show that our proposed approach has merit and promise.
1577295
Studying skin ageing through wavelet-based analysis of capacitive images###The skin care retains a great importance for both aesthetics and health. Nowadays, many different approaches are known to quantify the skin health status by analyzing the skin appearance. However, most of these methods are still grounded on surface replicas, or on the use of devices that are not suitable for a routine approach. Also not all the methods are designed to achieve results in an automatic manner. The work presented here describes a method to extract an age-related feature from high resolution capacitive map of the human skin achieved by a portable device. Skin surface samples of 87 subjects have been analyzed in vivo and automatically through using wavelet decomposition. After that samples have been enhanced, we devised a feature, which correspond to the energy of the wavelet coefficients at the finest scale. Experiments prove that the feature we extracted is linearly related to skin ageing.
1577340
Surveillance video for mobile devices###In this paper, we present a video encoding scheme that uses object-based adaptation to deliver surveillance video to mobile devices. The method relies on a set of complementary video adaptation strategies and generates content that matches various appliance and network resources. Prior to encoding, some of the adaptation strategies exploit video object segmentation and selective filtering in order to improve the perceived quality. Moreover, object segmentation enables the generation of automatic summaries and of simplified versions of the monitored scene. The performance of individual adaptation strategies is assessed using an objective video quality metric, which is also used to select the strategy that provides maximum value for the user under a given set of constraints. We demonstrate the effectiveness of the scheme on standard surveillance test sequences and realistic mobile client resource profiles.
1577341
Detecting retail events using moving edges###We present a moving object recognition system based on the characteristics of the object's edges. Our approach is formulated as an edge detection problem within two consecutive frames of a video sequence. The framework is evaluated in a retail environment for detecting dollies entering or leaving the back door of a store and in opening or closing a cashier's cash drawer. The system is trained manually with pre-recorded video sequence of a dolly entering a building and a cash drawer opening and closing. Once trained, the system is shown to be able to detect dollies and cash drawer actions reliably. The framework can be used to detect objects of any defined edge characteristics as a part of an event detection system for small retail businesses.
1577298
A gradient-based foreground detection technique for object tracking in a traffic monitoring system###Moving object detection is an important process in video surveillance and monitoring system. A conventional approach to moving object detection in video surveillance application is background subtraction. Information about background can be determined by various techniques. However, many existing background modelling techniques suffer in uncontrolled environments. This paper presents a new background modelling approach based on edge information. The proposed approach is robust to changes in outdoor environments where light can change randomly. Furthermore, edges require significantly less computing resource and result in faster processing time relative to intensity-based approaches. Experimental results show that, compared to intensity-based approaches in outdoor environments, high detection accuracy has been achieved with significantly less computing power.
1577299
Real-time video segmentation###In this article we present a real time algorithm for detecting moving objects in a video sequence taken with a fixed camera. When a background estimation is known, the algorithm is able to detect moving objects and locates them approximately. The method is based on a comparison between each image and the background. We use an a contrario model, assuming that moving objects yield locally major changes in the topographic map. Experimental results show that the algorithm is very robust to noise and to the background estimation. Moreover, the algorithm needs few parameters, which are easy to estimate.
1577344
An efficient motion-adaption de-interlacing technique on VLIW DSP architecture###This paper presents an efficient motion-adaptive deinterlacing method based on edge-based liner average (ELA) and temporal adaptive interpolation. The pixel in the missing field is classified into static and moving area. If a pixel is located in the static area, the information in the adjacent field with the same parity is used. If a pixel is located in the moving area, ELA is deployed intra field. Experimental results show that the performance of the proposed method is superior to the line-averaging and ELA method both objectively and subjectively. Moreover, our algorithm is tailored for VLIW DSP architecture and thus requires very low computational complexity.
1577345
Understanding of human motion, actions and interactions###Summary form only given. The efforts to develop computer systems able to detect humans and recognize their activities form an important area of research in computer vision today. The recognition of human activities will lead to a number of applications, including personal assistants, virtual reality, smart monitoring and surveillance systems, as well as motion analysis in sports, medicine and choreography. Motion is an important cue for the human visual system and for understanding human actions. It has been the subject of intense study in a number of fields including philosophy, psychology and neurobiology and, of course, computer vision, robotics and computer graphics. In computer vision research, motion has played an important role for the past thirty years. Prof. Aggarwal's interest in motion started with the study of motion of rigid planar objects and gradually progressed to the study of human motion. The current research includes the study of interactions at the gross (blob) level and at the detailed (head, torso, arms and legs) level. The two levels present different problems in terms of observation and analysis. For blob level analysis, we use a modified Hough transform called the temporal spatio-velocity transform to isolate pixels with similar velocity profiles. For the detailed-level analysis, we employ a multi-target, multi-assignment strategy to track blobs in consecutive frames. An event hierarchy consisting of pose, gesture, action and interaction are used to describe human-human interaction. A methodology is developed to describe the interaction at the semantic level. Professor Aggarwal's presentation will focus on the contributions from other fields leading to the study of motion in computer vision. Further, it will address the issues of interactions at the blob level and at the detailed level. In addition, it will address the directions of future research in motion and human activity recognition.
1577317
Gradient based multifocus video image fusion###Optics of lenses with a high degree of magnification suffer from the problem of a limited depth of field. The larger the focal length and magnification of the lens the smaller the depth of field becomes. As a result, fewer objects in the image are in focus. Multifocus digital image fusion attempts to increase the apparent depth of field through the fusion of object within several different fields of focus. In this work a novel multifocus video image fusion algorithm is proposed. Our unique approach requires orders of magnitude fewer calculations than all other known multifocus video image fusion algorithms.
1577316
An integrated surveillance system for outdoor security###An integrated system for the detection, active tracking and recognition of people in wide outdoor environments is hereafter discussed. Specifically, a static sensor with a wide view is used to detect people inside the environment and to classify their behaviours. As outcome of anomalous activities, an active camera is selected to focus its attention on a particular person. Here, techniques for face detection are employed to determine a region of interest where to extract features used by a tracking algorithm for an autonomous gaze of a PTZ camera. Finally, a face recognition phase is considered to recognize the person of interest. Results show how the integrated system is able to detect, track and recognise people inside a tough environment such as a parking lot.
1577342
Evaluating the performance of systems for tracking football players and ball###In this paper, we discuss the different approaches used for evaluating the results of tracking algorithms, and in particular for analysis of football (soccer) tracking results. The focus of the study is on systems with multiple static cameras. The appropriate data representation and ground truth capture methods are discussed, and evaluation measures that indicate the performance of any given automatic tracker are presented. The evaluation method is demonstrated to compare results of an implemented multi-camera tracker.
1577269
Human posture recognition using active contours and radial basis function neural network###In this paper an automated video surveillance system for human posture recognition using active contours and neural networks is presented. Localization of moving objects in the scene and human posture estimation are key features of the proposed architecture. The system architecture consists of five sequential modules that include the moving target detection process, two levels of segmentation process for interested element localization, features extraction of the object shape and a human posture classification system based on the radial basis functions neural network. Moving objects are detected by using an adaptive background subtraction method with an automatic background adaptation speed parameter and a new fast gradient vector flow snake algorithm for the elements segmentation is proposed. The developed system has been tested for the classification of three different postures such as standing, bending and squatting considering different kinds of feature. Results are promising and the architecture is also useful for the discrimination of human activities.
1577268
Hypovigilence analysis: open or closed eye or mouth? Blinking or yawning frequency?###This paper proposes a frequency method to estimate the state open or closed of eye and mouth and to detect associated motion events such as blinking and yawning. The context of that work is the detection of hypovigilence state of a user such as a driver, a pilot. In A. Benoit and Caplier (2005) we proposed a method for motion detection and estimation which is based on the processing achieved by the human visual system. The motion analysis algorithm the filtering step occurring at the retina level and the analysis done at the visual cortex level. This method is used to estimate the motion of eye and mouth: blinking is related to fast vertical motion of the eyelid and yawning is related to large vertical mouth opening. The detection of the open or closed state of the feature is based on the analysis of the total energy of the image at the output of the retina filter: this energy is higher for open features. The absolute level of energy associated to a specific state being different from a person to another and for different illumination conditions, the energy level associated to each state open or closed is adaptive and is updated each time a motion event (blinking or yawning) is detected. No constraint about motion is required. The system is working in real time and under all type of lighting conditions since the retina filtering is able to cope with illumination variations. This allows to estimate blinking and yawning frequencies which are clues of hypovigilance.
1577267
Performance evaluation of event detection solutions: the CREDS experience###In video surveillance projects, automatic and real-time event detection solutions are required to guarantee an efficient and cost-effective use of the infrastructure. Many solutions have been proposed to automatically detect a variety of events of interest. However, not all solutions and technologies may satisfy all the requirements of the surveillance scenario. For this reason, performance evaluation of existing event detection solutions becomes an important step in the deployment of video surveillance projects. In this paper, we propose a practical approach that aims at minimizing the ground truth generation problem and the expertise required to evaluate and compare the results by introducing specific requirements of specific event detection scenarios. This approach is believed to be applicable for an initial evaluation of candidate solutions to a specific surveillance scenario before more exhaustive tests in an integrated environment. The proposed method is under evaluation in the framework of the challenge of real-time event detection solutions (CREDS).
1577266
Automatic detection of dangerous events for underground surveillance###This paper describes automatic video sequences processing techniques for detecting suspect and dangerous situations within public transportations. Proposed surveillance system is able to raise different kind of warnings and alarms on the basis of the particular detected situation. Algorithms used for objects detection and tracking will be described in details and performances will be discussed in relation with alarm conditions that are showed in the sequences that have been made available for this conference. An empty reference image is used for object extraction through image difference. In order to perform background updating a high level module is implemented taking into account the detected objects and their classification tags. The system has been tested on several sequences showing dangerous events due to human behaviors in an underground station.
1577265
A real time surveillance system for metropolitan railways###This paper presents a real time surveillance system that can be deployed within public transport environments. The system is a fully customisable application that can be used to address the requirements for this application domain. The system has been under trial on a number of metropolitan railway systems in the UK and Italy. In this paper we discuss how some of the algorithms employed within the system can be adapted for use with the CREDS datasets.
1577264
Target segmentation and event detection at video-rate: the EAGLE project###In this paper we present the EAGLE system: new modular, two-layer object detection and tracking system for static camera situations. The first, low-level layer provides feature extraction and tracking capabilities. The second, high-level layer exploits this information using techniques borrowed from artificial intelligence; its flexible architecture is easily adaptable to different surveillance situations and allows for event detection raising (user defined) warnings and alarms. EAGLE uses intelligent scene observation in order to evaluate interaction with user-defined landmarks instead of probabilistic trajectory estimation. The often unpredictable behavior of humans in motion had us abandon that feature. EAGLE needs no detection areas and has the ability to do "warm starts", i.e., start tracking with targets already present in the scene. With this paper we intend to participate in the CREDS competition.
1577263
Metro railway security algorithms with real world experience adapted to the RATP dataset###SISELL experimented during six month an underground railway intrusion detection system in a real metro environment in Lyon. Our algorithms have been adapted to fit the Lyon metro configuration, got improved and gained a real world experience. This article presents the implementation of these methods on the CREDS dataset.
1577262
A track-based human movement analysis and privacy protection system adaptive to environmental contexts###This paper presents a track-based system for human movement analysis and privacy protection. Our system is adaptive to environmental contexts such as illumination variations, complex moving cast shadows, different camera perspectives, and diverse sue scenarios. Most of outdoor surveillance systems have been targeting at specific environmental situation: i.e., specific time, place, and activity scenarios. We address that more general human movement analysis systems should be able to handle multiple heterogeneous situations in an adaptive manner. We introduce the concept of "spatio-temporal personal boundary" to represent different grouping patterns of human tracks, and we incorporate the concept with various site models. Experimental evaluations with extensive outdoor data show our system's robustness to environmental changes and effectiveness to properly handle various environmental contexts.
1577261
Tracking by cluster analysis of feature points using a mixture particle filter###A moving target produces a coherent cluster of feature points in the image plane. This motivates our novel method of tracking multiple targets via feature points. First, the Harris corner detector and the Lucas-Kanade tracker are applied in each frame to detect feature points and their associated velocities. Points that are both spatially co-located and exhibit similar motion are grouped into clusters. Due to the non-Gaussian distribution of the points in a cluster and the multi-modality resulting from multiple targets, a special particle filter, the mixture particle filter, is adopted to model the mixture point distribution over time. Each cluster is treated as a mixture component and is modeled by an individual particle filter. The filters in the mixture are instantiated and initialized by applying the EM algorithm, are reclustered by merging overlapping clusters and splitting spatially disjoint clusters, and are terminated when their component weights drop below a threshold. The advantage of using mixture particle filtering is that it is capable of tracking multiple targets simultaneously and also of handling appearing and disappearing targets. We demonstrate the effectiveness of our method on different PETS datasets.
1577260
Object tracking using color interest points###This paper presents a new approach for tracking objects in complex situations such as people in a crowd or players on a soccer field. Each object in the image is represented by several interest points (IPs). These IPs are obtained using a color version of the Harris IP detector. Each IP is characterized by the local appearance (chromatic first-order local jet) of the object and by geometric parameters. We track objects by matching IPs from image to image based on the Mahalanobis distance. The approach is robust to occlusion. Performance is illustrated by some examples.
1577319
Stereo vision based human body detection from a localized mobile robot###Autonomous surveillance and monitoring of structures is one of the most studied tasks in the past years. In this paper we present an approach in mobile robotic surveillance to detect the presence of people or other moving objects in scenario and classify them as human body and not human body by stereo vision.
1577318
A modular multi-camera framework for team sports tracking###This article presents a modular architecture for multicamera tracking in the context of sports broadcasting. For each video stream, a geometrical module continuously performs the image-to-model homography estimation. A local-feature based tracking module tracks the players in each view. A supervisor module collects, associates and fuses the data provided by the tracking modules. The originality of the proposed system is three-fold. First, it allows to localize the targets on the ground with rotating and zooming cameras; second, it does not use background modeling techniques; and third, the local tracking can cope with severe occlusions. We present experimental results on raw TV-camera footage of a soccer game.
1577278
Multi-modal face image super-resolutions in tensor space###Face images of non-frontal views under poor illumination with low resolution reduce dramatically face recognition accuracy. To overcome these problems, super-resolution techniques can be exploited. In this paper, we present a Bayesian framework to perform multi-modal (such as variations in viewpoint and illumination) face image super-resolutions in tensor space. Given a single modal low-resolution face image, we benefit from the multiple factor interactions of training tensor, and super-resolve its high-resolution reconstructions across different modalities. Instead of performing pixel-domain super-resolutions, we reconstruct the high-resolution face images by computing a maximum likelihood identity parameter vector in high-resolution tensor space. Experiments show promising results of multi-view and multi-illumination face image super-resolutions respectively.
1577279
Facial feature extraction by kernel independent component analysis###In this paper, we introduce a new feature representation method for face recognition. The proposed method, referred as kernel ICA, combines the strengths of the kernel and independent component analysis (ICA) approaches. For performing kernel ICA, we employ an algorithm developed by F. R. Bach and M. I. Jordan. This algorithm has proven successful for separating randomly mixed auditory signals, but it has never been applied on bidimensional signals such as images. We compare the performance of kernel ICA with classical algorithms such as PCA and ICA within the context of appearance-based face recognition problem using the FERET and ORL databases. Experimental results show that both kernel ICA and ICA representations are superior to representations based on PCA for recognizing faces across days and changes in expressions.
1577274
A novel method for graffiti detection using change detection algorithm###In recent decades vandal acts and graffiti drawing problem have increased and have required a lot of public funding. To face this problem the communal administrations have invested in automatic video surveillance systems. To deal with this problem through image processing techniques, this paper presents a method for graffiti detection based on change detection algorithm and motion vector. The aim of this system is to detect the graffiti painting act while people are going to draw, identify them and distinguish the drawer.
1577275
A novel scheme of face verification using active appearance models###Face verification and face identification are two main applications for face recognition. Based on the face representation which they use, the current image-based face recognition techniques can be roughly classified into two groups: appearance-based methods and model-based methods. The method presented in this paper focuses on applying model-based methods to face verification. Unfortunately, the existing current model-based schemes are used for the applications of face identification and are not suitable for face verification. A novel scheme, which is custom-built for face verification applications, is therefore proposed in this paper. Active appearance model, a 2D morphable face model, is chosen and applied to realize the proposed scheme.
1577276
A hybrid technique for face detection in color images###In this paper, a hybrid technique for face detection in color images is presented. The proposed technique combines three analysis models, namely skin detection, automatic eye localization, and appearance-based face/nonface classification. Using a robust histogram-based skin detection model, skin-like pixels are first identified in the RGB color space. Based on this, face bounding-boxes are extracted from the image. On detecting a face bounding-box, approximate positions of the candidate mouth feature points are identified using the redness property of image pixels. A region-based eye localization step, based on the detected mouth feature points, is then applied to face bounding-boxes to locate possible eye feature points in the image. Based on the distance between the detected eye feature points, face/non-face classification is performed over a normalized search area using the Bayesian discriminating feature (BDF) analysis method. Some subjective evaluation results are presented on images taken using digital cameras and a Webcam, representing both indoor and outdoor scenes.
1577277
A fast and memory efficient approach for fingerprint authentication system###It is still a challenge to integrate a biometrics solution such as fingerprint matching into a smart card. However, current generation of smart card is usually equipped with an 8- or 16-bit microcontroller which has limitations on hardware resources. In this paper, we present our approaches to reduce memory requirement for storing image buffer and to reduce the image processing time. Also, we show the advantages of using line extraction scheme to reduce the size of the accumulator array and to speed up the matching process. The proposed method contains more information per bit than the conventional method that can be embedded in smart cards for a real-time match-on-card system implementation. Furthermore, optimization in platform level offers feasibility of code integration into a low memory budget platform. An example of fingerprint identification implementation on a DSP platform with limited memory budget is presented to show effectiveness of our approach.
1577270
Human height prediction and roads estimation for advanced video surveillance systems###This work is aimed at automatically learning the three-dimensional structure of an outdoor scene observed by a single uncalibrated video camera. In particular, we are proposing to estimate the 3D layout of roads and paths traveled by pedestrians by observing the pedestrians and to estimate the road parameters from their height and position in a video sequence. The developed algorithm has been implemented and was successfully tested in different environment including scene luminance variation during a day, possible mistakes in pedestrian detection, road coverage variation during a year. Proposed algorithm for 3D road map estimation (up to a scale factor) can be used in video surveillance applications to classify people on the scene by their heights, to detect human abnormal trajectories, for human gait analysis, for people traffic analysis and in other applications that require automatic roads estimation and human height prediction. This algorithm can be one of building block for advanced video surveillance systems.
1577271
VidMAP: video monitoring of activity with Prolog###This paper describes the architecture of a visual surveillance system that combines real time computer vision algorithms with logic programming to represent and recognize activities involving interactions amongst people, packages and the environments through which they move. The low level computer vision algorithms log primitive events of interest as observed facts, while the higher level Prolog based reasoning engine uses these facts in conjunction with predefined rules to recognize various activities in the input video streams. The system is illustrated in action on a multi-camera surveillance scenario that includes both security and safety violations.
1577272
Shape recognition based on a video and multi-sensor system###We present in this paper a real-time system for shape recognition. The proposed system is a video and multi-sensor platform that is able to classify the mobile objects evolving in the scene into several expected categories. The key of the recognition method is to compute mobile object properties thanks to the camera and sensors and then to use Bayesian classifiers. A learning phase based on ground truth data is used to train the Bayesian classifiers. Our recognition method has been integrated into an existing access control device used in public transportation (subway) at RATP (Regie Autonome des Transports Parisiens) to improve safety and comfort, to prevent fraud and to count people for statistical matters. The expected categories in this case are mainly "adult", "child", "suitcase" and "two adults close to each other".
1577273
Online appearance learning by template prediction###A new object tracking framework with online appearance learning ability is proposed in this paper. The object appearances are modeled as a set of probability mass functions (PMF), defined as "object-model-set". The averaged object appearance in the video is also modeled as a PMF, named as "universal model". Given an initial template of the target object, which is the only element in the initial object-model-set, the framework tries to track the object by looking into the whole input video sequence. The dynamic programming (DP) is applied to achieve a best spatial-scale matching between the observations and the current model set, across the whole input video. The object-model-set is iteratively updated if the prediction of the matched image patch using current object-model-set is less than its prior computed using universal model. The PMFs of such matched image patches are added into the object-model-set. Thus the object appearance, which is modeled as the set of PMFs of typical views, is learned online. The tracking results can be further refined given the updated object-model-set. This make the proposed tracking framework robust to the appearance variation caused by 3D motion, partial occlusion and illumination. Also, the learned typical views facilitate other vision tasks such as recognition or 3D reconstruction. Tracking results and the learned typical view on the challenging video sequence experimentally show the robustness and strong online learning ability of the proposed frame work.
1577249
Entry edge of field of view for multi-camera tracking in distributed video surveillance###Efficient solution to people tracking in distributed video surveillance is requested to monitor crowded and large environments. This paper proposes a novel use of the entry edges of field of view (E<sup>2</sup>oFoV) to solve the consistent labeling problem between partially overlapped views. An automatic and reliable procedure allows obtaining the homographic transformation between two overlapped views, without any manual calibration of the cameras. Through the homography, the consistent labeling is established each time a new track is detected in one of the cameras. A camera transition graph (CTG) is defined to speed up the establishment process by reducing the search space. Experimental results prove the effectiveness of the proposed solution also in challenging conditions.
1577248
Coarse-to-fine strategy for robust and efficient change detectors###We present a novel approach to change detection based on a coarse-to-fine strategy. An efficient coarse-level detection is proposed that filters out most of the possible false changes, thus attaining reliable and tight coarse-grain super-masks of the truly changed areas. The subsequent fine-level detection can thus "focus the attention" just on the "interesting" parts of the frame and perform a robust selective background updating procedure by considering the complement of these masks. Besides, the analysis of a strip of pixels surrounding each coarse-grain blob allows to infer information on light changes possibly occurring in the blob's vicinity. Although any algorithm can be used as the final fine-level detection, here we show how the approach applies to a particular algorithm we devised, based on a non-parametric statistical modelling of the camera noise.
1577315
Integrating multi-camera tracking into a dynamic task allocation system for smart cameras###This paper reports on the integration of multi-camera tracking into an agent-based framework, which features autonomous task allocation for smart cameras targeting traffic surveillance. Since our target platforms are distributed embedded systems with limited resources, the trackers may only be active, if the target is in the camera's field of view. Consequently, the tracking algorithm has to migrate from camera to camera in order to follow the target, whereas the decision when and whereto the migration takes place is reached autonomously by the tracker. Consequently, no central control host is required. We further present different strategies on when to migrate a tracker, and how to determine the camera which observes the tracked object subsequently. We have realized the tracker's control by using heterogeneous mobile agents, which employ a state-of-the-art tracking algorithm for tracking. The tracking system has been implemented on our smart cameras (SmartCam) which are comprised of a network processor and several digital signal processors (DSPs) and provide a complex software framework.
1577314
Rank-based multisensory fusion in multitarget video tracking###An attractive approach to improve tracking performance for visual surveillance is to use information from multiple visual sensory cues such as position, color, shape, etc. Previous work in fusion for tracking has tended to focus on fusion by numerically combining the scores assigned by each cue. We argue that for video scenes with many targets in a crowded situation, the splitting and merging of regions associated with targets, and the subsequent dramatic changes in cue values and reliabilities, renders this form of fusion less effective. In this paper we present experimental results showing that use of cue rank information in fusion produces a significantly better tracking result in crowded scenes. We also present a formalization of this fusion problem as a step in understanding why this effect occurs and how to build a tracking system that exploits it.
1577313
Frame-level temporal calibration of video sequences from unsynchronized cameras by using projective invariants###This paper describes a new method for temporally calibrating multiple cameras by image processing operations. Existing multi-camera algorithms assume that the input sequences are synchronized either by genlock or by time stamp information and a centralized server. Yet, hardware-based synchronization increases installation cost. Hence, using image information is necessary to align frames from the cameras whose clocks are not synchronized. Our method uses image processing to find the frame offset between sequences so that they can be aligned. We track foreground objects, extract a point of interest for each object as its current location, and find the corresponding location of the object in the other sequence by using projective invariants in P<sup>2</sup>. Our algorithm recovers the frame offset by matching the tracks in different views, and finding the most reliable match out of the possible track pairs. This method does not require information about intrinsic or extrinsic camera parameters, and thanks to information obtained from multiple tracks, is robust to possible errors in background subtraction or location extraction. We present results on different sequences from the PETS2001 database, which show the robustness of the algorithm in recovering the frame offset.
1577312
Collective calibration of active camera groups###Until recently, traditional approaches to the task of camera calibration have relied on the use of accurate grid patterns, or strategically placed targets. Such approaches can prove time consuming and often require expert supervision. For ambient intelligence type applications, it is unwise to rely on the consistency of camera positions and orientations; consequently a fully autonomous camera calibration procedure is preferred. In this paper we present an auto-calibration system for the estimation of the extrinsic properties of active cameras lying within indoor, self-observable groups. Neither prior knowledge of camera locations, nor a calibration-pattern is required, just a few basic parameters concerning the physical appearance of the cameras. Groups of active cameras can be calibrated within minutes, by exploiting their precise control mechanisms. As no supervision is required, camera deployment configurations can be changed or new cameras added easily.
1577311
Dual-sensor camera for acquiring image sequences with different spatio-temporal resolution###In accordance with advances in camera technology, the requirement of high-quality video has greatly increased. Among the factors required for high-quality video are a high-resolution and a high frame rate. However, the limitation of the pixel transfer rate restricts compatibility of a high-resolution and a high frame rate in commercial camera. We propose a dual-sensor camera that consists of two cameras: one with a high-resolution and a low frame rate and the other with a low-resolution and a high frame rate. The system is capable of capturing two different image sequences: high-resolution images and high-frame-rate images. A sensor calibration for the dual-sensor camera is also proposed.
1577310
A robust facial feature tracking system###Facial feature tracking is crucial in computer vision applications. In this paper, we propose a system capable of locating a human face using skin color filtering and then detecting and tracking six facial features, i.e. pupils, nostrils and lip corners, in a real time video. A 3D facial feature model is employed to estimate the 3D pose of a person's head, which improves the robustness of the tracking system. This system has the advantage of automatically detecting the facial features and recovering the features lost during the tracking process. Encouraging results have been obtained using the proposed system.
1577241
Detecting and quantifying unusual interactions by correlating salient motion###A significant problem in scene interpretation is efficient bottom-up extraction and representation of salient features. In this paper, we address the problem of correlating salient motion at a spatio-temporal level and also across spatially separated regions since it is in the interactions that more sophisticated scene interpretation can be found. We show that it is possible to spatio-temporally locate and detect salient motion events and interactions in two contrasting scenarios using the same hierarchical co-occurrence framework. Thus generating a concise description of a dynamic scene from the sequence data alone. Results show it is possible to reduce a highly populated multi-dimensional co-occurrence matrix representing correlations between salient motion regions, to a one dimensional vector with clearly separable unusual activity. The results also show that the method inherently provides a quantifiable measure of the saliency of an interaction through its frequency of occurrence.
1577240
Trajectory clustering and its applications for video surveillance###In this paper we present a trajectory clustering method suited for video surveillance and monitoring systems. The clusters are dynamic and built in real-time as the trajectory data is acquired, without the need of an off-line processing step. We show how the obtained clusters can be successfully used both to give proper feedback to the low-level tracking system and to collect valuable information for the high-level event analysis modules.
1577243
Real-time change detection for surveillance in public transportation###The efficiency of event detection in video surveillance applications depends on the performance of the early stage of content change detection. However, this stage encounters difficulties deriving from the presence of noise in image acquisition devices. Furthermore, illumination variations in the surveyed scene tend to cause degradation in change detection results. This paper introduces a real-time statistic change detection technique which employs a block-based clustering procedure for the estimation of the noise model. The method is applied in conjunction with a brightness normalization stage for the suppression of ambient illumination variations. Additionally, an adaptation of the technique for real-time surveillance of subway environments is proposed.
1577242
Using local and global object's information to track vehicles in urban scenes###In intelligent transportation systems (ITS's) vehicle tracking is necessary to permit high-level analysis, such as vehicle counting or classification. Nowadays, the need for a precise vehicle behavior analysis is growing mainly in urban intersections. Typical urban traffic scenes contain high-cluttered areas where static and dynamic occlusions take place and objects are missed. Tracking systems relying on monocular cameras are widespread. However, often they are misled by the complicated object interactions occurring in those areas, thus yielding errors in the higher level modules. The real-time tracking system we have conceived relies on an algorithm exploiting local and global information from corner points and whole object's features that allows us to keep track of many different objects in challenging urban scenarios. We assess our results through extensive on-field testing by manually extracting the ground truth from different sequences taken by real world traffic monitoring systems.
1577245
Denoising image sequences does not require motion estimation###State of the art movie restoration methods either estimate motion and filter out the trajectories, or compensate the motion by an optical flow estimate and then filter out the compensated movie. Now, the motion estimation problem is ill posed. This fact is known as the aperture problem: trajectories are ambiguous since they could coincide with any promenade in the space-time isophote surface. In this paper, we try to show that, for denoising, the aperture problem can be taken advantage of. Indeed, by the aperture problem, many pixels in the neighboring frames are similar to the current pixel one wishes to denoise. Thus, denoising by an averaging process can use many more pixels than just the ones on a single trajectory. This observation leads to use for movies a recently introduced image denoising method, the NL-means algorithm. This static 3D algorithm outperforms motion compensated algorithms, as it does not lose movie details. It involves the whole movie isophote and not just a trajectory.
1577244
Scene modelling using an adaptive mixture of Gaussians in colour and space###We present an integrated pixel segmentation and region tracking algorithm, designed for indoor environments. Visual monitoring systems often use frame differencing techniques to independently classify each image pixel as either foreground or background. Typically, this level of processing does not take account of the global image structure, resulting in frequent misclassification. We use an adaptive Gaussian mixture model in colour and space to represent background and foreground regions of the scene. This model is used to probabilistically classify observed pixel values, incorporating the global scene structure into pixel-level segmentation. We evaluate our system over 4 sequences and show that it successfully segments foreground pixels and tracks major foreground regions as they move through the scene.
1577247
Object tracking and matting for a class of dynamic image-based representations###Image-based rendering (IBR) is an emerging technology for photo-realistic rendering of scenes from a collection of densely sampled images and videos. Recently, an object-based approach for a class of dynamic image-based representations called plenoptic videos was proposed. This paper proposes an automatic object tracking approach using the level-set method. Our tracking method, which utilizes both local and global features of the image sequences instead of global features exploited in previous approach, can achieve better tracking results for objects, especially with non-uniform energy distribution. Due to possible segmentation errors around object boundaries, natural matting with Bayesian approach is also incorporated into our system. Furthermore, a MPEG-4 like object-based algorithm is developed for compressing the plenoptic videos, which consist of the alpha maps, depth maps and textures of the segmented image-based objects from different video plenoptic streams. Experimental results show that satisfactory renderings can be obtained by the proposed approaches.
1577246
View registration using interesting segments of planar trajectories###We introduce a method for recovering the spatial and temporal alignment between two or more views of objects moving over a ground plane. Existing approaches either assume that the streams are globally synchronized, so that only solving the spatial alignment is needed, or that the temporal misalignment is small enough so that exhaustive search can be performed. In contrast, our approach can recover both the spatial and temporal alignment, regardless of their magnitude. We compute for each trajectory a number of interesting segments, and we use their description to form putative matches between trajectories. Each pair of corresponding interesting segments induces a temporal alignment, and defines an interval of common support across two views of an object that is used to recover the spatial alignment. Interesting segments and their descriptors are defined using algebraic projective invariants measured along the trajectories. Similarity between interesting segments is computed taking into account the statistics of such invariants. Candidate alignment parameters are verified by checking the consistency, in terms of the symmetric transfer error, of all the putative pairs of corresponding interesting segments. Experiments are conducted with two different sets of data, one with two views of an outdoor scene featuring moving people and cars, and one with four views of a laboratory sequence featuring moving radio-controlled cars.
1577256
Joint audio-video people tracking using belief theory###This paper is concerned with the use of belief theory to resolve the data association problem in the context of tracking and identifying people using audio and video data. In order to associate measurements with targets, the proposed method exploits different features such as color, position and acoustic parameters. This has the advantage of providing a robust solution to data association in challenging tracking scenarios.
1577257
Human tracking in real-time video for varying illumination###Tracking objects or humans using background subtraction is commonly used both in indoor and outdoor environment. But this method may not produce quality results due to illumination change, shadows, and occlusion occurred in indoor or outdoor environments. Song and Nevatia suggested a simultaneous tracking of face and body for human tracking in an indoor environment using Adaboost face detection and Camshift color tracking methods (X. Song and R. Nevatia, 2004). Changes in illumination are not considered in their work. In this research, an intelligent method for color tracking scheme using skin reflectance values is proposed to track the human in real-time video for varying illuminations both in indoor and outdoor environments. This research finds application in the live transmission of an indoor video conference or a live news cast from an outdoor as well as in the places where the illumination change occurs frequently.
1577254
Multiple object tracking using elastic matching###A novel region-based multiple object tracking framework based on Kalman filtering and elastic matching is proposed. The proposed Kalman filtering-elastic matching model is general in two significant ways. First, it is suitable for tracking of both, rigid and elastic objects. Second, it is suitable for tracking using both, fixed cameras and moving cameras since the method does not rely on background subtraction. The elastic matching algorithm exploits both the spectral features and structural features of the tracked objects, making it more robust and general in the context of object tracking. The proposed tracking framework can be viewed as a generalized Kalman filter where the elastic matching algorithm is used to measure the velocity field which is then approximated using B-spline surfaces. The control points of the B-spline surfaces are directly used as the tracking variables in a grid-based Kalman filtering model. The limitations of the Gaussian distribution assumption in the Kalman filter are overcome by the large capture range of the elastic matching algorithm. The B-spline approximation of the velocity field is used to update the spectral features of the tracked objects in the grid-based Kalman filter model. The dynamic nature of these spectral features are subsequently used to reason about occlusion. Experimental results on tracking of multiple objects in real-time video are presented.
1577255
Real time tracking of multiple persons using elementary tracks###We propose a real time tracking algorithm for a counting person application. Our algorithm needs any a priori knowledge neither on the model of person, nor on their size or their number, which can evolve with time. It manages several problems such as occlusion and under or over-segmentations especially thanks to a shape model obtained with a homography. The first step consisting in motion detection, leads to regions that have to be assigned to trajectories. This tracking step is achieved using a new concept: elementary tracks. They allow on the one hand to manage the tracking and on the other hand, to detect the output of occlusion by introducing coherent sets of regions. Those sets enable to define temporal kinematical, shape and colour models. Significant results will be presented on several sequences with ground truth.
1577252
Boosting particle filter-based eye tracker performance through adapted likelihood function to reflexions and light changes###In this paper we propose a log likelihood-ratio function of foreground and background models used in a particle filter to track the eye region in dark-bright pupil image sequences. This model fuses information from both dark and bright pupil images and their difference image into one model. The tracker overcomes the issues of prior selection of static thresholds during the detection of feature observations in the bright-dark difference images. The auto-initialization process is performed using cascaded classifier trained using adaboost and adapted to IR eye images. Experiments show good performance in challenging sequences with test subjects showing large head movements and under significant light changes.
1577253
A robust vehicle detection approach###Vehicle detection plays an important role in the intelligent transportation system. In this paper, we propose a novel approach which performs a spatio-temporal wavelet transform on videos to obtain motion information of vehicles. Different kinds of motion information extracted in sub-bands are combined to form an additive motion image. The additive motion image is then processed by adaptive thresholding, connected components labeling to segment moving region. The moving region is not accurate since the wavelet transform references many consecutive frames along temporal domain. We present a location calibration method to obtain precise moving regions of vehicles. The proposed approach is tolerant to cast shadow and camera vibration. Experimental videos are captured from roadway and expressway. Experimental results show high precision and recall rates.
1577250
Tracking motion objects in infrared videos###We propose motion detection and object tracking method that is particularly suitable for infrared videos. Detection of moving objects in infrared videos is based on changing texture in parts of the view field. We estimate the speed of texture change by measuring the spread of texture vectors in the texture space. This method allows us to robustly detect very fast and very slow moving object. Our theoretical and experimental results show that the proposed method significantly outperforms the Stauffer-Grimson approach based on Gaussian mixture model. We observe that the proposed method does not require any post-processing, which is a necessary step for the Stauffer-Grimson approach. Moreover, the object tracking is improved when based on the spatiotemporal texture blocks.
1577251
Look there! Predicting where to look for motion in an active camera network###A framework is proposed that answers the following question: if a moving object is observed by one camera in a pan-tilt-zoom (PTZ) camera network, what other camera(s) might be foveated on that object within a predefined time window, and what would be the corresponding PTZ parameter settings? No calibration is assumed, and there are no restrictions on camera placement or initial parameter settings. The framework accrues a predictive model over time. To start out, the cameras follow randomized "tours" in discretized PTZ space. If a moving object is detected in the field of view of more than one camera at a particular instant or within a predefined time window, then the model is updated to record the cameras' associations and the corresponding parameter settings. As more and more moving objects are observed, the model adapts and the most frequent associations are discovered. The formulation also allows for verification of its predictions, and reinforces its correct predictions. The system is demonstrated in observing people in an office environment with a three PTZ camera network.
1577258
Track matching over disjoint camera views based on an incremental major color spectrum histogram###Matching tracks from a single individual across disjoint camera views is a challenging task in video surveillance. In this paper, a major color spectrum histogram representation (MCSHR) is introduced to represent a moving object by using a normalized distance between two points in the RGB space. Then, an incremental MCSHR is proposed to cope with small pose changes and segmentation errors occurring along the track. Finally, a similarity measurement algorithm is proposed based on the incremental MCSHR to measure the similarity of any two tracked moving objects. The proposed similarity measurement algorithm proved capable of measuring the similarity of the two moving objects accurately. Experimental results show that with three to five frames integration, the proposed incremental MCSHR algorithm can make matching more robust and reliable than single-frame matching, especially for small pose changes. The matching performance is not obviously improved instead when the number of integration is more than five. The similarity of a same moving object in two different tracks has been improved from 92% to 95% with the integration number increased from three to five, while two different moving objects have been easily discriminated. The proposed algorithm can be used to match tracks from single individuals in camera networks, which do not provide full coverage of the monitored space.
1577259
Group stochastic search for object detection and tracking###A technique is presented for locating and tracking objects in cluttered environments. Agents are randomly distributed across the image, and subsequently grouped around targets. Each agent uses a weightless neural network and a histogram intersection technique to score its location. The system has been used to locate and track a head in 320&times;240 resolution video at up to 15 fps.
1577304
Features extraction and selection for emotional speech classification###The classification of emotional speech is a topic in speech recognition with more and more interest, and it has giant prospect in applications in a wide variety of fields. It is an important preparation for automatic classification and recognition of emotions to select a proper feature set as a description to the emotional speech, and to find a proper definition to the emotions in speech. The speech samples used in this paper come from Berlin database which contains 7 kinds of emotions, with 207 speech samples of male voice and 287 speech samples of female voice. A feature set of 50 potentially features is extracted and analyzed, and the best features are selected. A definition of emotions as 3-states emotions is also proposed in this paper.
1577305
A highly efficient block-based dynamic background model###A block-based dynamic background modelling technique featuring incremental update is presented, with the aim of increasing the sensitivity of background detection by considering the local connectivity of pixels. An accumulative model is maintained on-line by a heuristic algorithm to build up a statistical representation of a dynamic scene from a fixed camera view for foreground-background segmentation. The model is compared with a block-based technique employing cooccurrence [M. Seki et al., June 2003], and shown to be favourable in terms of both performance and conceptual simplicity. Using predominantly simple integer operations, the algorithm is highly amenable to direct implementation in hardware.
1577306
Colored visual tags: a robust approach for augmented reality###This paper presents a robust method for fast visual tags reading, suitable for augmented reality (AR) environments. Tag detection is based on well known tools of image-processing, but their combination, together with the use of colored markers, allows a robust recognition even with low-cost CMOS or CCD cameras and in poorly illuminated environments. In particular the color mix and the structure of the tag are quite unusual in common environments and can be easily detected with color filtering and geometric analysis. The proposed tag carries binary information encoded in its structure: in the presented implementation a 32-bit code with 12 parity bits is encoded in the tag but extensions to longer codes can be easily devised.
1577307
Wavelet packets and co-occurrence matrices for texture-based image segmentation###In this paper, a texture-based segmentation approach using wavelet packets, co-occurrence matrices and normalised modified histogram thresholding is discussed and developed. Background and objects in remotely sensed light detection and ranging (LIDAR) data are successfully partitioned into rivers, fields and residential areas using the developed algorithms. The issue of wavelet packet decomposition level is addressed by analysing the sub-images' energy and entropy. The standard deviation of the modified histogram, which is derived from the main diagonal of the sub-image's co-occurrence matrix, is used as a measure to evaluate the sub-images in terms of thresholdability. Finally, the segmentation results are presented.
1577300
An effective multi-stage background generation algorithm###In this paper we present a new background generation algorithm and show experimental results aimed at assessing its performance comparatively with respect to two other representative approaches. The algorithm is able to extract a stationary background from a short bootstrap sequence in which moving objects can also be present. The method works with pixel-wise temporal statistics and consists of three subsequent stages. The first two try to isolate for each pixel the stationary background process from the possible foreground processes due to the moving objects covering the pixel, thus voting the background process temporal median as the good background value. The third stage completes the background generation by means of a non-parametric statistical model of the temporal camera noise, inferred from the statistics computed in the previous stage.
1577301
Target-color learning and its detection for non-stationary scenes by nearest neighbor classification in the spatio-color space###We propose a method for detecting foreground objects in non-stationary scenes. The method can (1) detect arbitrary foreground objects without any prior knowledge of them, (2) identify background pixels under various changes in a background scene, and (3) detect minor difference between the background and target colors. Online detection is realized by the nearest neighbor classifier in the 5D xy-YUV space (the spatio-color space), consisting of the x and y coordinates of an image and Y, U, and V colors, which holds rectified training data of background colors and automatically learned target colors. We conducted experiments to confirm the effectiveness of our method.
1577302
Faster learning via optimised Adaboost###Adaboost has been found by many researchers to be an extremely successful classification algorithm. However, it is often stated that Adaboost takes a significant amount of time to learn a good classification. This paper aims to show that the Adaboost algorithm is not the cause of the slow learning. By altering how Adaboost is used, a significant increase in learning speed, over 14 times faster, can be achieved at the cost of a small loss in classification accuracy.
1577303
Resolution enhancement for video clips: tight frame approach###Video clip consists of frames, and each frame can be considered as a transformed picture of the reference frame. In this paper, we briefly discuss a framelet method for high-resolution image reconstruction to enhance the resolution of video clips. The detailed discussion can be found in R.H. Chan et al. (2005). Experiments on an actual video clip show that our method can provide information that are not discernable from the given video clip.
1577308
Shape reconstruction from two color images using photometric stereo combined with segmentation and stereopsis###Most objects in a scene of our interest in reconstructing their shapes may have colors on them. Existing photometric methods require at least three images with different light directions to reconstruct the shape. If accurate shapes are obtainable even from two images, the construction of such an observation system may be much easier and its operation may be much speedier. In this paper we combine our photometric stereo method with color segmentation and the binocular stereopsis. First, color segmentation is applied to the images and component shapes are reconstructed from the segmented images. Then, the feature points of the components are estimated using the stereopsis not only to put them together to get the whole shape but also to reconstruct the scene. Basic experimental results are presented.
1577309
Motion-based flexible camera registration###We outline our latest methods and algorithmic solutions for detection of concurrent motions and registering cameras in real-life surveillance systems. We show that cameras can be registered in several rather unfavorable conditions, based on: (1) unpredictable motion without structured background or defined object shapes or (2) walking persons of undefined silhouettes and short detectable walking distances or (3) shadows of undefined structures in front of flickering background. These methods are tested in real-life sequences and we show that flexible 3D camera registration is possible even in bad lighting conditions and in the lack of any known structures or motions.
1577331
A system to automatically monitor forbidden areas###Surveillance systems that automatically detect illegal behaviors performed by people unaware of the camera have a wide range of applications: security, healthcare, conservation of cultural heritage and so on. In particular the monitoring of museum and archaeological sites is one of the most challenging problems to be solved in order to avoid irreparable damages to historical heritage. In this paper a system able to check by common digital RGB cameras unexpected accesses to forbidden areas in a public museum is presented. The reliability of the proposed framework is shown by many experimental tests performed in the Messapic Museum of Egnathia (Italy).
1577330
Two-pass hexagonal algorithm with improved hashtable structure for motion estimation###This paper presents an improved two-pass hexagonal (TPA) algorithm constituted by linear hashtable motion estimation algorithm (LHMEA) and hexagonal search (HEXBS) for motion estimation. In the TPA, motion vectors (MV) are generated from the first-pass LHMEA and are used as predictors for second-pass HEXBS motion estimation, which only searches a small number of macroblocks (MBs). The hashtable structure of LHMEA is improved compared to the original TPA and LHMEA. The evaluation of the algorithm considers the three important metrics being processing time, compression rate and PSNR. The performance of the algorithm is evaluated by using standard video sequences and the results are compared to current algorithms.
1577333
Bit-rate control algorithm based on local image complexity for video coding with ROI###The bit-rate control algorithm for video sequence encoding with region of interest (ROI) is presented in this paper. The algorithm distributes available bit budget among image layers taking into consideration both the distance from ROI and the local complexity. It improves the image quality in ROI by lowering the image quality outside ROI with the preservation of the global constraint of the encoded stream bit-rate. The algorithm also ensures the gradual image quality degradation outside ROI.
1577332
Least squares motion estimation algorithm in the compressed DCT domain for H.26x/MPEG-x video sequences###A new compressed domain motion estimation algorithm that makes use of the DCT coefficients directly obtained from the H.26x or MPEG-x video stream is presented. The proposed algorithm is based on an iterative scheme that computes the new motion vectors by applying a least squares estimation technique. To reduce its computational effort, the algorithm may consider only an arbitrary subset of non- DCT coefficients. The performance of the algorithm was assessed in a DCT domain H.263 video transcoder, where the obtained motion vectors provided the means to significantly enhance the quality of the temporal prediction scheme with a consequent reduction of the required bit-rate.
1577335
Motion compensated refinement for low complexity pixel based distributed video coding###Distributed video coding (DVC) is a new coding paradigm that enables to exploit video statistics, partially or totally at the decoder. A particular case of DVC, Wyner-Ziv coding, deals with lossy source coding with side information at the decoder and allows a shift of complexity from the encoder to the decoder, theoretically without any penalty in the coding efficiency. The Wyner-Ziv solution here described encodes each video frame independently (intraframe coding), but decodes the same frame conditionally (interframe decoding). At the decoder, and compensation tools are responsible to obtain an accurate interpolation of the original frame using previously decoded (temporally adjacent) frames. This paper proposes a novel approach to improve the performance of pixel domain Wyner-Ziv video coding by using a motion compensated refinement of the decoded frame and use it as improved side information. More precisely, upon partial decoding of each frame, the decoder refines its motion trajectories in order to achieve a better reconstruction of the decoded frame.
1577334
An improved wavelet-based image watermarking technique###This paper proposes an adaptive blind image watermarking technique based on wavelet transform using a random sequence of real numbers. First, the image is decomposed into non overlapping blocks. Then, each block is classified as uniform or non uniform by using a JND-based classifier. The strength of the embedded watermark into the high subband coefficients of each transformed block depends upon the nature of the block according to its classification. The Neyman-Pearson criterion is used to derive the detection rule. Unlike the embedding process, the detection does not require any classification of blocs. This adaptive approach has been assessed on various standard images and compared with a similar watermarking technique (H. Inoue et al., 1999). The results have shown an obvious improvement in terms of robustness against different manipulations and a better ability of detection
1577337
Meaningful automatic video demultiplexing with unknown number of cameras, contrast changes, and motion###This paper presents a software-based parameter-free method for the demultiplexing of a video stream (L. Rudin et al., 2004) that is missing camera labeling information. The method is based on the observation that frames coming from the same input camera share some common characteristic features. These features are extracted from the input frames and grouped together according to statistical criteria. As a result of this grouping the number of different input sources in the video stream is inferred and it is possible to ascertain the source for each frame.
1577336
Video combiner for multi-channel video surveillance based on finite state methods###In this paper a new technique for a multi-channel video combiner based on finite state methods is presented. The proposed technique combines the input video channels in the compressed domain using generalised finite transducers. The proposed technique operates entirely in the compressed domain thus eliminating the processing overhead, delay and picture quality degradation associated with traditional video combiner methods adapting the decompress/combine/recompress approach.
1577339
Face super-resolution using multiple occluded images of different resolutions###In this paper, we present a novel learning-based algorithm to super-resolve multiple partially occluded low-resolution face images. By integrating hierarchical patch-wise alignment and inter-frame constraints into a Bayesian framework, we can probabilistically align multiple input images at different resolutions and recursively infer the high-resolution face image. We address the problem of fusing partial imagery information through multiple frames and discuss the new algorithm's effectiveness when encountering occluded low-re solution face images. We show promising results compared to that of existing face hallucination methods.
1577338
A parallel hardware design for parametric active contour models###We propose a hardware design for parametric active contour models particularly applicable for implementation of gradient vector flow (GVF) snakes. A numerical iterative algorithm of GVF is used to develop a parallel hardware design in a FPGA architecture which is based on using a number of parallel cell units for snake points and a main controller for all control tasks and memory accesses. Using this parallel architecture we could obtain a snake adaptation time of 22 ms in QVGA image size (320&times;240 pixels) which was used for motion detection in video samples of 20 fps. The performance results are very encouraging, however, the system can be still improved by using more parallel architecture and simplifying some complicated instructions.
1577234
Human motion recognition based on statistical shape analysis###Dynamic shape is a time series of the outlines of a moving object, which records the temporal variation of the shape of the object during its movement. We believe that the dynamic shape provides clues about the motion performed by the object. In this paper, we borrow tools from system identification to capture the "essence" of the dynamic shape, so that we convert the problems of modelling, learning, and recognizing object motions to the modelling, learning, and comparing of dynamical systems where each motion is represented. Concretely, we use Kenall's definition of shape to represent object contours extracted from each frame, and construct a tangent space with the full Procrustes mean shape as the pole to approximate a linear space for the data set; we then apply these linearized contour representations as training data to learn the dynamical systems, i.e. estimate system parameters; finally supervised pattern classification techniques based on various types of distance measure are adopted for recognition.
1577235
A belief theory-based static posture recognition systems for real-time video surveillance applications###This paper presents a system that can automatically recognize four different static human body postures for video surveillance applications. The considered postures are standing, sitting, squatting, and lying. The data come from the persons 2D segmentation and from their face localization. It consists in distance measurements relative to a reference posture (standing, arms stretched horizontally). The recognition is based on data fusion using the belief theory, because this theory allows the modelling of imprecision and uncertainty. The efficiency and the limits of the recognition system are highlighted thanks to the processing of several thousands of frames. A considered application is the monitoring of elder people in hospitals or at home. This system allows real-time processing.
1577236
Video surveillance for aircraft activity monitoring###This paper presents a complete visual surveillance system for the automatic scene interpretation of airport aprons. The system comprises two modules scene tracking and scene understanding. The scene tracking module, comprising a bottom-up methodology, and the scene understanding module, comprising a video event representation and recognition scheme, have been demonstrated to be a valid approach for apron monitoring.
1577237
Clustering of human actions using invariant body shape descriptor and dynamic time warping###We propose a human action clustering method based on a 3D representation of the body in terms of volumetric coordinates. Features representing body postures are extracted directly from 3D data, making the system inherently insensitive to viewpoint dependence, motion ambiguities and self-occlusions. An invariant shape descriptor of human body is obtained in order to capture only posture-dependent characteristics, despite possible differences in translation, orientation, scale and body size. Frame-by-frame descriptions, generated from a gesture sequence, are collected together in matrices. Clustering of action matrices is eventually performed, and through a dynamic time warping (while computing the distance metric), we gain independence from possible temporal nonlinear distortions among different instances of the same gesture.
1577238
Relevance learning for spectral clustering with applications on image segmentation and video behaviour profiling###We aim to tackle the problem of unsupervised visual learning. A novel relevance learning algorithm is proposed for data clustering using eigenvectors of a data affinity matrix. We show that it is critical to select the relevant eigenvectors for both estimating the optimal number of clusters and performing data clustering especially given noisy and sparse data. The effectiveness of our algorithm is demonstrated on solving two challenging visual data clustering problems: image segmentation and video behaviour profiling.
1577239
On the feasibility of using a cognitive model to filter surveillance data###This paper describes a novel approach to the problem of automated visual surveillance. The authors have extended an existing algorithm which uses a cognitive model of navigation to explain behaviour in a surveillance setting. We then take this cognitive model and apply it to the problem of filtering surveillance data: typically, a surveillance or CCTV installation will have a limited number of operatives monitoring a large number of cameras. The proposed system filters upon inexplicability scores, on the grounds that those trajectories which we can explain in terms of simple goals are exactly those trajectories which are uninteresting: it is only those we cannot simply explain which are worth attending to. Initial results are promising, with over 50% of uninteresting trajectories being excluded.
1577328
Multi-camera positioning to optimize task observability###The performance of computer vision systems for measurement, surveillance, reconstruction, gait recognition, and many other applications, depends heavily on the placement of cameras observing the scene. This work addresses the question of the optimal placement of cameras to maximize the performance of real-world vision systems in a variety of applications. Specifically, our goal is to optimize the aggregate observability of the tasks being performed by the subjects in an area. We develop a general analytical formulation of the observation problem, in terms of the statistics of the motion in the scene and the total resolution of the observed actions that is applicable to many observation tasks and multi-camera systems. An optimization approach is used to find the internal and external (mounting position and orientation) camera parameters that optimize the observation criteria. We demonstrate the method for multi-camera systems in real-world monitoring applications, both indoor and outdoor.
1577329
Enhanced cross-diamond-hexagonal search algorithms for fast block motion estimation###This paper proposes two enhanced cross-diamond-hexagonal search algorithms to solve the motion-estimation problem in video coding. These algorithms differ from each other by their second step search only, and both of them employ cross-shaped pattern in first step. Proposed method is an improvement over CDHS, which eliminates some checking points of CDHS algorithm. Experimental results show that the proposed methods perform faster than the diamond search (DS) and CDHS, whereas similar quality is preserved.
1577326
A software architecture for real-time, embedded monitoring systems###We introduce software architecture for embedded, real-time monitoring systems. The architecture is based both upon sound software engineering principles and industrial experience in the application domain.
1577327
Tracking soccer players using broadcast TV images###Tracking soccer players using broadcast TV images is a challenging problem because of players' quick movements, occlusion, and camera movements. This paper presents a framework to track multiple players using the temporal spatio-velocity (TSV) transform. The TSV transform is a combination of a windowing process and the Hough transform. We have previously introduced the TSV transform to extract velocity-stable blobs using binary image sequences. In this paper, we extend the transform to apply to grayscale or color images in order to track object textures. We also increase the computational performance of the TSV transform by setting a computational window around the blob being tracked. This operation, which we call the "local TSV transform ", maintains the computational window at the center of the tracked object and provides an alternate means of tracking when players become occluded, a common problem in broadcast TV images. The performance of the system on a soccer video is demonstrated.
1577324
A robust appearance model for tracking human motions###We propose an original method for tracking people based on the construction of a 2-D human appearance model. The general framework, which is a region-based tracking approach, is applicable to any type of object. We show how to specialize the method for taking advantage of the structural properties of the human body. We segment its visible parts, construct and update the appearance model. This latter one provides a discriminative feature capturing both color and shape properties of the different limbs, making it possible to recognize people after they have temporarily disappeared. The method does not make use of skin color detection, which allows us to perform tracking under any viewpoint. The only assumption for the recognition is the approximate viewpoint correspondence during the matching process between the different models. Several results in complex situations prove the efficiency of the algorithm, which runs in near real time. Finally, the model provides an important clue for further human motion analysis process.
1577325
A template-guided approach to vehicle surveillance and access control###Video-based surveillance techniques have extended their scope to the field of undervehicle inspection. However, their role is currently restricted to the visualization of the inspection results, while the evaluation of their outcome depends solely on the judgement of the operator. This paper presents an intelligent template-guided approach, which addresses the task of computer-assisted undervehicle inspection and access control. It combines a license plate identification stage which authenticates incoming vehicles and a template-guided undervehicle inspection stage which alerts the operator in case of questionable content alterations.
1577322
Data association in multi-target tracking using belief theory: handling target emergence and disappearance issue###When associating data in the context of multiple target tracking, one is faced with the problem of handling the target emergence and disappearance. In this paper we show that we are able to handle this issue using belief theory based data association method without the introduction of an additional hypothesis to the frame of discernment. Using a specific modelling of belief functions, this is done by detecting and managing a portion of a conflict, which originates from the non-exhaustivity of the frame of discernment. The proposed method is associative and does not rely on the order under which the beliefs are combined. We demonstrate the effectiveness of the proposed method with experiments on simulated data. Additionally, we compare it with the extended world based data association method where a virtual hypothesis is added to the frame of discernment.
1577323
Stereo person tracking with short and long term plan-view appearance models of shape and color###In prior work, we introduced adaptive plan-view height and occupancy templates, derived from stereo camera data, for person tracking and activity recognition. These templates efficiently capture current details of each tracked person's body pose, thereby enabling good tracking performance even when multiple people occlude and interact with each other. However, the templates ignore useful color information, and their rapid evolution makes them poorly suited for recognizing the same person at well-separated times. In this paper, we seek to remedy both of these shortcomings, by 1) adding novel plan-view color templates to our short-term, template-based models of person appearance, and 2) augmenting our person descriptions with longer-term models that describe invariants of each person's shape and color. We demonstrate how each of these improves our real-time tracking performance on challenging, multi-person sequences.
1577320
A multi-feature object association framework for overlapped field of view multi-camera video surveillance systems###This work describes a data fusion technique to improve performances in objects localization and tracking for automatic video surveillance systems. The developed strategy is designed to perform well in case of interaction among objects, i.e. when the moving objects to track, and whose position we want to locate on the common map reference system, result superimposed in the image plane. In order to solve such complex situations, different kind of techniques have been integrated but the focus of the paper is on the data association step in the fusion chain. As discussed in the text, failing in the association phase means computing wrong position during fusion process. The performances of the developed technique has been evaluated on sequences of real images and experimental results show the validity of the approach in the reduction of association errors during occlusion phases.
1577321
An effective real-time mosaicing algorithm apt to detect motion through background subtraction using a PTZ camera###Nowadays, many visual surveillance systems exploit pan/tilt/zoom (PTZ) cameras to increase the field of view of a surveyed area. The background subtraction technique is widespread to detect moving objects with a high accuracy using one stationary camera. Extending such algorithms to work with moving cameras requires to have a background mosaic at one's disposal. Many solutions using mosaic background subtraction have been proposed, which offer real time capabilities or high quality of the detected objects. However, most of them rely on prior assumptions which limit the camera motion or the algorithm to work with a depth field of view only. In this work we propose some innovative solutions to achieve a real time mosaic background apt to work with existing background subtraction algorithms to yield excellent foreground object masks. Extensive experiments accomplished on challenging indoor and outdoor scenes permit to assess the quality of the mosaic as well as of the detected moving masks.
1217894
Detecting, recognizing and understanding video events in surveillance video###Summary form only given. The Advanced Research and Development Activity (ARDA) is currently sponsoring an advanced research program called VACE or Video Analysis and Content Extraction. The VACE program will embark on a second two-year R and D phase. The focus of this phase of VACE is on moving beyond the detection, recognition and tracking of objects in video streams to the detection, recognition and understanding of the activities that the objects are engaged in. The VALE program is interested in video events in all types of video: these types include: news broadcast video, meeting/conference video, UAV motion imagery and ground reconnaissance video as well as surveillance video. This brief overview, however, concentrates on VACE's interests in and ARDA's goals/objectives for detecting, recognizing and understanding video events in surveillance video.
1217901
Recognition and detection of occluded faces by a neural network classifier with recursive data reconstruction###The paper describes how to improve the robustness to occlusions in face recognition and detection. We propose a neural network architecture which integrates an auto-associative neural network into a simple classifier. The auto-associative network is employed to recall the original face from a partially occluded face image and to detect the occluded regions in the input image. The original face can be reconstructed by replacing those regions with the recalled pixels. By applying this reconstruction process recursively, the integrated network is able to classify occluded faces robustly. To confirm the effectiveness of this method, we performed experiments on face image classification and face detection. It is shown that the classification performance is not decreased even if 20-30% of the face image is occluded.
1217925
Detecting abandoned packages in a multi-camera video surveillance system###We describe a video surveillance system that detects abandoned packages automatically. In this system, multiple cameras locate objects in space and time despite occlusions and distracting lighting effects observed by subsets of the cameras. A multiple-state model of an abandoned package provides the ability to detect realistic abandoned package events. The paper outlines the system by describing the modules for camera view segmentation, object classification, view-object association, 3D object tracking, and finally detection of the event of a package being abandoned, which highlights object association using multiple cameras and the multiple-state abandoned package model.
1217900
Efficient design of advanced correlation filters for robust distortion-tolerant face recognition###The paper summarizes new research in performing face recognition using advanced correlation filters. We examine the performance of such filters in the area of biometrics for face authentication. We also compare results when the filters are applied to face identification. Our results are based on the illumination subsets of the CMU PIE database. We also present methods that reduce the memory requirements of these filters to run on limited computational resources, including computationally efficient methods of synthesizing these filters. Finally, we describe an online training algorithm implemented on a face verification system for synthesizing correlation filters from a video stream to handle pose/scale variations. The system also uses an efficient scheme to perform face localization within the current framework during the authentication stage.
1217926
Moving cast shadow elimination for robust vehicle extraction based on 2D joint vehicle/shadow models###A new algorithm to eliminate moving cast shadow for robust vehicle detection and extraction in a vision-based highway monitoring system is investigated. The proposed algorithm is based on a simplified 2D vehicle/shadow model of six types projected on to a 2D image plane. Parameters of the joint 2D vehicle/shadow models can be estimated from the input video without light source and camera calibration information. Simulations are performed to verify that the proposed technique is effective for vision-based highway surveillance systems.
1217903
Experimental results from using a rank and fuse approach for multi-target tracking in CCTV surveillance###We study a novel approach to the problem of fusion of sensory information in tracking multiple targets in CCTV surveillance video. The approach, called "rank and fuse" (RAF) is based on multiple feature ranking and merging as opposed to a more typical combination of all scores (similarity or probability) in a single ranking. This has the advantages of low computational complexity, easy scalability to multiple features, and low-latency. Experimental results are presented to illustrate two aspects of the RAF approach for a "difficult" example from CCTV surveillance: the advantage of rank versus score combination, and the use of the rank versus score curve to decide which features to fuse.
1217890
Battlefields that see###Summary form only given. We introduce two new applications of automated video analysis being pursued by DARPA. Video Verification of Identity (VIVID) is concerned with automatically tracking moving vehicles from a moving aircraft and searching the surrounding area for others who may be nearby. Combat Zones That See (CTS) is coordinating the analysis of large numbers of fixed cameras to identify and track vehicles over extended distances. Together, these programs illustrate the transformational power that the automated analysis of video has for military reconnaissance.
1217930
Human body pose estimation using silhouette shape analysis###We describe a system for human body pose estimation from multiple views that is fast and completely automatic. The algorithm works in the presence of multiple people by decoupling the problems of pose estimation of different people. The pose is estimated based on a likelihood function that integrates information from multiple views and thus obtains a globally optimal solution. Other characteristics that make our method more general than previous work include: (1) no manual initialization; (2) no specification of the dimensions of the 3D structure; (3) no reliance on some learned poses or patterns of activity; (4) insensitivity to edges and clutter in the background and within the foreground. The algorithm has applications in surveillance and promising results have been obtained.
1217931
Fast good features selection for wide area monitoring###Recently the surveillance of wide areas has pointed the interest of the research community. The use of active vision seems to be the most effective solutions for these needs. Against the better acquiring resolution there is the problem of the apparent motion inducted by the camera motion known as ego-motion. Feature based methods for ego-motion estimation are widely used in computer vision but they deal with feature recovery and with errors in feature tracking. In this paper, we propose a fast method to extract and select new features during camera motion. This is achieved by adopting a reference map containing well trackable features that is updated at each frame by introducing new good features related to regions appearing in the current image. A new procedure is applied to reject badly tracked features. The current frame and the background after compensation are processed by a change detection method in order to locate mobile objects. Results are presented in the context of a visual-based surveillance system for monitoring outdoor environments.
1217932
Posture estimation in visual surveillance of archaeological sites###The paper presents a fast and reliable approach to estimate body postures in outdoor visual surveillance. It works on patches corresponding to people, recognized by two subsystems (motion detection and object recognition) on image sequences coming from a still camera. The proposed algorithm is based on an unsupervised clustering approach and is substantially independent from a-priori assumption about the possible output postures. Horizontal and vertical histograms of the binary shapes associated to humans are selected as features. The Manhattan distance is used for building clusters and for run-time classification. After experimental tests the BCLS (Basic Competitive Learning Scheme) algorithm has been selected for the construction of clusters. The whole approach has been verified on real sequences acquired while typical illegal activities involved in stealing were simulated in an archeological site.
1217933
Invariant feature extraction and biased statistical inference for video surveillance###Using cameras for detecting hazardous or suspicious events has spurred new research for security concerns. To make such detection reliable, researchers trust overcome difficulties such as variation in camera capabilities, environmental factors. imbalances of positive and negative training data, and asymmetric costs of misclassifying events of different classes. Following up on the event-detection framework (Wu et al. (2003)) that we have proposed, we present in this paper the framework's two major components: invariant feature extraction and biased statistical inference. We report results of our experiments using the framework for detecting suspicious motion events in a parking lot.
1217934
Boosting object detection using feature selection###Feature subset selection has received considerable attention in the machine learning literature, however, it has not been fully explored or exploited in the computer vision area. In this paper, we consider the problem of object detection using genetic algorithms (GA) for feature subset selection. We argue that feature selection is an important problem in object detection, and demonstrate that GA provide a simple, general, and powerful framework for selecting good sets of features, leading to lower detection error rates. As a case study, we have chosen to perform feature extraction using the popular method of principal component analysis (PCA) and classification using support vector machines (SVM). We have tested this framework on. two difficult and practical object detection problems: vehicle detection and face detection. Experimental results demonstrate significant performance improvements in both cases.
1217889
Proceedings IEEE Conference on Advanced Video and Signal Based Surveillance. AVSS 2003###The following topics are dealt with: face detection; face recognition; tracking; motion analysis; object detection; event analysis/learning; change detection; feature selection/extraction; video registration; system/camera calibration.
1217936
Vision-based positioning and terrain mapping by global alignment for UAVs###Construction of 3D topographic maps from stereo or monocular video, over coverage areas of kilometer scale, taken by low-altitude airborne platforms is addressed. Two computational frameworks for these two cases are considered, accommodating the online processing of video along the path. In these formulations, stereo disparity information enables the computation of 3D motions and depth maps to be done more readily, however, monocular motion cues provide similar accuracy with more computational steps. The critical issue is to overcome the drift error, which is inherent of the causal frame-to frame motion estimation, as the video frames are acquired. A novel global alignment scheme is proposed, aimed at determining the 3D trajectory most consistent with the estimated 3D motions between pairs of nearby positions. Performance is demonstrated based on experiment with a sequence of 5000 stereo pairs, simulating aerial photographic data from an airborne platform flying at 110 m above (the reference plane of) a 1 km &times; 1 km terrain with 5-65m elevation. Maximum geo-referenced positioning accuracy is roughly 2 m, with elevation error of 1 m or less over 95% of the terrain.
1217937
On registration of regions of interest (ROI) in video sequences###The paper addresses the problem of registering regions of interest in two video sequences. Potential applications include blob fusion and target tracking in blurry sequences. It is assumed that the moving target is tracked successfully in one of the two sequences and is represented by a bounding box in each frame of the first sequence. The goal is to find the corresponding bounding box for each frame of the second video sequence. The registration algorithm developed is based on mutual information. To facilitate the registration process, the two cameras are assumed to be calibrated such that the geometrical transformation required to register the corresponding bounding boxes is a 2D rigid body transformation without rotation. Visual and IR video sequences are used to test the proposed approach.
1217912
Photometric aspects: a new approach for 3D free form object recognition using a single luminance image###3D free form object recognition is one of the most difficult problems in computer vision. We present a new approach which exploits only one luminance image of a complex object to recognize it in the scene by identifying its appearance in the input image. We construct a photometric (non geometric) projective invariant to perform matching between local regions of the object in the image and those of the model. We propose an original method based on what we called "photometric aspects" to construct a discriminative data base of the 3D object model. We demonstrate the effectiveness of our approach while implementing it with complex free form objects and we present some obtained results.
1217913
Adaptive object identification and recognition using neural networks and surface signatures###The paper introduces an adaptive technique for 3D object identification and recognition in 3D scanned scenes. This technique uses neural learning of the 3D free-form surface representation of the object in study. This representation scheme captures the 3D curvature information of any free-form surface and encodes it into a 2D image corresponding to a certain point on the surface. This image represents a "surface signature" because it is unique for this point and is independent of the object translation or orientation in space.
1217910
Human detection using depth and gray images###A method is presented for extracting pedestrian information from an image sequence taken by a monocular camera. The method makes use of hybrid sensing of depth and gray information and it is shown to work well in an indoor environment. A split-and-merge strategy is proposed to process depth data for object and human detection. Furthermore, human tracking and event detection are also presented to recognize simple behavior such as hand-shaking. This method does not use background subtraction, and therefore it is applicable for scenes taken from mobile platforms. Experimental results are presented to validate our approach.
1217911
Supervised-PCA and SVM classifiers for object detection in infrared images###We tackle the problem of detecting sources of combustion in high definition multispectral medium wavelength infrared (MWIR) (3-5 &mu;m) images. We present a novel approach to this problem consisting of processing the images block-wise using a new technique that we call supervised principal component analysis (SPCA) to get the components of these blocks. This outperforms state-of-the-art methods with a significant reduction in the complexity of the whole scheme. As a classifier, we propose the use of a support vector machine (SVM) comparing the results from both its novelty-detection and binary non-linear versions. High performance is achieved from a small set of components.
1217916
Recognizing human activities###The paper deals with the problem of classification of human activities from video as one way of performing activity monitoring. Our approach uses motion features that are computed very efficiently and subsequently projected into a lower dimension space where matching is performed. Each action is represented as a manifold in this lower dimension space and matching is done by comparing these manifolds. To demonstrate the effectiveness of this approach, it was used on a large data set of similar actions, each performed by many different actors. Classification results are accurate and show that this approach can handle many challenges such as variations in performers' physical attributes, color of clothing, and style of motion. An important result is that the recovery of three-dimensional properties of a moving person, or even two-dimensional tracking of the person's limbs, is not a necessary step that must precede action recognition.
1217917
A real time vehicle's license plate recognition system###A smart and simple algorithm is presented for a vehicle license plate recognition system. Based on pattern matching, this algorithm can be applied for real time detection of license plates for collecting data for surveying or for some application specific purposes. The proposed system has been prototyped using C++ and the experimental results have been shown for recognition of Alberta license plates.
1217914
Towards a view invariant gait recognition algorithm###Human gait is a spatio-temporal phenomenon and typifies the motion characteristics of an individual. The gait of a person is easily recognizable when extracted from a side-view of the person. Accordingly, gait-recognition algorithms work best when presented with images where the person walks parallel to the camera image plane. However, it is not realistic to expect this assumption to be valid in most real-life scenarios. Hence, it is important to develop methods whereby the side-view can be generated from any other arbitrary view in a simple, yet accurate, manner. This is the main theme of the paper. We show that if the person is far enough from the camera, it is possible to synthesize a side view (referred to as canonical view) from any other arbitrary view using a single camera. Two methods are proposed for doing this: (i) using the perspective projection model; (ii) using the optical flow based structure from motion equations. A simple camera calibration scheme for this method is also proposed. Examples of synthesized views are presented. Preliminary testing with gait recognition algorithms gives encouraging results. A by-product of this method is a simple algorithm for synthesizing novel views of a planar scene.
1217915
Fingerprint identification: classification vs. indexing###We present a comparison of two key approaches for fingerprint identification. These approaches are based on (a) classification followed by verification, and (b) indexing followed by verification. The fingerprint classification approach is based on a novel feature-learning algorithm. It learns to discover composite operators and features that are evolved from combinations of primitive image processing operations. These features are then used for classification of fingerprints into five classes. The indexing approach is based on novel triplets of minutiae. The verification algorithm, based on least square minimization over each of the possible minutiae triplet pairs, is used for identification in both cases. On the NIST-4 fingerprint database, the comparison shows that, although correct classification rate can be as high as 92.8% for 5-class problems, the indexing approach performs better, based on the size of the search space and identification results.
1217896
Face cataloger: multi-scale imaging for relating identity to location###The level of security at a facility is directly related to how well the facility can keep track of "who is where". The "who" part of this question is typically addressed through the use of face images for recognition either by a person or a computer face recognition system. The "where" part of this question can be addressed through 3D position tracking. The "who is where" problem is inherently multi-scale, wide angle views are needed for location estimation and high resolution face images for identification. A number of other people tracking challenges like activity understanding are multiscale in nature. An effective system to answer "who is where?" must acquire face images without constraining the users and must closely associate the face images with the 3D path of the person. Our solution to this problem uses computer controlled pan-tilt-zoom cameras driven by a 3D wide-baseline stereo tracking system. The pan-tilt-zoom cameras automatically acquire zoomed-in views of a person's head, while the person is in motion within the monitored space.
1217907
Application of adaptive block matching in the extraction of temporal motor activity signals from video recordings of neonatal seizures###The paper presents a procedure developed to extract quantitative information from video recordings of neonatal seizures in the form of temporal motor activity signals. The motor activity signals are extracted by tracking selected anatomical sites during the seizure using adaptive block matching. The motion of a block of pixels is quantified by searching for the most similar block of pixels in subsequent frames; this search is facilitated by employing various update strategies to account for the changing appearance of the block. Experiments indicate that the temporal motor activity signals extracted by the proposed procedure constitute an effective representation of videotaped clinical events and can be used for seizure recognition and characterization.
1217902
Discrete event modeling of misrecognition in PTZ tracking###The paper introduces an approach to the problem of choosing when to zoom a moving camera so as to follow a designated video surveillance target. Rather than trying to maintain a simple viewing constraint (e.g., target >10% of image), the potential misrecognition of the target is also used to decide when to zoom. A discrete-event approach is used to develop two models of appearance change as well as a model that represents the viewing constraints for target surveillance. Disagreement between the appearance models is taken to indicate a potential loss of target. Supervisory discrete event control theory is used to construct automatically a controller that selects zoom actions to prevent loss of target. The implementation of this controller is overviewed and results presented.
1217906
Improving the extraction of temporal motion strength signals from video recordings of neonatal seizures###The paper presents a procedure developed to extract quantitative information from video recordings of neonatal seizures in the form of temporal motion strength signals. These signals are obtained by applying nonlinear filtering, segmentation, and morphological filtering on the differences between adjacent frames. The experiments indicate that temporal motion strength signals constitute an effective representation of videotaped clinical events and can be used for seizure recognition and characterization.
1217924
An IEEE 1394 - FireWire - based embedded video system for surveillance applications###In order to address the need for portable inexpensive systems for video surveillance, we built a computer vision system that provides digital video data transfer from a CCD camera using embedded software/hardware via the IEEE 1394 protocol, also known as FireWire or i.Link, and Ethernet TCP/IP interfaces. Controlled by an extended version of the IEEE 1394-based digital camera specification (DCAM), the system is made up of entirely open interfaces that provide many image resolutions and frame rates, and digital signal processing and compression capabilities. We present the design of the system and its performance on running a digital signal processing application. We also give details about the software and hardware architecture, as well as our directions for future research and development.
1217918
A reliable-inference framework for recognition of human actions###We present an action recognition method based on the concept of reliable inference. Our approach is formulated in a probabilistic framework using posterior class ratios to verify the saliency of an input before committing to any action classification. The framework is evaluated in the context of walking, running, and standing at multiple viewpoints and compared to ML and MAP approaches. Results examining individual silhouette images with the framework demonstrate that these actions can be reliably discriminated while discounting confusing images.
1217919
Discovering Bayesian causality among visual events in a complex outdoor scene###Modelling events is one of the key problems in dynamic scene understanding when salient and autonomous visual changes occurring in a scene need to be characterised as a set of different object temporal events. We propose an approach to understand complex outdoor scenarios which is based on modelling temporally correlated events using dynamic Bayesian networks (DBNs). A partially coupled hidden Markov model (PCHMM) is exploited whose topology is determined automatically using the Bayesian information criterion (BIC). Causality discovery and events modelling are also tackled using a multi-observation hidden Markov model (MOHMM).
1217927
Detection of changes in surveillance videos###We provide theoretical and experimental results showing that the dimension of video trajectories is a useful tool to access the mid-level content of videos, such as the appearance or disappearance of an object, and changes in the velocity and direction of moving objects. Moreover, the amount of change is proportional to the size of the objects involved and their speed. All this is achieved by a robust technique of dimensionality computation of video trajectories based on eigenvalues.
1217938
Video extraction in compressed domain###In this paper, we propose a video extraction algorithm directly in the compressed domain for low cost and fast content access to those compressed video data via MPEG. Extensive experiments show that such extracted images and videos not only maintain well-preserved content features, but also illustrate reasonable quality in terms of both PSNR values and visual inspection. In cases where video processing tasks do not necessarily require full resolution pixel data such as browsing, pattern recognition, and object tracking in surveillance applications, the proposed algorithm will provide superior performance in terms of computing efficiency, under the context that millions of video frames need to be accessed, yet they are stored in compressed format.
1217935
Color-based video stabilization for real-time on-board object detection on high-speed trains###This paper is concerned with a particular application of image stabilization. Image stabilization is a necessary step to reduce the effect of camera motion when, as in this case, image sequences are acquired from a mobile platform. In this work, in order to find an efficient motion estimator, two one-dimensional characteristic curves are extracted from each video frame. Such curves are then compared in consequent frames to estimate image displacement. The proposed algorithm is suitable for real time processing and provides good performance; in order to verify its validity, it has been tested on a variety of color video-sequences taken from the point of view of trains moving along railways tracks. Results are provided in order to compare the proposed approach with a feature-based stabilization method.
1217923
Scalable image-based multi-camera visual surveillance system###We describe the design of a scalable and wide coverage visual surveillance system. Scalability (the ability to add and remove cameras easily during system operation with minimal overhead and system degradation) is achieved by utilizing only image-based information for camera control. We show that when a pan-tilt-zoom camera pans and tilts, a given image point moves in a circular and a linear trajectory, respectively. We create a scene model using a plan view of the scene. The scene model makes it easy for us to handle occlusion prediction and schedule video acquisition tasks subject to visibility constraints. We describe a maximum weight matching algorithm to assign cameras to tasks that meet the visibility constraints. The system is illustrated both through simulations and real video from a 6-camera configuration.
1217922
A distributed visual surveillance system###We present a distributed vision-based surveillance system. The system acquires and processes grey level images through one or multiple camera units monitoring certain area(s) via a local area network (LAN) and is capable of combining information from multiple camera units to obtain a consensus decision. It can be trained to detect certain type of intrusions, for example pedestrians, a group of pedestrians, vehicles, pets, etc., and minimizes false alerts due to other non-interested intrusions. As a case study, we aim to detect pedestrian/vehicle in an observation area. Our vision-based intrusion detection approach consists of two main steps: background subtraction based hypothesis generation (HG) and appearance-based hypothesis verification (HV). HG hypothesizes possible threats (intrusions), and HV verifies those hypotheses using a Gabor filter for feature extraction and support vector machines (SVMs) for classification. The system has been tested in an unconstrained outdoor environment, illustrating good performance.
1217921
Mugshot database acquisition in video surveillance networks using incremental auto-clustering quality measures###Face recognition has primarily focused on recognizing and matching face images against large, controlled databases of frontal views. Many of these techniques perform well against databases that have been collected from a reduced set of viewpoints, under controlled lighting, and are normalized for scale. Acquisition of these databases, however, particularly in unconstrained environments, remains a challenge. We present a real-time technique to acquire a mugshot database automatically from a video surveillance network. Mugshot extraction is a twofold problem. First, faces are detected and tracked in all cameras of the network. Face targets are analyzed to determine which frames represent actual mugshots capable of supporting subsequent matching and recognition. Next, mugshot candidates are evaluated based on their ability to improve the quality of the incrementally constructed database. We introduce a database quality measure, which assigns high value to mugshots of previously unseen subjects or mugshots that do not decrease separability of existing clusters. The quality measure is discounted for mugshots that are redundant or increase the intra-cluster spread. Results demonstrate that automatic acquisition of a high-quality database from a twelve-camera network is feasible. The quality of these databases is demonstrated using traditional methods to match faces accurately against the acquired database.
1217920
Automatic learning of an activity-based semantic scene model###The paper proposes an activity-based semantic model for a scene under visual surveillance. It illustrates methods that allow unsupervised learning of the model from trajectory data derived from automatic visual surveillance cameras. Results are shown for each method. Finally, the benefits of such a model in a visual surveillance system are discussed.
1217909
A robust motion-estimation algorithm for multiple-target tracking at close proximity based on hexagonal partitioning###The paper develops a solution to the task of tracking the position and movement of large (relative to pixel and image size) bodies through a visible-light camera's field of view. Noise sources such as dynamic backgrounds, vibration, variation in appearance, and rapidly changing lighting environments contribute to the complexity. Given that a low number of targets may be present at any one time and some assumptions about the dynamic nature of the image and targets, a solution to this problem is formulated which localizes and tracks objects in the field of view. The algorithm is capable of distinguishing among multiple targets which are in close proximity to the camera and to each other. A major consideration in the development is that the implemented system should be able to process the data in real time with moderate computational power. The present area of application is that of automatically generating ridership statistics for transit agencies: to count persons getting on or off a bus.
1217908
A multi-camera conical imaging system for robust 3D motion estimation, positioning and mapping from UAVs###Over the last decade there, has been an increasing interest in developing vision systems and technologies that support the operation of unmanned platforms for positioning, mapping, and navigation. Until very recently, these developments relied on images from standard CCD cameras with a single optical center and limited field of view, making them restrictive for some applications. Panoramic images have been explored extensively in recent years. The particular configuration of interest to our investigation yields a conical view, which is most applicable for airborne and underwater platforms. Instead of a single catadioptric camera (Gluckman, J.M. and Nayar, S.K., 1999; Swaminathan, R. et al., 2001), a combination of conventional cameras may he used to generate images at much higher resolution (Negahdaripour, S. et al., Proc. Oceans, 2001). We derive complete mathematic models of projection and image motion equations for a down-looking conical camera that may be installed on a mobile platform - e.g. an airborne or submersible system for terrain flyover imaging. We describe the calibration of a system comprising multiple cameras with overlapping fields of view to generate the conical view. We demonstrate with synthetic and real data that such images provide better accuracy in 3D visual motion estimation, which is the underlying issue in 3D positioning, navigation, mapping, image registration and photo-mosaicking.
1217899
3D face modeling using two views and a generic face model with application to 3D face recognition###We present an algorithm for 3D face modeling from a frontal image and a profile image of a person's face. The algorithm starts by computing the 3D coordinates of automatically extracted facial feature points. The coordinates of the selected feature points are then used to deform a 3D generic face model to obtain a 3D face model for that person. Procrustes analysis is used to minimize globally the distances between the facial feature vertices in the model and the corresponding 3D points obtained from the images. Then, local deformation is performed on the facial feature vertices to obtain a more realistic 3D model for the person. Preliminary experiments to asses the applicability of the models for face recognition show encouraging results.
1217898
Automatic face region tracking for highly accurate face recognition in unconstrained environments###We present a combined real-time face region tracking and highly accurate face recognition technique for an intelligent surveillance system. High-resolution face images are very important to achieving accurate identification of a human face. Conventional surveillance or security systems, however, usually provide poor image quality because they use only fixed cameras to record scenes passively. We have implemented a real-time surveillance system that tracks a moving face using four pan-tilt-zoom (PTZ) cameras. While tracking, the region-of-interest (ROI) can be obtained by using a low-pass filter and background subtraction with the PTZ. Color information in the ROI is updated to extract features for optimal tracking and zooming. FaceIt<sup>&reg;</sup>, which is one of the most popular face recognition software packages, is evaluated and then used to recognize the faces from the video signal. Experimentation with real human faces showed highly acceptable results in the sense of both accuracy and computational efficiency.
1217897
Face tracking system based on color, stereovision and elliptical shape features###We present a vision system that tracks a human face in 3D. We combine color and stereo cues to find likely image regions where a face may exist. A greedy search algorithm examines for a face candidate, focusing action around the position at which the face was detected in the previous time step. The aim of the search is to find the best-fit head ellipse. The size of the searched ellipse projected into the image is scaled depending on the depth information. The final position of the ellipse is determined on the basis of intensity gradient near the edge of the ellipse, depth gradient along the head boundary and matching of the color histograms representing the interior of the actual and the previous ellipse. The color histogram and parameters of the ellipse are dynamically updated over time and compared with previous ones. The frontal view face is detected using PCA to make the tracking more reliable and, in particular, to update the color model over time with only face-like skin pixels.
1217904
PMHT based multiple point targets tracking using multiple models in infrared image sequence###Data association and model selection are important factors for tracking multiple targets in a dense clutter environment. We propose a sequential probabilistic multiple hypotheses tracking (PMHT) based algorithm using interacting multiple modelling (IMM), namely the IMM-PMHT algorithm. Inclusion of IMM enables any arbitrary trajectory to be tracked without any a priori information about the target dynamics. IMM allows us to incorporate different dynamic models for the targets and PMHT helps to avoid the uncertainty about the measurement origin. It operates in an iterative mode using an expectation-maximization (EM) algorithm. The proposed algorithm uses only measurement association as missing data, which simplifies E-step and M-step. It is computationally more efficient, and an important characteristic of our proposed algorithm is that it operates in a single batch model, i.e. sequential, and hence can be used for real time tracking.
1217895
A novel approach to detect and correct highlighted face region in color image###Different environmental illumination has a great impact on face detection and recognition. Automatic detection and radiant correction of highlighted regions on face images is helpful to identify human faces correctly in a color image. In this paper we present a novel approach based on dichromatic reflection model to detect and remove highlights in the face region. After inspecting the distribution configuration of skin pixels in various color models, we perform the highlight analysis on a critical two-dimensional plane instead of in a three-dimensional chromatic space. This brings forth some advantages: computational complexity is reduced, a ratio between eigenvalues is proposed in a stepwise PCA to detect automatically the existence of highlighted face region and estimate the skin dichromatic reflection vectors, by which highlight in the face region can be removed.
1217928
Moving object detection between multiple and color images###There are several publications dedicated to the description and analysis of change detection between two gray-value images. This paper introduces new methods to detect moving objects between multiple images and to detect changes between color images or any type of multispectral images. We are not aware of methods giving the possibility of detecting color changes and changes between multiple frames. All the proposed change detectors are based on the Gramian determinant, which provides low computational cost and is easy to implement. These features are very important due to the additional complexity of change detection between multiple as well as color images.
1217893
Real-time detection of threat###Summary form only given. Government agencies, personnel security professionals, and our military services are faced with new challenges to rapidly assess the credibility of statements made by individuals in airports, border crossings, secured facilities, and a variety of environments not conducive to prolonged interviews. The changing environment has become more global and threats lie not just in the securing of an environment, but the increased dependency on gathering accurate information from a variety of individuals. The most robust source available for obtaining information regarding the past and present behavior of an individual or groups of individuals may be the person of interest. Some new technologies may offer assistance in this critical area. Current advanced research projects looking at emerging technologies in operational credibility assessment are presented for discussion.
1217892
Video surveillance and human activity recognition for anti-terrorism and force protection###Summary form only given. Current ONR and joint ONR/DARPA programs in video surveillance technology are presented. These include: omni-directional video in a panoramic periscope for submarine situation awareness and mast-mounted omni-cameras for force protection of surface combatants in harbors and for shoreline protection. Ongoing research projects on automated detection and tracking of humans and small craft for AT/FP are discussed in relation to emerging requirements. Research progress, challenges and opportunities in video-based human activity recognition are explored. New DARPA initiatives in facial expression analysis and deception detection for checkpoint screening are presented.
1217891
Progress in Human ID###Summary form only given. The Human ID program is developing techniques and methods for identifying humans at a distance. Techniques being investigated are face recognition; recognition from body dynamics in video including gait; recognition from infrared, multi-spectral, and hyperspectral imagery. To assess progress a series of evaluations, challenging problems, and demonstrations are being conducted.
1217944
Automatic camera selection and fusion for outdoor surveillance under changing weather conditions###An outdoor multi-camera video surveillance system operating under changing weather conditions is presented. A new confidence measure, appearance ratio (AR), is defined to evaluate automatically the sensors' performance for each time instant. By comparing their ARs, the system can select the most appropriate cameras to perform specific tasks. When redundant measurements are available for a target, the AR measures are used to perform a weighted fusion of them. Experimental results are presented on outdoor scenes under different weather conditions.
1217905
Self-occlusion immune video tracking of objects in cluttered environments###We propose a new approach that uses a motion-estimation based framework for video tracking of objects in the presence of self-occlusion in cluttered environments. What makes our work different from others is that, instead of carrying out the motion estimation between two adjacent frames, we tackle the self-occlusion problem from the view of multiple frames. The heart of our approach lies in extracting features appearing in different time frames, genesis frames, and setting up a motion estimation scheme through multiple applications of Kalman filtering based on the different genesis indices. To make the tracked object look visually familiar to the human observer, the system also makes its best attempt at extracting the boundary contour of the object - a difficult problem in its own right, since self-occlusion created by any rotational motion of the tracked object would cause large sections of the boundary contour in the previous frame to disappear in the current frame. Our approach has been tested on a wide variety of video sequences, some of which are presented.
1217939
A frame-level FSBM motion estimation architecture with large search range###Motion estimation plays an important role in video compression to remove temporal redundancies between successive frames. It is also useful in aiding detection of moving objects. Full-search block-matching (FSBM) is the most preferred algorithm for motion estimation. Frame-level pipelined FSBM architectures have advantages over block-level pipelined architectures in their simpler control and reduced number of memory accesses. In this paper, a frame-level pipelined FSBM motion estimation array processor for large search range p = qN is presented where q&ge; 1/2 and N&times;N is the block size.
1217941
Adaptive live video streaming by priority drop###In this paper we explore the use of priority progress streaming (PPS) for video surveillance applications. PPS is an adaptive streaming technique for the delivery of continuous media over variable bit-rate channels. It is based on the simple idea of reordering media components within a time window into priority order before transmission. The main concern when using PPS for live video streaming is the time delay introduced by reordering. In this paper we describe how PPS can be extended to support live streaming and show that the delay inherent in the approach can be tuned to satisfy a wide range of latency constraints while supporting fine-grain adaptation.
1217940
Combined wavelet domain and temporal video denoising###We develop a new filter which combines spatially adaptive noise filtering in the wavelet domain and temporal filtering in the signal domain. For spatial filtering, we propose a new wavelet shrinkage method, which estimates how probable it is that a wavelet coefficient represents a "signal of interest" given its value, given the locally averaged coefficient magnitude and given the global subband statistics. The temporal filter combines a motion detector and recursive time-averaging. The results show that this combination outperforms single resolution spatio-temporal filters in terms of quantitative performance measures as well as in terms of visual quality. Even though our current implementation of the new filter does not allow real-time processing, we believe that its optimized software implementation could be used for real- or near real-time filtering.
1217943
Site calibration for large indoor scenes###Indoor video surveillance networks as typically used in retail-networks need to be consistently calibrated with respect to a global coordinate system to provide the spatial context required for automatic recognition. This can be problematic if the fields of view of the cameras are disjoint. The paper presents a strategy to calibrate disjoint views into one coordinate system. The system is based on a device which can calculate its current position and orientation with respect to the global coordinate frame while it traverses the entire site without requiring direct line of sight between all sets of points. The paper explains why more traditional approaches have disadvantages and presents experimental results using the new method.
1217942
A survey of camera self-calibration###The paper surveys the developments of the last 10 years in the area of camera self-calibration. Self-calibration is an attempt to calibrate camera by finding intrinsic parameters that are consistent with the underlying projective geometry of a sequence of images. In order to solve this problem, the camera intrinsic constraints have been used separately and in conjunction with camera motion constraints or scene constraints. Most self-calibration algorithms are concerned with unknown but constant intrinsic camera parameters. Recently, camera self-calibration in the case of varying intrinsic camera parameters was also studied. We present the basic theories behind the different self-calibration techniques and discuss the ideas behind most of the self-calibration algorithms.
1217945
SOM based algorithm for video surveillance system parameter optimal selection###In automatic video surveillance systems, full time monitoring represents an important goal to achieve. The aim of the paper is to find a new methodology for video surveillance adaptive parameter regulation. The method presented is based on self organizing maps (SOM) which are used for parameter regulation purposes. Results shown prove how this method permits overall good performances to be achieved for all environments.
1217929
A change-detection algorithm based on structure and colour###The paper proposes a novel change-detection algorithm for automated video surveillance applications. The algorithm is based on the idea of incorporating into the background model a set of simple low-level features capable of capturing effectively "structural" (i.e. robust with respect to illumination variations) information. Thanks to this approach, and unlike most conventional change-detection algorithms, the proposed algorithm is capable of handling correctly still and slow objects as well as of working properly throughout very long time spans. Moreover, the algorithm can naturally interact with the higher-level processing modules found in advanced video-based surveillance systems in order to allow for flexible and intelligent background maintenance.
